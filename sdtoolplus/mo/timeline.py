# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
from datetime import datetime
from datetime import timedelta
from itertools import pairwise
from uuid import UUID

import structlog
from more_itertools import one
from more_itertools import only
from more_itertools.more import collapse
from more_itertools.more import first

from sdtoolplus.autogenerated_graphql_client import ClassFilter
from sdtoolplus.autogenerated_graphql_client import EmployeeFilter
from sdtoolplus.autogenerated_graphql_client import FacetFilter
from sdtoolplus.autogenerated_graphql_client import GetRelatedUnitsRelatedUnitsObjects
from sdtoolplus.autogenerated_graphql_client import RAValidityInput
from sdtoolplus.autogenerated_graphql_client.input_types import AssociationCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import AssociationFilter
from sdtoolplus.autogenerated_graphql_client.input_types import (
    AssociationTerminateInput,
)
from sdtoolplus.autogenerated_graphql_client.input_types import AssociationUpdateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EmployeeCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EmployeeUpdateInput
from sdtoolplus.autogenerated_graphql_client.input_types import OrganisationUnitFilter
from sdtoolplus.autogenerated_graphql_client.input_types import RelatedUnitFilter
from sdtoolplus.config import TIMEZONE
from sdtoolplus.depends import GraphQLClient
from sdtoolplus.exceptions import MoreThanOneAssociationError
from sdtoolplus.mo_org_unit_importer import OrgUnitUUID
from sdtoolplus.models import POSITIVE_INFINITY
from sdtoolplus.models import Active
from sdtoolplus.models import AssociationTimeline
from sdtoolplus.models import EngagementSDUnit
from sdtoolplus.models import EngagementUnit
from sdtoolplus.models import Person
from sdtoolplus.models import Timeline
from sdtoolplus.models import combine_intervals

logger = structlog.stdlib.get_logger()


def mo_end_to_datetime(mo_end: datetime | None) -> datetime:
    """
    Convert a MO end datetime or None to a datetime directly as it is in MO, i.e.
    no +/- timedelta adjustments are performed.
    """
    return mo_end if mo_end is not None else POSITIVE_INFINITY


def datetime_to_mo_end(end_datetime: datetime) -> datetime | None:
    """
    Convert a datetime to a MO end date or None directly as it is, i.e. no +/-
    timedelta adjustments are performed.
    """
    return None if end_datetime == POSITIVE_INFINITY else end_datetime


def _mo_end_to_timeline_end(mo_end: datetime | None) -> datetime:
    """
    Convert a MO end datetime to the end date required by our timeline objects.
    """
    mo_end = mo_end_to_datetime(mo_end)
    return (
        mo_end + timedelta(days=1)
        if not mo_end == POSITIVE_INFINITY
        else POSITIVE_INFINITY
    )


def timeline_interval_to_mo_validity(start: datetime, end: datetime) -> RAValidityInput:
    mo_end = datetime_to_mo_end(end)
    # Subtract one day due to MO
    mo_end = mo_end - timedelta(days=1) if mo_end is not None else None
    return RAValidityInput(from_=start, to=mo_end)


def get_patch_validity(
    codegen_validity_from: datetime,
    codegen_validity_to: datetime | None,
    mo_validity: RAValidityInput,
) -> RAValidityInput:
    """
    Get the validity for which the patch update should be performed. We need to truncate
    it with the timeline (start, end) endpoint update validities in order not to write
    beyond these in MO for the particular patch operation.
    """
    codegen_validity_to_datetime = mo_end_to_datetime(codegen_validity_to)
    mo_validity_to = mo_end_to_datetime(mo_validity.to)

    patch_validity_from = max(codegen_validity_from, mo_validity.from_)
    patch_validity_to = min(codegen_validity_to_datetime, mo_validity_to)

    return RAValidityInput(
        from_=patch_validity_from,
        to=None if patch_validity_to is POSITIVE_INFINITY else patch_validity_to,
    )


async def get_class(
    gql_client: GraphQLClient,
    facet_user_key: str,
    class_user_key: str,
) -> UUID:
    ou_type_classes = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=[facet_user_key]),
            user_keys=[class_user_key],
        )
    )

    try:
        current = one(ou_type_classes.objects).current
    except ValueError as error:
        logger.error(
            "Not exactly on class found in MO",
            facet_user_key=facet_user_key,
            class_user_key=class_user_key,
            error=error,
        )
        raise error
    assert current is not None
    return current.uuid


async def get_class_user_key(
    gql_client: GraphQLClient,
    class_uuid: UUID,
    at: datetime | None = None,
) -> str:
    classes = await gql_client.get_class(ClassFilter(uuids=[class_uuid]), at=at)

    try:
        current = one(classes.objects).current
    except ValueError as error:
        logger.error(
            "Class not found or more than one class found", class_uuid=class_uuid
        )
        raise error
    if current is None:
        return await get_class_user_key(
            gql_client=gql_client, class_uuid=class_uuid, at=datetime.now(tz=TIMEZONE)
        )

    return current.user_key


def get_association_filter(
    person: UUID, user_key: str, from_date: datetime | None, to_date: datetime | None
) -> AssociationFilter:
    return AssociationFilter(
        # TODO: check if association_type_user_keys is municipality dependent
        association_type_user_keys=["SD-medarbejder"],
        employee=EmployeeFilter(uuids=[person]),
        # NOTE: users keys are assumed unique and static. If they change we will
        # risk creating duplicate associations. Ideally, we should attach the
        # association to the engagement UUID, but in order to be backwards
        # compatible with the old SD-integration, we will use the user_key.
        user_keys=[user_key],
        from_date=from_date,
        to_date=to_date,
    )


async def get_association_timeline(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
) -> AssociationTimeline:
    gql_timeline = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )

    objects = gql_timeline.objects

    if not objects:
        return AssociationTimeline()

    logger.debug("ass", objects=objects)
    validities = one(objects, too_long=MoreThanOneAssociationError).validities

    active_intervals = tuple(
        Active(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    unit_intervals = tuple(
        EngagementSDUnit(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.org_unit_uuid,
        )
        for obj in validities
    )

    timeline = AssociationTimeline(
        association_active=Timeline[Active](
            intervals=combine_intervals(active_intervals)
        ),
        association_unit=Timeline[EngagementSDUnit](
            intervals=combine_intervals(unit_intervals)
        ),
    )
    logger.debug("MO association timeline", timeline=timeline.dict())

    return timeline


async def create_person(
    gql_client: GraphQLClient,
    cpr: str,
    givenname: str,
    lastname: str,
    dry_run: bool = False,
) -> None:
    logger.info("Create new person", cpr=cpr, givenname=givenname, lastname=lastname)

    employee_input = EmployeeCreateInput(
        cpr_number=cpr,
        given_name=givenname,
        surname=lastname,
    )
    logger.debug("Create person payload", payload=employee_input.dict())
    if not dry_run:
        await gql_client.create_person(input=employee_input)
    logger.debug("Person created", cpr=cpr)


async def update_person(
    gql_client: GraphQLClient,
    uuid: UUID,
    start: datetime,
    person: Person,
    dry_run: bool = False,
) -> None:
    logger.info("Update person")

    payload = EmployeeUpdateInput(
        uuid=uuid,
        cpr_number=person.cpr,
        given_name=person.given_name,
        surname=person.surname,
        validity=RAValidityInput(from_=start, to=None),
    )
    logger.debug("Update person payload", payload=payload.dict())
    if not dry_run:
        await gql_client.update_person(payload)
    logger.debug("Person updated", cpr=person.cpr)


def _get_related_units_endpoints(
    objects: list[GetRelatedUnitsRelatedUnitsObjects],
    start: datetime,
    end: datetime,
) -> list[datetime]:
    """
    Get the related unit endpoints timeline datetimes. E.g. in the case of dep3 having
    related units C, D and E as below, the function will return
    [t3, t4, t5, t6, t7, t8] (where t3 and t8 are the provided start and end argument,
    respectively).

    Time  --------t1--------t2----t3--t4--t5--t6--t7--t8-----t9--------------------->
    dep3          |-------------C---------|---E---|
                                      |---D---|
    """
    endpoints = set(
        collapse(
            (validity.validity.from_, _mo_end_to_timeline_end(validity.validity.to))
            for obj in objects
            for validity in obj.validities
        )
    )
    endpoints = endpoints.union({start, end})

    return sorted(endpoint for endpoint in endpoints if start <= endpoint <= end)


def _get_related_unit_at(
    objects: list[GetRelatedUnitsRelatedUnitsObjects],
    unit_uuid: OrgUnitUUID,
    at: datetime,
) -> OrgUnitUUID | None:
    """
    Get a single related unit (or None if no such unit exists) at the given time. If
    there are more than one related unit, we select the first in a list of sorted org
    unit UUIDs
    """
    related_units = sorted(
        org_unit_uuid
        for obj in objects
        for validity in obj.validities
        for org_unit_uuid in validity.org_unit_uuids
        if not org_unit_uuid == unit_uuid
        and validity.validity.from_
        <= at
        < _mo_end_to_timeline_end(validity.validity.to)
    )
    return first(related_units, default=None)


async def related_units(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
    unit_interval: EngagementUnit,
    unknown_unit_uuid: OrgUnitUUID,
) -> list[EngagementUnit]:
    """
    Returns the related units in the given interval (or the "Unknown" unit if no related
    unit can be found). Note that the input interval may be divided into smaller
    intervals.
    """
    mo_rel_units = await gql_client.get_related_units(
        RelatedUnitFilter(
            from_date=unit_interval.start,
            # This to_date is counterintuitive for this OU relation look up,
            # since the to_date is the day *after* the relation potentially
            # ends, but MO requires these dates. Especially since we are not
            # allowed to ask for an OU relation where from_date=to_date, which
            # is the case for a unit_interval lasting only for a single day.
            to_date=datetime_to_mo_end(unit_interval.end),
            org_unit=OrganisationUnitFilter(uuids=[unit_uuid]),
        )
    )

    objects = mo_rel_units.objects

    # Get the related unit interval endpoints as timeline datetimes
    endpoints = _get_related_units_endpoints(
        objects=objects, start=unit_interval.start, end=unit_interval.end
    )
    timeline_related_units = []
    for start, end in pairwise(endpoints):
        timeline_related_unit = _get_related_unit_at(
            objects=objects, unit_uuid=unit_uuid, at=start
        )
        if timeline_related_unit is None:
            timeline_related_unit = unknown_unit_uuid
        assert timeline_related_unit is not None
        timeline_related_units.append(
            EngagementUnit(
                start=start,
                end=end,
                value=timeline_related_unit,
            )
        )

    return timeline_related_units


async def create_association(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    sd_association_timeline: AssociationTimeline,
    start: datetime,
    end: datetime,
    association_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Create association",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    payload = AssociationCreateInput(
        user_key=user_key,
        person=person,
        org_unit=sd_association_timeline.association_unit.entity_at(start).value,
        association_type=association_type,
        validity=timeline_interval_to_mo_validity(start, end),
    )
    logger.debug("Create association payload", payload=payload.dict())

    if not dry_run:
        await gql_client.create_association(payload)
    logger.debug("Association created", person=str(person), user_key=user_key)


async def update_association(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    sd_association_timeline: AssociationTimeline,
    start: datetime,
    end: datetime,
    association_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Update association",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)
    logger.debug("mo_validity", mo_validity=mo_validity)

    association = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=start, to_date=end
        )
    )
    objects = association.objects
    obj = only(objects)

    if obj:
        # The association already exists in this validity period
        for validity in one(objects).validities:
            logger.debug("validity", validity=validity)
            payload = AssociationUpdateInput(
                uuid=obj.uuid,
                user_key=user_key,
                person=person,
                org_unit=sd_association_timeline.association_unit.entity_at(
                    start
                ).value,
                association_type=association_type,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
            )
            logger.debug("Update association", payload=payload.dict())
            if not dry_run:
                await gql_client.update_association(payload)
            logger.debug("Association updated", person=str(person), user_key=user_key)
        return

    # The association does not already exist in this validity period
    association = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )
    payload = AssociationUpdateInput(
        uuid=one(association.objects).uuid,
        user_key=user_key,
        person=person,
        org_unit=sd_association_timeline.association_unit.entity_at(start).value,
        association_type=association_type,
        validity=mo_validity,
    )
    logger.debug("Update association payload", payload=payload.dict())

    if not dry_run:
        await gql_client.update_association(payload)
    logger.debug("Association updated", person=str(person), user_key=user_key)


async def terminate_association(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Terminate association",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    association = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )
    association_uuid = one(association.objects).uuid

    if mo_validity.to is not None:
        payload = AssociationTerminateInput(
            uuid=association_uuid, from_=mo_validity.from_, to=mo_validity.to
        )
    else:
        payload = AssociationTerminateInput(
            uuid=association_uuid,
            # Converting from "from" to "to" due to the wierd way terminations in MO work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug("Terminate association", payload=payload.dict())

    if not dry_run:
        await gql_client.terminate_association(payload)
    logger.debug("Association terminated", person=str(person), user_key=user_key)
