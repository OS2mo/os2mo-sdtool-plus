# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
from datetime import datetime
from datetime import timedelta
from itertools import pairwise
from typing import cast
from uuid import UUID

import structlog
from more_itertools import one
from more_itertools import only
from more_itertools.more import collapse
from more_itertools.more import first

from sdtoolplus.autogenerated_graphql_client import ClassFilter
from sdtoolplus.autogenerated_graphql_client import EmployeeFilter
from sdtoolplus.autogenerated_graphql_client import EngagementCreateInput
from sdtoolplus.autogenerated_graphql_client import EngagementTerminateInput
from sdtoolplus.autogenerated_graphql_client import EngagementUpdateInput
from sdtoolplus.autogenerated_graphql_client import FacetFilter
from sdtoolplus.autogenerated_graphql_client import GetRelatedUnitsRelatedUnitsObjects
from sdtoolplus.autogenerated_graphql_client import GraphQLClientGraphQLMultiError
from sdtoolplus.autogenerated_graphql_client import LeaveCreateInput
from sdtoolplus.autogenerated_graphql_client import LeaveFilter
from sdtoolplus.autogenerated_graphql_client import LeaveTerminateInput
from sdtoolplus.autogenerated_graphql_client import LeaveUpdateInput
from sdtoolplus.autogenerated_graphql_client import OrganisationUnitCreateInput
from sdtoolplus.autogenerated_graphql_client import OrganisationUnitTerminateInput
from sdtoolplus.autogenerated_graphql_client import OrganisationUnitUpdateInput
from sdtoolplus.autogenerated_graphql_client import RAValidityInput
from sdtoolplus.autogenerated_graphql_client.input_types import AddressCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import AddressFilter
from sdtoolplus.autogenerated_graphql_client.input_types import AddressTerminateInput
from sdtoolplus.autogenerated_graphql_client.input_types import AddressUpdateInput
from sdtoolplus.autogenerated_graphql_client.input_types import AssociationCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import AssociationFilter
from sdtoolplus.autogenerated_graphql_client.input_types import (
    AssociationTerminateInput,
)
from sdtoolplus.autogenerated_graphql_client.input_types import AssociationUpdateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EmployeeCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EmployeeUpdateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EventSendInput
from sdtoolplus.autogenerated_graphql_client.input_types import OrganisationUnitFilter
from sdtoolplus.autogenerated_graphql_client.input_types import RelatedUnitFilter
from sdtoolplus.config import TIMEZONE
from sdtoolplus.depends import GraphQLClient
from sdtoolplus.exceptions import CannotProcessOrgUnitError
from sdtoolplus.exceptions import ClassNotFoundError
from sdtoolplus.exceptions import MoreThanOneAssociationError
from sdtoolplus.exceptions import MoreThanOneClassError
from sdtoolplus.exceptions import MoreThanOneEngagementError
from sdtoolplus.exceptions import MoreThanOneLeaveError
from sdtoolplus.exceptions import MoreThanOneOrgUnitError
from sdtoolplus.exceptions import MoreThanOnePhoneNumberError
from sdtoolplus.exceptions import MoreThanOnePNumberError
from sdtoolplus.exceptions import MoreThanOnePostalAddressError
from sdtoolplus.exceptions import NoValueError
from sdtoolplus.exceptions import OrgUnitNotFoundError
from sdtoolplus.mo_org_unit_importer import OrgUnitUUID
from sdtoolplus.models import POSITIVE_INFINITY
from sdtoolplus.models import Active
from sdtoolplus.models import AssociationTimeline
from sdtoolplus.models import EngagementKey
from sdtoolplus.models import EngagementName
from sdtoolplus.models import EngagementSDUnit
from sdtoolplus.models import EngagementTimeline
from sdtoolplus.models import EngagementType
from sdtoolplus.models import EngagementUnit
from sdtoolplus.models import EngagementUnitId
from sdtoolplus.models import EngType
from sdtoolplus.models import LeaveTimeline
from sdtoolplus.models import MOPhoneNumberTimelineObj
from sdtoolplus.models import MOPNumberTimelineObj
from sdtoolplus.models import MOPostalAddressTimelineObj
from sdtoolplus.models import OrgGraphQLEvent
from sdtoolplus.models import Person
from sdtoolplus.models import Timeline
from sdtoolplus.models import UnitId
from sdtoolplus.models import UnitLevel
from sdtoolplus.models import UnitName
from sdtoolplus.models import UnitParent
from sdtoolplus.models import UnitPhoneNumber
from sdtoolplus.models import UnitPNumber
from sdtoolplus.models import UnitPostalAddress
from sdtoolplus.models import UnitTimeline
from sdtoolplus.models import combine_intervals

logger = structlog.stdlib.get_logger()


def mo_end_to_datetime(mo_end: datetime | None) -> datetime:
    """
    Convert a MO end datetime or None to a datetime directly as it is in MO, i.e.
    no +/- timedelta adjustments are performed.
    """
    return mo_end if mo_end is not None else POSITIVE_INFINITY


def datetime_to_mo_end(end_datetime: datetime) -> datetime | None:
    """
    Convert a datetime to a MO end date or None directly as it is, i.e. no +/-
    timedelta adjustments are performed.
    """
    return None if end_datetime == POSITIVE_INFINITY else end_datetime


def _mo_end_to_timeline_end(mo_end: datetime | None) -> datetime:
    """
    Convert a MO end datetime to the end date required by our timeline objects.
    """
    mo_end = mo_end_to_datetime(mo_end)
    return (
        mo_end + timedelta(days=1)
        if not mo_end == POSITIVE_INFINITY
        else POSITIVE_INFINITY
    )


def timeline_interval_to_mo_validity(start: datetime, end: datetime) -> RAValidityInput:
    mo_end = datetime_to_mo_end(end)
    # Subtract one day due to MO
    mo_end = mo_end - timedelta(days=1) if mo_end is not None else None
    return RAValidityInput(from_=start, to=mo_end)


def get_patch_validity(
    codegen_validity_from: datetime,
    codegen_validity_to: datetime | None,
    mo_validity: RAValidityInput,
) -> RAValidityInput:
    """
    Get the validity for which the patch update should be performed. We need to truncate
    it with the timeline (start, end) endpoint update validities in order not to write
    beyond these in MO for the particular patch operation.
    """
    codegen_validity_to_datetime = mo_end_to_datetime(codegen_validity_to)
    mo_validity_to = mo_end_to_datetime(mo_validity.to)

    patch_validity_from = max(codegen_validity_from, mo_validity.from_)
    patch_validity_to = min(codegen_validity_to_datetime, mo_validity_to)

    return RAValidityInput(
        from_=patch_validity_from,
        to=None if patch_validity_to is POSITIVE_INFINITY else patch_validity_to,
    )


async def get_class(
    gql_client: GraphQLClient,
    facet_user_key: str,
    class_user_key: str,
) -> UUID:
    ou_type_classes = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=[facet_user_key]),
            user_keys=[class_user_key],
        )
    )

    current = one(
        ou_type_classes.objects,
        too_short=ClassNotFoundError,
        too_long=MoreThanOneClassError,
    ).current
    assert current is not None
    return current.uuid


async def get_class_user_key(
    gql_client: GraphQLClient,
    class_uuid: UUID,
    at: datetime | None = None,
) -> str:
    classes = await gql_client.get_class(ClassFilter(uuids=[class_uuid]), at=at)

    try:
        current = one(classes.objects).current
    except ValueError as error:
        logger.error(
            "Class not found or more than one class found", class_uuid=class_uuid
        )
        raise error
    if current is None:
        return await get_class_user_key(
            gql_client=gql_client, class_uuid=class_uuid, at=datetime.now(tz=TIMEZONE)
        )

    return current.user_key


async def get_engagement_types(gql_client: GraphQLClient) -> dict[EngType, UUID]:
    """
    Get map from engagement type (Enum) to MO engagement type class UUID
    """
    r_eng_types = await gql_client.get_class(
        ClassFilter(facet=FacetFilter(user_keys=["engagement_type"]))
    )

    relevant_classes = (
        obj.current
        for obj in r_eng_types.objects
        if obj.current is not None
        and obj.current.user_key in (eng_type.value for eng_type in EngType)
    )

    return {EngType(clazz.user_key): clazz.uuid for clazz in relevant_classes}


def get_association_filter(
    person: UUID, user_key: str, from_date: datetime | None, to_date: datetime | None
) -> AssociationFilter:
    return AssociationFilter(
        # TODO: check if association_type_user_keys is municipality dependent
        association_type_user_keys=["SD-medarbejder"],
        employee=EmployeeFilter(uuids=[person]),
        # NOTE: users keys are assumed unique and static. If they change we will
        # risk creating duplicate associations. Ideally, we should attach the
        # association to the engagement UUID, but in order to be backwards
        # compatible with the old SD-integration, we will use the user_key.
        user_keys=[user_key],
        from_date=from_date,
        to_date=to_date,
    )


async def get_ou_timeline(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
) -> UnitTimeline:
    logger.info("Get MO org unit timeline", unit_uuid=str(unit_uuid))

    gql_timelime = await gql_client.get_org_unit_timeline(
        unit_uuid=unit_uuid, from_date=None, to_date=None
    )
    objects = gql_timelime.objects

    if not objects:
        logger.debug("MO OU timeline is empty")
        return UnitTimeline()

    validities = one(
        objects,
        too_short=OrgUnitNotFoundError,
        too_long=MoreThanOneOrgUnitError,
    ).validities

    activity_intervals = tuple(
        Active(
            start=obj.validity.from_,
            # TODO (#61435): MOs GraphQL subtracts one day from the validity end dates
            # when reading, compared to what was written.
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    id_intervals = tuple(
        UnitId(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.user_key,
        )
        for obj in validities
    )

    level_intervals = tuple(
        UnitLevel(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.org_unit_level.name if obj.org_unit_level is not None else None,
        )
        for obj in validities
    )

    name_intervals = tuple(
        UnitName(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.name,
        )
        for obj in validities
    )

    parent_intervals = tuple(
        UnitParent(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.parent_uuid,
        )
        for obj in validities
    )

    timeline = UnitTimeline(
        active=Timeline[Active](intervals=combine_intervals(activity_intervals)),
        name=Timeline[UnitName](intervals=combine_intervals(name_intervals)),
        unit_id=Timeline[UnitId](intervals=combine_intervals(id_intervals)),
        unit_level=Timeline[UnitLevel](intervals=combine_intervals(level_intervals)),
        parent=Timeline[UnitParent](intervals=combine_intervals(parent_intervals)),
    )
    logger.debug("MO OU timeline", timeline=timeline.dict())

    return timeline


async def get_pnumber_timeline(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
) -> MOPNumberTimelineObj:
    logger.info("Get MO P-number timeline", org_unit=str(unit_uuid))

    gql_timeline = await gql_client.get_address_timeline(
        AddressFilter(
            org_unit=OrganisationUnitFilter(uuids=[unit_uuid]),
            address_type=ClassFilter(
                facet=FacetFilter(user_keys=["org_unit_address_type"]),
                user_keys=["P-nummer"],  # TODO: check if this may be region specific
            ),
            from_date=None,
            to_date=None,
        )
    )

    objects = gql_timeline.objects

    if not objects:
        logger.debug("MO P-number timeline is empty")
        return MOPNumberTimelineObj(uuid=None, pnumber=Timeline[UnitPNumber]())

    object_ = one(objects, too_long=MoreThanOnePNumberError)

    timeline = MOPNumberTimelineObj(
        uuid=object_.uuid,
        pnumber=Timeline[UnitPNumber](
            intervals=combine_intervals(
                tuple(
                    UnitPNumber(
                        start=obj.validity.from_,
                        end=_mo_end_to_timeline_end(obj.validity.to),
                        value=obj.value,
                    )
                    for obj in object_.validities
                )
            )
        ),
    )
    logger.debug("MO P-number timeline", timeline=timeline.dict())

    return timeline


async def get_postal_address_timeline(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
) -> MOPostalAddressTimelineObj:
    logger.info("Get MO postal address timeline", org_unit=str(unit_uuid))

    gql_timeline = await gql_client.get_address_timeline(
        AddressFilter(
            org_unit=OrganisationUnitFilter(uuids=[unit_uuid]),
            address_type=ClassFilter(
                facet=FacetFilter(user_keys=["org_unit_address_type"]),
                # TODO: use both keys for now as it has changed in the APOS importer?
                # TODO: handle the municipality case
                user_keys=["AdresseAPOSOrgUnit", "AdresseSDOrgUnit"],
            ),
            from_date=None,
            to_date=None,
        )
    )

    objects = gql_timeline.objects

    if not objects:
        logger.debug("MO postal address timeline is empty")
        return MOPostalAddressTimelineObj(
            uuid=None, pnumber=Timeline[UnitPostalAddress]()
        )

    object_ = one(objects, too_long=MoreThanOnePostalAddressError)

    timeline = MOPostalAddressTimelineObj(
        uuid=object_.uuid,
        postal_address=Timeline[UnitPostalAddress](
            intervals=combine_intervals(
                tuple(
                    UnitPostalAddress(
                        start=obj.validity.from_,
                        end=_mo_end_to_timeline_end(obj.validity.to),
                        value=obj.value,
                    )
                    for obj in object_.validities
                )
            )
        ),
    )
    logger.debug("MO postal address timeline", timeline=timeline.dict())

    return timeline


async def get_phone_number_timeline(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
) -> MOPhoneNumberTimelineObj:
    logger.info("Get MO phone number timeline", org_unit=str(unit_uuid))

    gql_timeline = await gql_client.get_address_timeline(
        AddressFilter(
            org_unit=OrganisationUnitFilter(uuids=[unit_uuid]),
            address_type=ClassFilter(
                facet=FacetFilter(user_keys=["org_unit_address_type"]),
                # TODO: handle the municipality case
                user_keys=["lokation_telefon_lokal"],
            ),
            from_date=None,
            to_date=None,
        )
    )

    objects = gql_timeline.objects

    if not objects:
        logger.debug("MO phone number timeline is empty")
        return MOPhoneNumberTimelineObj(uuid=None, pnumber=Timeline[UnitPhoneNumber]())

    object_ = one(objects, too_long=MoreThanOnePhoneNumberError)

    timeline = MOPhoneNumberTimelineObj(
        uuid=object_.uuid,
        phone_number=Timeline[UnitPhoneNumber](
            intervals=combine_intervals(
                tuple(
                    UnitPhoneNumber(
                        start=obj.validity.from_,
                        end=_mo_end_to_timeline_end(obj.validity.to),
                        value=obj.value,
                    )
                    for obj in object_.validities
                )
            )
        ),
    )
    logger.debug("MO phone number timeline", timeline=timeline.dict())

    return timeline


async def _queue_ou_parent(
    gql_client: GraphQLClient,
    parent: OrgUnitUUID,
    institution_identifier: str,
    priority: int,
) -> None:
    logger.debug("Queuing OU parent", parent=str(parent))
    await gql_client.send_event(
        input=EventSendInput(
            namespace="sd",
            routing_key="org",
            subject=OrgGraphQLEvent(
                institution_identifier=institution_identifier,
                org_unit=parent,
            ).json(),
            priority=priority,
        )
    )


async def create_ou(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    start: datetime,
    end: datetime,
    desired_unit_timeline: UnitTimeline,
    org_unit_type_user_key: str,
    institution_identifier: str,
    priority: int,
    dry_run: bool = False,
) -> None:
    logger.info("Creating OU", uuid=str(org_unit))
    logger.debug(
        "Creating OU",
        start=start,
        end=end,
        desired_unit_timeline=desired_unit_timeline.dict(),
    )

    # Get the OU type UUID
    ou_type_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_type",
        class_user_key=org_unit_type_user_key,
    )

    # Get the OU level UUID
    unit_level = desired_unit_timeline.unit_level.entity_at(start)
    ou_level_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_level",
        class_user_key=unit_level.value,  # type: ignore
    )

    parent = cast(OrgUnitUUID, desired_unit_timeline.parent.entity_at(start).value)

    payload = OrganisationUnitCreateInput(
        uuid=org_unit,
        validity=timeline_interval_to_mo_validity(start, end),
        name=desired_unit_timeline.name.entity_at(start).value,
        user_key=desired_unit_timeline.unit_id.entity_at(start).value,
        parent=parent,
        org_unit_type=ou_type_uuid,
        org_unit_level=ou_level_uuid,
    )
    logger.debug("OU create payload", payload=payload.dict())
    if not dry_run:
        try:
            await gql_client.create_org_unit(payload)
        except GraphQLClientGraphQLMultiError as error:
            mo_error = str(one(error.errors))
            if mo_error not in [
                "ErrorCodes.V_DATE_OUTSIDE_ORG_UNIT_RANGE",
                "ErrorCodes.E_ORG_UNIT_NOT_FOUND",
            ]:
                raise error

            queue_priority = priority - 1
            logger.error(
                "Cannot create unit due to a MO error. Queuing parent",
                org_unit=str(org_unit),
                parent=parent,
                start=start,
                end=end,
                priority=queue_priority,
            )
            await _queue_ou_parent(
                gql_client=gql_client,
                parent=parent,
                institution_identifier=institution_identifier,
                priority=queue_priority,
            )
            raise CannotProcessOrgUnitError()

    logger.debug("OU created", uuid=str(org_unit))


async def update_ou(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    start: datetime,
    end: datetime,
    desired_unit_timeline: UnitTimeline,
    org_unit_type_user_key: str,
    institution_identifier: str,
    priority: int,
    dry_run: bool = False,
) -> None:
    logger.info("Updating OU", uuid=str(org_unit))
    logger.debug(
        "Updating OU",
        start=start,
        end=end,
        desired_unit_timeline=desired_unit_timeline.dict(),
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)
    # TODO: refactor get_org_unit_timeline to take a RAValidityInput object instead of
    # start and end dates
    ou = await gql_client.get_org_unit_timeline(
        org_unit, mo_validity.from_, mo_validity.to
    )

    # Get the OU type UUID
    ou_type_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_type",
        class_user_key=org_unit_type_user_key,
    )

    # Get the OU level UUID
    unit_level = desired_unit_timeline.unit_level.entity_at(start)
    ou_level_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_level",
        class_user_key=unit_level.value,  # type: ignore
    )

    parent = cast(OrgUnitUUID, desired_unit_timeline.parent.entity_at(start).value)

    if ou.objects:
        # The OU already exists in this validity period
        for validity in one(ou.objects).validities:
            payload = OrganisationUnitUpdateInput(
                uuid=org_unit,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
                name=desired_unit_timeline.name.entity_at(start).value,
                user_key=desired_unit_timeline.unit_id.entity_at(start).value,
                parent=parent,
                org_unit_type=ou_type_uuid,
                org_unit_level=ou_level_uuid,
                org_unit_hierarchy=validity.org_unit_hierarchy,
                time_planning=validity.time_planning_uuid,
            )
            logger.debug("OU update payload", payload=payload.dict())
            if not dry_run:
                try:
                    await gql_client.update_org_unit(payload)
                except GraphQLClientGraphQLMultiError as error:
                    mo_error = str(one(error.errors))
                    if mo_error not in [
                        "ErrorCodes.V_DATE_OUTSIDE_ORG_UNIT_RANGE",
                        "ErrorCodes.E_ORG_UNIT_NOT_FOUND",
                    ]:
                        raise error

                    queue_priority = priority - 1
                    logger.error(
                        "Cannot update unit due to MO error. Queuing parent",
                        org_unit=str(org_unit),
                        parent=parent,
                        start=start,
                        end=end,
                        priority=queue_priority,
                        mo_error=mo_error,
                    )
                    await _queue_ou_parent(
                        gql_client=gql_client,
                        parent=parent,
                        institution_identifier=institution_identifier,
                        priority=queue_priority,
                    )
                    raise CannotProcessOrgUnitError()

            logger.debug("OU updated", uuid=str(org_unit))
        return

    # The OU does not already exist in this validity period
    payload = OrganisationUnitUpdateInput(
        uuid=org_unit,
        validity=mo_validity,
        name=desired_unit_timeline.name.entity_at(start).value,
        user_key=desired_unit_timeline.unit_id.entity_at(start).value,
        parent=parent,
        org_unit_type=ou_type_uuid,
        org_unit_level=ou_level_uuid,
    )
    logger.debug("OU update payload", payload=payload.dict())
    if not dry_run:
        try:
            await gql_client.update_org_unit(payload)
        except GraphQLClientGraphQLMultiError as error:
            mo_error = str(one(error.errors))
            if mo_error not in [
                "ErrorCodes.V_DATE_OUTSIDE_ORG_UNIT_RANGE",
                "ErrorCodes.E_ORG_UNIT_NOT_FOUND",
            ]:
                raise error

            queue_priority = priority - 1
            logger.error(
                "Cannot update unit due to MO error. Queuing parent",
                org_unit=str(org_unit),
                parent=parent,
                start=start,
                end=end,
                priority=queue_priority,
                mo_error=mo_error,
            )
            await _queue_ou_parent(
                gql_client=gql_client,
                parent=parent,
                institution_identifier=institution_identifier,
                priority=queue_priority,
            )
            raise CannotProcessOrgUnitError()

    logger.debug("OU updated", uuid=str(org_unit))


async def _queue_ou_children(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    mo_validity: RAValidityInput,
    institution_identifier: str,
    priority: int,
) -> None:
    ou = await gql_client.get_org_unit_children(
        org_unit=org_unit, from_date=mo_validity.from_, to_date=mo_validity.to
    )

    child_uuids = [child.uuid for child in ou.objects]

    for child_uuid in child_uuids:
        logger.debug("Queuing OU child", child_uuid=str(child_uuid))
        await gql_client.send_event(
            input=EventSendInput(
                namespace="sd",
                routing_key="org",
                subject=OrgGraphQLEvent(
                    institution_identifier=institution_identifier,
                    org_unit=child_uuid,
                ).json(),
                priority=priority,
            )
        )


async def terminate_ou(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    start: datetime,
    end: datetime,
    institution_identifier: str,
    priority: int,
    dry_run: bool = False,
) -> None:
    logger.info("Terminate OU", org_unit=str(org_unit), start=start, end=end)
    if end - start <= timedelta(days=1):
        # Necessary due to https://redmine.magenta.dk/issues/65130
        logger.error(
            "Cannot terminate unit in an interval shorter than one day due to MO"
        )
        return

    mo_validity = timeline_interval_to_mo_validity(start, end)

    # Temporary work-around: get addresses to terminate if any
    mo_unit = await gql_client.get_org_unit_timeline(
        unit_uuid=org_unit,
        from_date=mo_validity.from_,
        to_date=mo_validity.to,
    )

    if mo_validity.to is not None:
        addr_term_payloads = [
            AddressTerminateInput(
                uuid=address.uuid,
                from_=mo_validity.from_,
                to=mo_validity.to,
            )
            for validity in one(mo_unit.objects).validities
            for address in validity.addresses
        ]
        payload = OrganisationUnitTerminateInput(
            uuid=org_unit,
            from_=mo_validity.from_,
            to=mo_validity.to,
        )
    else:
        addr_term_payloads = [
            AddressTerminateInput(
                uuid=address.uuid,
                # Converting from "from" to "to" due to the wierd way terminations in MO
                # work
                to=mo_validity.from_ - timedelta(days=1),
            )
            for validity in one(mo_unit.objects).validities
            for address in validity.addresses
        ]
        payload = OrganisationUnitTerminateInput(
            uuid=org_unit,
            # Converting from "from" to "to" due to the wierd way terminations in MO
            # work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug(
        "OU address termination payloads",
        payloads=[payload.dict() for payload in addr_term_payloads],
    )
    logger.debug("OU terminate payload", payload=payload.dict())
    if not dry_run:
        for addr_term_payload in addr_term_payloads:
            await gql_client.terminate_address(addr_term_payload)
        try:
            await gql_client.terminate_org_unit(payload)
        except GraphQLClientGraphQLMultiError as error:
            if (
                not str(one(error.errors))
                == "ErrorCodes.V_TERMINATE_UNIT_WITH_CHILDREN"
            ):
                raise error

            queue_priority = priority - 1
            logger.error(
                "Cannot terminate unit due to active child units. Queuing children",
                org_unit=str(org_unit),
                start=start,
                end=end,
                priority=queue_priority,
            )
            await _queue_ou_children(
                gql_client=gql_client,
                org_unit=org_unit,
                mo_validity=mo_validity,
                institution_identifier=institution_identifier,
                priority=queue_priority,
            )
            raise CannotProcessOrgUnitError()

    logger.debug("OU terminated", org_unit=str(org_unit))


async def get_engagement_timeline(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
) -> EngagementTimeline:
    logger.info("Get MO engagement timeline", person=str(person), emp_id=user_key)

    gql_timeline = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=None, to_date=None
    )
    objects = gql_timeline.objects

    if not objects:
        return EngagementTimeline()

    object_ = one(objects, too_long=MoreThanOneEngagementError)
    validities = object_.validities

    # Make sure we only look up each class once in MO for this time calculation
    class_uuid_to_user_key: dict[UUID, str] = dict()

    activity_intervals = tuple(
        Active(
            start=obj.validity.from_,
            # TODO (#61435): MOs GraphQL subtracts one day from the validity end dates
            # when reading, compared to what was written.
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    key_intervals = []
    for obj in validities:
        job_function_user_key = await get_class_user_key(
            gql_client=gql_client,
            class_uuid=obj.job_function_uuid,
            at=obj.validity.from_,
        )
        key_intervals.append(
            EngagementKey(
                start=obj.validity.from_,
                end=_mo_end_to_timeline_end(obj.validity.to),
                value=job_function_user_key,
            )
        )

    name_intervals = tuple(
        EngagementName(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            # TODO: introduce name strategy here
            value=obj.extension_1,
        )
        for obj in validities
    )

    unit_intervals = tuple(
        EngagementUnit(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.org_unit_uuid,
        )
        for obj in validities
    )

    sd_unit_intervals = tuple(
        EngagementSDUnit(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.extension_5,
        )
        for obj in validities
    )

    unit_id_intervals = tuple(
        EngagementUnitId(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.extension_4,
        )
        for obj in validities
    )

    type_intervals = []
    for obj in validities:
        type_user_key = class_uuid_to_user_key.get(obj.engagement_type_uuid)
        if type_user_key is None:
            type_user_key = await get_class_user_key(
                gql_client=gql_client, class_uuid=obj.engagement_type_uuid
            )
        type_intervals.append(
            EngagementType(
                start=obj.validity.from_,
                end=_mo_end_to_timeline_end(obj.validity.to),
                value=EngType(type_user_key),
            )
        )

    timeline = EngagementTimeline(
        eng_active=Timeline[Active](intervals=combine_intervals(activity_intervals)),
        eng_key=Timeline[EngagementKey](
            intervals=combine_intervals(tuple(key_intervals))
        ),
        eng_name=Timeline[EngagementName](intervals=combine_intervals(name_intervals)),
        eng_unit=Timeline[EngagementUnit](intervals=combine_intervals(unit_intervals)),
        eng_sd_unit=Timeline[EngagementSDUnit](
            intervals=combine_intervals(sd_unit_intervals)
        ),
        eng_unit_id=Timeline[EngagementUnitId](
            intervals=combine_intervals(unit_id_intervals)
        ),
        eng_type=Timeline[EngagementType](
            intervals=combine_intervals(tuple(type_intervals))
        ),
    )
    logger.debug("MO engagement timeline", timeline=timeline.dict())

    return timeline


async def get_leave_timeline(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
) -> LeaveTimeline:
    gql_timeline = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=None,
            to_date=None,
        )
    )
    objects = gql_timeline.objects

    if not objects:
        return LeaveTimeline()

    validities = one(objects, too_long=MoreThanOneLeaveError).validities

    active_intervals = tuple(
        Active(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    timeline = LeaveTimeline(
        leave_active=Timeline[Active](intervals=combine_intervals(active_intervals)),
    )
    logger.debug("MO leave timeline", timeline=timeline.dict())

    return timeline


async def get_association_timeline(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
) -> AssociationTimeline:
    gql_timeline = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )

    objects = gql_timeline.objects

    if not objects:
        return AssociationTimeline()

    logger.debug("ass", objects=objects)
    validities = one(objects, too_long=MoreThanOneAssociationError).validities

    active_intervals = tuple(
        Active(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    unit_intervals = tuple(
        EngagementSDUnit(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.org_unit_uuid,
        )
        for obj in validities
    )

    timeline = AssociationTimeline(
        association_active=Timeline[Active](
            intervals=combine_intervals(active_intervals)
        ),
        association_unit=Timeline[EngagementSDUnit](
            intervals=combine_intervals(unit_intervals)
        ),
    )
    logger.debug("MO association timeline", timeline=timeline.dict())

    return timeline


async def create_engagement(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    desired_eng_timeline: EngagementTimeline,
    eng_types: dict[EngType, UUID],
    dry_run: bool = False,
) -> None:
    logger.info("Creating engagement", person=str(person), emp_id=user_key)
    logger.debug(
        "Creating engagement",
        start=start,
        end=end,
        desired_eng_timeline=desired_eng_timeline.dict(),
    )

    # Get the job_function
    r_job_function = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=["engagement_job_function"]),
            user_keys=[str(desired_eng_timeline.eng_key.entity_at(start).value)],
            # The scope is the JobPositionLevelCode, and employments in SD
            # always refer to JobPositions at level 0.
            scope=["0"],
        )
    )
    current_job_function = one(
        r_job_function.objects,
        too_short=ClassNotFoundError,
        too_long=MoreThanOneClassError,
    ).current
    assert current_job_function is not None
    job_function_uuid = current_job_function.uuid

    payload = EngagementCreateInput(
        user_key=user_key,
        validity=timeline_interval_to_mo_validity(start, end),
        extension_1=desired_eng_timeline.eng_name.entity_at(start).value,
        extension_4=desired_eng_timeline.eng_unit_id.entity_at(start).value,
        extension_5=str(desired_eng_timeline.eng_sd_unit.entity_at(start).value),
        person=person,
        org_unit=desired_eng_timeline.eng_unit.entity_at(start).value,
        engagement_type=eng_types[
            desired_eng_timeline.eng_type.entity_at(start).value  # type: ignore
        ],
        # TODO: introduce job_function strategy
        job_function=job_function_uuid,
    )
    logger.debug("Create engagement payload", payload=payload.dict())
    if not dry_run:
        await gql_client.create_engagement(payload)
    logger.debug("Engagement created", person=str(person), emp_id=user_key)


async def create_person(
    gql_client: GraphQLClient,
    cpr: str,
    givenname: str,
    lastname: str,
    dry_run: bool = False,
) -> None:
    logger.info("Create new person", cpr=cpr, givenname=givenname, lastname=lastname)

    employee_input = EmployeeCreateInput(
        cpr_number=cpr,
        given_name=givenname,
        surname=lastname,
    )
    logger.debug("Create person payload", payload=employee_input.dict())
    if not dry_run:
        await gql_client.create_person(input=employee_input)
    logger.debug("Person created", cpr=cpr)


async def update_person(
    gql_client: GraphQLClient,
    uuid: UUID,
    start: datetime,
    person: Person,
    dry_run: bool = False,
) -> None:
    logger.info("Update person")

    payload = EmployeeUpdateInput(
        uuid=uuid,
        cpr_number=person.cpr,
        given_name=person.given_name,
        surname=person.surname,
        validity=RAValidityInput(from_=start, to=None),
    )
    logger.debug("Update person payload", payload=payload.dict())
    if not dry_run:
        await gql_client.update_person(payload)
    logger.debug("Person updated", cpr=person.cpr)


async def create_leave(
    gql_client: GraphQLClient,
    person: UUID,
    eng_uuid: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    sd_leave_timeline: LeaveTimeline,
    leave_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info("Create leave", person=str(person), user_key=user_key)
    logger.debug(
        "Create leave", start=start, end=end, sd_leave_timeline=sd_leave_timeline.dict()
    )

    payload = LeaveCreateInput(
        user_key=user_key,
        person=person,
        engagement=eng_uuid,
        leave_type=leave_type,
        validity=timeline_interval_to_mo_validity(start, end),
    )
    logger.debug("Create leave payload", payload=payload.dict())

    if not dry_run:
        await gql_client.create_leave(payload)
    logger.debug("Leave created", person=str(person), user_key=user_key)


async def update_engagement(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    desired_eng_timeline: EngagementTimeline,
    eng_types: dict[EngType, UUID],
    dry_run: bool = False,
) -> None:
    logger.info("Update engagement", person=str(person), emp_id=user_key)
    logger.debug(
        "Update engagement",
        start=start,
        end=end,
        desired_eng_timeline=desired_eng_timeline.dict(),
    )

    # Get the job_function
    r_job_function = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=["engagement_job_function"]),
            user_keys=[str(desired_eng_timeline.eng_key.entity_at(start).value)],
            # The scope is the JobPositionLevelCode, and employments in SD
            # always refer to JobPositions at level 0.
            scope=["0"],
        )
    )
    current_job_function = one(
        r_job_function.objects,
        too_short=ClassNotFoundError,
        too_long=MoreThanOneClassError,
    ).current
    assert current_job_function is not None
    job_function_uuid = current_job_function.uuid

    mo_validity = timeline_interval_to_mo_validity(start, end)

    eng = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=start, to_date=end
    )
    obj = only(eng.objects)

    if obj:
        # The engagement already exists in this validity period
        for validity in one(eng.objects).validities:
            eng_name = desired_eng_timeline.eng_name.entity_at(start).value
            payload = EngagementUpdateInput(
                uuid=obj.uuid,
                user_key=user_key,
                primary=validity.primary_uuid,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
                # The empty string will be converted to null in the LoRa DB. Update
                # logic when https://redmine.magenta.dk/issues/65028 has been fixed.
                extension_1=eng_name if eng_name is not None else "",
                extension_2=validity.extension_2,
                extension_3=validity.extension_3,
                extension_4=desired_eng_timeline.eng_unit_id.entity_at(start).value,
                extension_5=str(
                    desired_eng_timeline.eng_sd_unit.entity_at(start).value
                ),
                extension_6=validity.extension_6,
                extension_7=validity.extension_7,
                extension_8=validity.extension_8,
                extension_9=validity.extension_9,
                extension_10=validity.extension_10,
                person=person,
                org_unit=desired_eng_timeline.eng_unit.entity_at(start).value,
                engagement_type=eng_types[
                    desired_eng_timeline.eng_type.entity_at(start).value  # type: ignore
                ],
                job_function=job_function_uuid,
            )
            logger.debug(
                "Update engagement in validity interval",
                payload=payload.dict(),
                validity=validity,
            )
            if not dry_run:
                await gql_client.update_engagement(payload)
            logger.debug("Engagement updated", person=str(person), emp_id=user_key)
        return

    # The engagement does not already exist in this validity period
    eng = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=None, to_date=None
    )
    payload = EngagementUpdateInput(
        uuid=one(eng.objects).uuid,
        user_key=user_key,
        validity=mo_validity,
        # TODO: introduce extention_1 strategy
        extension_1=desired_eng_timeline.eng_name.entity_at(start).value,
        extension_4=desired_eng_timeline.eng_unit_id.entity_at(start).value,
        extension_5=str(desired_eng_timeline.eng_sd_unit.entity_at(start).value),
        person=person,
        org_unit=desired_eng_timeline.eng_unit.entity_at(start).value,
        engagement_type=eng_types[desired_eng_timeline.eng_type.entity_at(start).value],  # type: ignore
        job_function=job_function_uuid,
    )
    logger.debug(
        "Update engagement in interval", payload=payload.dict(), mo_validity=mo_validity
    )
    if not dry_run:
        await gql_client.update_engagement(payload)
    logger.debug("Engagement updated", person=str(person), emp_id=user_key)


async def update_leave(
    gql_client: GraphQLClient,
    person: UUID,
    eng_uuid: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    sd_leave_timeline: LeaveTimeline,
    leave_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info("Update leave", person=str(person), user_key=user_key)
    logger.debug(
        "Update leave", start=start, end=end, sd_leave_timeline=sd_leave_timeline.dict()
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    leave = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=start,
            to_date=end,
        )
    )
    objects = leave.objects
    obj = only(objects)

    if obj:
        # The leave already exists in this validity period
        for validity in one(objects).validities:
            payload = LeaveUpdateInput(
                uuid=obj.uuid,
                user_key=user_key,
                person=person,
                engagement=eng_uuid,
                leave_type=leave_type,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
            )
            logger.debug("Update leave", payload=payload.dict())
            if not dry_run:
                await gql_client.update_leave(payload)
            logger.debug("Leave updated", person=str(person), user_key=user_key)
        return

    # The leave does not already exist in this validity period
    leave = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=None,
            to_date=None,
        )
    )
    payload = LeaveUpdateInput(
        uuid=one(leave.objects).uuid,
        user_key=user_key,
        person=person,
        engagement=eng_uuid,
        leave_type=leave_type,
        validity=mo_validity,
    )
    logger.debug("Update leave payload", payload=payload.dict())

    if not dry_run:
        await gql_client.update_leave(payload)
    logger.debug("Leave updated", person=str(person), user_key=user_key)


async def terminate_engagement(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Terminate engagement",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    eng = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=None, to_date=None
    )
    eng_uuid = one(eng.objects).uuid

    if mo_validity.to is not None:
        payload = EngagementTerminateInput(
            uuid=eng_uuid, from_=mo_validity.from_, to=mo_validity.to
        )
    else:
        payload = EngagementTerminateInput(
            uuid=eng_uuid,
            # Converting from "from" to "to" due to the wierd way terminations in MO work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug("Terminate engagement", payload=payload.dict())

    if not dry_run:
        await gql_client.terminate_engagement(payload)
    logger.debug("Engagement terminated", person=str(person), user_key=user_key)


async def terminate_leave(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Terminate leave",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    leave = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=None,
            to_date=None,
        )
    )
    leave_uuid = one(leave.objects).uuid

    if mo_validity.to is not None:
        payload = LeaveTerminateInput(
            uuid=leave_uuid, from_=mo_validity.from_, to=mo_validity.to
        )
    else:
        payload = LeaveTerminateInput(
            uuid=leave_uuid,
            # Converting from "from" to "to" due to the wierd way terminations in MO work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug("Terminate leave", payload=payload.dict())

    if not dry_run:
        await gql_client.terminate_leave(payload)
    logger.debug("Leave terminated", person=str(person), user_key=user_key)


async def terminate_leave_before_engagement_termination(
    gql_client: GraphQLClient,
    eng_term_start: datetime,
    eng_term_end: datetime,
    mo_leave_timeline: LeaveTimeline,
    person: UUID,
    user_key: str,
) -> None:
    logger.debug(
        "Terminate leave prior to engagement termination",
        person=str(person),
        user_key=user_key,
        eng_term_start=eng_term_start,
        eng_term_end=eng_term_end,
    )

    endpoints = sorted(
        mo_leave_timeline.get_interval_endpoints().union({eng_term_start, eng_term_end})
    )
    endpoints = [
        endpoint for endpoint in endpoints if eng_term_start <= endpoint <= eng_term_end
    ]

    for start, end in pairwise(endpoints):
        try:
            mo_leave_timeline.leave_active.entity_at(start)
        except NoValueError:
            logger.debug(
                "No leave to terminate in this interval",
                person=str(person),
                user_key=user_key,
                start=start,
                end=end,
            )
            continue
        await terminate_leave(
            gql_client=gql_client,
            person=person,
            user_key=user_key,
            start=start,
            end=end,
        )
        logger.debug(
            "Terminated leave prior to engagement termination",
            person=str(person),
            user_key=user_key,
            start=start,
            end=end,
        )


def _get_related_units_endpoints(
    objects: list[GetRelatedUnitsRelatedUnitsObjects],
    start: datetime,
    end: datetime,
) -> list[datetime]:
    """
    Get the related unit endpoints timeline datetimes. E.g. in the case of dep3 having
    related units C, D and E as below, the function will return
    [t3, t4, t5, t6, t7, t8] (where t3 and t8 are the provided start and end argument,
    respectively).

    Time  --------t1--------t2----t3--t4--t5--t6--t7--t8-----t9--------------------->
    dep3          |-------------C---------|---E---|
                                      |---D---|
    """
    endpoints = set(
        collapse(
            (validity.validity.from_, _mo_end_to_timeline_end(validity.validity.to))
            for obj in objects
            for validity in obj.validities
        )
    )
    endpoints = endpoints.union({start, end})

    return sorted(endpoint for endpoint in endpoints if start <= endpoint <= end)


def _get_related_unit_at(
    objects: list[GetRelatedUnitsRelatedUnitsObjects],
    unit_uuid: OrgUnitUUID,
    at: datetime,
) -> OrgUnitUUID | None:
    """
    Get a single related unit (or None if no such unit exists) at the given time. If
    there are more than one related unit, we select the first in a list of sorted org
    unit UUIDs
    """
    related_units = sorted(
        org_unit_uuid
        for obj in objects
        for validity in obj.validities
        for org_unit_uuid in validity.org_unit_uuids
        if not org_unit_uuid == unit_uuid
        and validity.validity.from_
        <= at
        < _mo_end_to_timeline_end(validity.validity.to)
    )
    return first(related_units, default=None)


async def related_units(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
    unit_interval: EngagementUnit,
    unknown_unit_uuid: OrgUnitUUID,
) -> list[EngagementUnit]:
    """
    Returns the related units in the given interval (or the "Unknown" unit if no related
    unit can be found). Note that the input interval may be divided into smaller
    intervals.
    """
    mo_validity = timeline_interval_to_mo_validity(
        unit_interval.start, unit_interval.end
    )

    mo_rel_units = await gql_client.get_related_units(
        RelatedUnitFilter(
            from_date=mo_validity.from_,
            to_date=mo_validity.to,
            org_unit=OrganisationUnitFilter(uuids=[unit_uuid]),
        )
    )

    objects = mo_rel_units.objects

    # Get the related unit interval endpoints as timeline datetimes
    endpoints = _get_related_units_endpoints(
        objects=objects, start=unit_interval.start, end=unit_interval.end
    )
    timeline_related_units = []
    for start, end in pairwise(endpoints):
        timeline_related_unit = _get_related_unit_at(
            objects=objects, unit_uuid=unit_uuid, at=start
        )
        if timeline_related_unit is None:
            timeline_related_unit = unknown_unit_uuid
        assert timeline_related_unit is not None
        timeline_related_units.append(
            EngagementUnit(
                start=start,
                end=end,
                value=timeline_related_unit,
            )
        )

    return timeline_related_units


async def delete_address(
    gql_client: GraphQLClient, address_uuid: UUID, dry_run: bool
) -> None:
    logger.debug("Delete address in MO", addr_uuid=str(address_uuid))
    if not dry_run:
        await gql_client.delete_address(address_uuid)


async def create_pnumber_address(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    address_uuid: UUID | None,
    sd_pnumber_timeline: Timeline[UnitPNumber],
    dry_run: bool,
) -> None:
    logger.debug("Create P-number in MO", pnumber_timeline=sd_pnumber_timeline.dict())

    # Get the address visibility UUID
    visibility_class_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="visibility",
        # TODO: handle required variability in municipality mode
        class_user_key="Public",
    )

    # Get the P-number address type
    p_number_address_type_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_address_type",
        # TODO: use correct class user_key in municipality mode
        class_user_key="P-nummer",
    )

    first_sd_pnumber = first(sd_pnumber_timeline.intervals)
    create_address_payload = AddressCreateInput(
        uuid=address_uuid,
        org_unit=org_unit,
        visibility=visibility_class_uuid,
        validity=timeline_interval_to_mo_validity(
            first_sd_pnumber.start, first_sd_pnumber.end
        ),
        user_key=first_sd_pnumber.value,
        value=first_sd_pnumber.value,
        address_type=p_number_address_type_uuid,
    )
    logger.debug("Create address", payload=create_address_payload.dict())
    if not dry_run:
        created_address_uuid = (
            await gql_client.create_address(create_address_payload)
        ).uuid
    else:
        created_address_uuid = UUID(int=0)

    for sd_pnumber in sd_pnumber_timeline.intervals[1:]:
        update_address_payload = AddressUpdateInput(
            uuid=created_address_uuid,
            org_unit=org_unit,
            visibility=visibility_class_uuid,
            validity=timeline_interval_to_mo_validity(sd_pnumber.start, sd_pnumber.end),
            user_key=sd_pnumber.value,
            value=sd_pnumber.value,
            address_type=p_number_address_type_uuid,
        )
        logger.debug("Update address", payload=update_address_payload.dict())
        if not dry_run:
            await gql_client.update_address(update_address_payload)


async def create_postal_address(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    address_uuid: UUID | None,
    sd_postal_address_timeline: Timeline[UnitPostalAddress],
    dry_run: bool,
) -> None:
    logger.debug(
        "Create postal address in MO",
        postal_address_timeline=sd_postal_address_timeline.dict(),
    )

    # Get the address visibility UUID
    visibility_class_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="visibility",
        # TODO: handle required variability in municipality mode
        class_user_key="Public",
    )

    # Get the postal address type

    # postal_address_type_uuid = await _get_class(
    #     gql_client=gql_client,
    #     facet_user_key="org_unit_address_type",
    #     # TODO: use correct class user_key in municipality mode
    #     class_user_key="AdresseSDOrgUnit",
    # )

    # TODO: replace this code block with the one just above when the postal address
    #       user_key has converged
    ou_type_classes = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=["org_unit_address_type"]),
            user_keys=["AdresseAPOSOrgUnit", "AdresseSDOrgUnit"],
        )
    )
    current = one(
        ou_type_classes.objects,
        too_short=ClassNotFoundError,
        too_long=MoreThanOneClassError,
    ).current
    assert current is not None
    postal_address_type_uuid = current.uuid

    first_sd_postal_address = first(sd_postal_address_timeline.intervals)
    create_address_payload = AddressCreateInput(
        uuid=address_uuid,
        org_unit=org_unit,
        visibility=visibility_class_uuid,
        validity=timeline_interval_to_mo_validity(
            first_sd_postal_address.start, first_sd_postal_address.end
        ),
        user_key=first_sd_postal_address.value,
        value=first_sd_postal_address.value,
        address_type=postal_address_type_uuid,
    )
    logger.debug("Create address", payload=create_address_payload.dict())
    if not dry_run:
        created_address_uuid = (
            await gql_client.create_address(create_address_payload)
        ).uuid
    else:
        created_address_uuid = UUID(int=0)

    for sd_postal_address in sd_postal_address_timeline.intervals[1:]:
        update_address_payload = AddressUpdateInput(
            uuid=created_address_uuid,
            org_unit=org_unit,
            visibility=visibility_class_uuid,
            validity=timeline_interval_to_mo_validity(
                sd_postal_address.start, sd_postal_address.end
            ),
            user_key=sd_postal_address.value,
            value=sd_postal_address.value,
            address_type=postal_address_type_uuid,
        )
        logger.debug("Update address", payload=update_address_payload.dict())
        if not dry_run:
            await gql_client.update_address(update_address_payload)


async def create_phone_number(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    address_uuid: UUID | None,
    sd_phone_number_timeline: Timeline[UnitPhoneNumber],
    dry_run: bool,
) -> None:
    logger.debug(
        "Create phone number in MO",
        phone_number_timeline=sd_phone_number_timeline.dict(),
    )

    # Get the address visibility UUID
    visibility_class_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="visibility",
        # TODO: handle required variability in municipality mode
        class_user_key="Public",
    )

    # Get the phone number address type

    phone_number_type_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_address_type",
        # TODO: use correct class user_key in municipality mode
        class_user_key="lokation_telefon_lokal",
    )

    first_sd_phone_number = first(sd_phone_number_timeline.intervals)
    create_address_payload = AddressCreateInput(
        uuid=address_uuid,
        org_unit=org_unit,
        visibility=visibility_class_uuid,
        validity=timeline_interval_to_mo_validity(
            first_sd_phone_number.start, first_sd_phone_number.end
        ),
        user_key=first_sd_phone_number.value,
        value=first_sd_phone_number.value,
        address_type=phone_number_type_uuid,
    )
    logger.debug("Create address", payload=create_address_payload.dict())
    if not dry_run:
        created_address_uuid = (
            await gql_client.create_address(create_address_payload)
        ).uuid
    else:
        created_address_uuid = UUID(int=0)

    for sd_phone_number in sd_phone_number_timeline.intervals[1:]:
        update_address_payload = AddressUpdateInput(
            uuid=created_address_uuid,
            org_unit=org_unit,
            visibility=visibility_class_uuid,
            validity=timeline_interval_to_mo_validity(
                sd_phone_number.start, sd_phone_number.end
            ),
            user_key=sd_phone_number.value,
            value=sd_phone_number.value,
            address_type=phone_number_type_uuid,
        )
        logger.debug("Update address", payload=update_address_payload.dict())
        if not dry_run:
            await gql_client.update_address(update_address_payload)


async def create_association(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    sd_association_timeline: AssociationTimeline,
    start: datetime,
    end: datetime,
    association_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Create association",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    payload = AssociationCreateInput(
        user_key=user_key,
        person=person,
        org_unit=sd_association_timeline.association_unit.entity_at(start).value,
        association_type=association_type,
        validity=timeline_interval_to_mo_validity(start, end),
    )
    logger.debug("Create association payload", payload=payload.dict())

    if not dry_run:
        await gql_client.create_association(payload)
    logger.debug("Association created", person=str(person), user_key=user_key)


async def update_association(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    sd_association_timeline: AssociationTimeline,
    start: datetime,
    end: datetime,
    association_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Update association",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)
    logger.debug("mo_validity", mo_validity=mo_validity)

    association = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=start, to_date=end
        )
    )
    objects = association.objects
    obj = only(objects)

    if obj:
        # The association already exists in this validity period
        for validity in one(objects).validities:
            logger.debug("validity", validity=validity)
            payload = AssociationUpdateInput(
                uuid=obj.uuid,
                user_key=user_key,
                person=person,
                org_unit=sd_association_timeline.association_unit.entity_at(
                    start
                ).value,
                association_type=association_type,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
            )
            logger.debug("Update association", payload=payload.dict())
            if not dry_run:
                await gql_client.update_association(payload)
            logger.debug("Association updated", person=str(person), user_key=user_key)
        return

    # The association does not already exist in this validity period
    association = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )
    payload = AssociationUpdateInput(
        uuid=one(association.objects).uuid,
        user_key=user_key,
        person=person,
        org_unit=sd_association_timeline.association_unit.entity_at(start).value,
        association_type=association_type,
        validity=mo_validity,
    )
    logger.debug("Update association payload", payload=payload.dict())

    if not dry_run:
        await gql_client.update_association(payload)
    logger.debug("Association updated", person=str(person), user_key=user_key)


async def terminate_association(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Terminate association",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    association = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )
    association_uuid = one(association.objects).uuid

    if mo_validity.to is not None:
        payload = AssociationTerminateInput(
            uuid=association_uuid, from_=mo_validity.from_, to=mo_validity.to
        )
    else:
        payload = AssociationTerminateInput(
            uuid=association_uuid,
            # Converting from "from" to "to" due to the wierd way terminations in MO work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug("Terminate association", payload=payload.dict())

    if not dry_run:
        await gql_client.terminate_association(payload)
    logger.debug("Association terminated", person=str(person), user_key=user_key)
