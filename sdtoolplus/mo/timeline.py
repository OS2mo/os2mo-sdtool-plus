# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
from datetime import datetime
from datetime import timedelta
from itertools import pairwise
from uuid import UUID
from uuid import uuid4

import structlog
from more_itertools import one
from more_itertools import only
from more_itertools.more import collapse
from more_itertools.more import first

from sdtoolplus.autogenerated_graphql_client import ClassFilter
from sdtoolplus.autogenerated_graphql_client import EmployeeFilter
from sdtoolplus.autogenerated_graphql_client import EngagementCreateInput
from sdtoolplus.autogenerated_graphql_client import EngagementTerminateInput
from sdtoolplus.autogenerated_graphql_client import EngagementUpdateInput
from sdtoolplus.autogenerated_graphql_client import FacetFilter
from sdtoolplus.autogenerated_graphql_client import GetRelatedUnitsRelatedUnitsObjects
from sdtoolplus.autogenerated_graphql_client import LeaveCreateInput
from sdtoolplus.autogenerated_graphql_client import LeaveFilter
from sdtoolplus.autogenerated_graphql_client import LeaveTerminateInput
from sdtoolplus.autogenerated_graphql_client import LeaveUpdateInput
from sdtoolplus.autogenerated_graphql_client import OrganisationUnitCreateInput
from sdtoolplus.autogenerated_graphql_client import OrganisationUnitTerminateInput
from sdtoolplus.autogenerated_graphql_client import OrganisationUnitUpdateInput
from sdtoolplus.autogenerated_graphql_client import RAValidityInput
from sdtoolplus.autogenerated_graphql_client.input_types import AddressCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import AddressFilter
from sdtoolplus.autogenerated_graphql_client.input_types import AddressTerminateInput
from sdtoolplus.autogenerated_graphql_client.input_types import AddressUpdateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EmployeeCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EmployeeUpdateInput
from sdtoolplus.autogenerated_graphql_client.input_types import OrganisationUnitFilter
from sdtoolplus.autogenerated_graphql_client.input_types import RelatedUnitFilter
from sdtoolplus.depends import GraphQLClient
from sdtoolplus.mo_org_unit_importer import OrgUnitUUID
from sdtoolplus.models import POSITIVE_INFINITY
from sdtoolplus.models import Active
from sdtoolplus.models import EngagementKey
from sdtoolplus.models import EngagementName
from sdtoolplus.models import EngagementSDUnit
from sdtoolplus.models import EngagementTimeline
from sdtoolplus.models import EngagementType
from sdtoolplus.models import EngagementUnit
from sdtoolplus.models import EngagementUnitId
from sdtoolplus.models import EngType
from sdtoolplus.models import LeaveTimeline
from sdtoolplus.models import MOPNumberTimelineObj
from sdtoolplus.models import MOPostalAddressTimelineObj
from sdtoolplus.models import Person
from sdtoolplus.models import Timeline
from sdtoolplus.models import UnitId
from sdtoolplus.models import UnitLevel
from sdtoolplus.models import UnitName
from sdtoolplus.models import UnitParent
from sdtoolplus.models import UnitPNumber
from sdtoolplus.models import UnitPostalAddress
from sdtoolplus.models import UnitTimeline
from sdtoolplus.models import combine_intervals

logger = structlog.stdlib.get_logger()


def mo_end_to_datetime(mo_end: datetime | None) -> datetime:
    """
    Convert a MO end datetime or None to a datetime directly as it is in MO, i.e.
    no +/- timedelta adjustments are performed.
    """
    return mo_end if mo_end is not None else POSITIVE_INFINITY


def datetime_to_mo_end(end_datetime: datetime) -> datetime | None:
    """
    Convert a datetime to a MO end date or None directly as it is, i.e. no +/-
    timedelta adjustments are performed.
    """
    return None if end_datetime == POSITIVE_INFINITY else end_datetime


def _mo_end_to_timeline_end(mo_end: datetime | None) -> datetime:
    """
    Convert a MO end datetime to the end date required by our timeline objects.
    """
    mo_end = mo_end_to_datetime(mo_end)
    return (
        mo_end + timedelta(days=1)
        if not mo_end == POSITIVE_INFINITY
        else POSITIVE_INFINITY
    )


def timeline_interval_to_mo_validity(start: datetime, end: datetime) -> RAValidityInput:
    mo_end = datetime_to_mo_end(end)
    # Subtract one day due to MO
    mo_end = mo_end - timedelta(days=1) if mo_end is not None else None
    return RAValidityInput(from_=start, to=mo_end)


def get_patch_validity(
    codegen_validity_from: datetime,
    codegen_validity_to: datetime | None,
    mo_validity: RAValidityInput,
) -> RAValidityInput:
    """
    Get the validity for which the patch update should be performed. We need to truncate
    it with the timeline (start, end) endpoint update validities in order not to write
    beyond these in MO for the particular patch operation.
    """
    codegen_validity_to_datetime = mo_end_to_datetime(codegen_validity_to)
    mo_validity_to = mo_end_to_datetime(mo_validity.to)

    patch_validity_from = max(codegen_validity_from, mo_validity.from_)
    patch_validity_to = min(codegen_validity_to_datetime, mo_validity_to)

    return RAValidityInput(
        from_=patch_validity_from,
        to=None if patch_validity_to is POSITIVE_INFINITY else patch_validity_to,
    )


async def _get_class(
    gql_client: GraphQLClient,
    facet_user_key: str,
    class_user_key: str,
) -> UUID:
    ou_type_classes = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=[facet_user_key]),
            user_keys=[class_user_key],
        )
    )

    current = one(ou_type_classes.objects).current
    assert current is not None
    return current.uuid


async def get_engagement_types(gql_client: GraphQLClient) -> dict[EngType, UUID]:
    """
    Get map from engagement type (Enum) to MO engagement type class UUID
    """
    r_eng_types = await gql_client.get_class(
        ClassFilter(facet=FacetFilter(user_keys=["engagement_type"]))
    )

    relevant_classes = (
        obj.current
        for obj in r_eng_types.objects
        if obj.current is not None
        and obj.current.name in (eng_type.value for eng_type in EngType)
    )

    return {EngType(clazz.name): clazz.uuid for clazz in relevant_classes}


async def get_ou_timeline(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
) -> UnitTimeline:
    logger.info("Get MO org unit timeline", unit_uuid=str(unit_uuid))

    gql_timelime = await gql_client.get_org_unit_timeline(
        unit_uuid=unit_uuid, from_date=None, to_date=None
    )
    objects = gql_timelime.objects

    if not objects:
        logger.debug("MO OU timeline is empty")
        return UnitTimeline()

    validities = one(objects).validities

    activity_intervals = tuple(
        Active(
            start=obj.validity.from_,
            # TODO (#61435): MOs GraphQL subtracts one day from the validity end dates
            # when reading, compared to what was written.
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    id_intervals = tuple(
        UnitId(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.user_key,
        )
        for obj in validities
    )

    level_intervals = tuple(
        UnitLevel(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.org_unit_level.name if obj.org_unit_level is not None else None,
        )
        for obj in validities
    )

    name_intervals = tuple(
        UnitName(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.name,
        )
        for obj in validities
    )

    parent_intervals = tuple(
        UnitParent(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.parent_uuid,
        )
        for obj in validities
    )

    timeline = UnitTimeline(
        active=Timeline[Active](intervals=combine_intervals(activity_intervals)),
        name=Timeline[UnitName](intervals=combine_intervals(name_intervals)),
        unit_id=Timeline[UnitId](intervals=combine_intervals(id_intervals)),
        unit_level=Timeline[UnitLevel](intervals=combine_intervals(level_intervals)),
        parent=Timeline[UnitParent](intervals=combine_intervals(parent_intervals)),
    )
    logger.debug("MO OU timeline", timeline=timeline.dict())

    return timeline


async def get_pnumber_timeline(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
) -> MOPNumberTimelineObj:
    logger.info("Get MO P-number timeline", org_unit=str(unit_uuid))

    gql_timeline = await gql_client.get_address_timeline(
        AddressFilter(
            org_unit=OrganisationUnitFilter(uuids=[unit_uuid]),
            address_type=ClassFilter(
                facet=FacetFilter(user_keys=["org_unit_address_type"]),
                user_keys=["P-nummer"],  # TODO: check if this may be region specific
            ),
            from_date=None,
            to_date=None,
        )
    )

    objects = gql_timeline.objects

    if not objects:
        logger.debug("MO P-number timeline is empty")
        return MOPNumberTimelineObj(uuid=None, pnumber=Timeline[UnitPNumber]())

    # TODO: catch ValueError exception
    object = one(objects)

    timeline = MOPNumberTimelineObj(
        uuid=object.uuid,
        pnumber=Timeline[UnitPNumber](
            intervals=tuple(
                UnitPNumber(
                    start=obj.validity.from_,
                    end=_mo_end_to_timeline_end(obj.validity.to),
                    value=obj.value,
                )
                for obj in object.validities
            )
        ),
    )
    logger.debug("MO P-number timeline", timeline=timeline.dict())

    return timeline


async def get_postal_address_timeline(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
) -> MOPostalAddressTimelineObj:
    logger.info("Get MO postal address timeline", org_unit=str(unit_uuid))

    gql_timeline = await gql_client.get_address_timeline(
        AddressFilter(
            org_unit=OrganisationUnitFilter(uuids=[unit_uuid]),
            address_type=ClassFilter(
                facet=FacetFilter(user_keys=["org_unit_address_type"]),
                # TODO: use both keys for now as it has changed in the APOS importer?
                # TODO: handle the municipality case
                user_keys=["AdresseAPOSOrgUnit", "AdresseSDOrgUnit"],
            ),
            from_date=None,
            to_date=None,
        )
    )

    objects = gql_timeline.objects

    if not objects:
        logger.debug("MO postal address timeline is empty")
        return MOPostalAddressTimelineObj(
            uuid=None, pnumber=Timeline[UnitPostalAddress]()
        )

    # TODO: catch ValueError exception
    object = one(objects)

    timeline = MOPostalAddressTimelineObj(
        uuid=object.uuid,
        postal_address=Timeline[UnitPostalAddress](
            intervals=tuple(
                UnitPostalAddress(
                    start=obj.validity.from_,
                    end=_mo_end_to_timeline_end(obj.validity.to),
                    value=obj.value,
                )
                for obj in object.validities
            )
        ),
    )
    logger.debug("MO postal address timeline", timeline=timeline.dict())

    return timeline


async def create_ou(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    start: datetime,
    end: datetime,
    desired_unit_timeline: UnitTimeline,
    org_unit_type_user_key: str,
    dry_run: bool = False,
) -> None:
    logger.info("Creating OU", uuid=str(org_unit))
    logger.debug(
        "Creating OU",
        start=start,
        end=end,
        desired_unit_timeline=desired_unit_timeline.dict(),
    )

    # Get the OU type UUID
    ou_type_uuid = await _get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_type",
        class_user_key=org_unit_type_user_key,
    )

    # Get the OU level UUID
    unit_level = desired_unit_timeline.unit_level.entity_at(start)
    ou_level_uuid = await _get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_level",
        class_user_key=unit_level.value,  # type: ignore
    )

    payload = OrganisationUnitCreateInput(
        uuid=org_unit,
        validity=timeline_interval_to_mo_validity(start, end),
        name=desired_unit_timeline.name.entity_at(start).value,
        user_key=desired_unit_timeline.unit_id.entity_at(start).value,
        parent=desired_unit_timeline.parent.entity_at(start).value,
        org_unit_type=ou_type_uuid,
        org_unit_level=ou_level_uuid,
    )
    logger.debug("OU create payload", payload=payload.dict())
    if not dry_run:
        await gql_client.create_org_unit(payload)
    logger.debug("OU created", uuid=str(org_unit))


async def update_ou(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    start: datetime,
    end: datetime,
    desired_unit_timeline: UnitTimeline,
    org_unit_type_user_key: str,
    dry_run: bool = False,
) -> None:
    logger.info("Updating OU", uuid=str(org_unit))
    logger.debug(
        "Updating OU",
        start=start,
        end=end,
        desired_unit_timeline=desired_unit_timeline.dict(),
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)
    # TODO: refactor get_org_unit_timeline to take a RAValidityInput object instead of
    # start and end dates
    ou = await gql_client.get_org_unit_timeline(
        org_unit, mo_validity.from_, mo_validity.to
    )

    # Get the OU type UUID
    ou_type_uuid = await _get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_type",
        class_user_key=org_unit_type_user_key,
    )

    # Get the OU level UUID
    unit_level = desired_unit_timeline.unit_level.entity_at(start)
    ou_level_uuid = await _get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_level",
        class_user_key=unit_level.value,  # type: ignore
    )

    if ou.objects:
        # The OU already exists in this validity period
        for validity in one(ou.objects).validities:
            payload = OrganisationUnitUpdateInput(
                uuid=org_unit,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
                name=desired_unit_timeline.name.entity_at(start).value,
                user_key=desired_unit_timeline.unit_id.entity_at(start).value,
                parent=desired_unit_timeline.parent.entity_at(start).value,
                org_unit_type=ou_type_uuid,
                org_unit_level=ou_level_uuid,
                org_unit_hierarchy=validity.org_unit_hierarchy,
                time_planning=validity.time_planning_uuid,
            )
            logger.debug("OU update payload", payload=payload.dict())
            if not dry_run:
                await gql_client.update_org_unit(payload)
            logger.debug("OU updated", uuid=str(org_unit))
        return

    # The OU does not already exist in this validity period
    payload = OrganisationUnitUpdateInput(
        uuid=org_unit,
        validity=mo_validity,
        name=desired_unit_timeline.name.entity_at(start).value,
        user_key=desired_unit_timeline.unit_id.entity_at(start).value,
        parent=desired_unit_timeline.parent.entity_at(start).value,
        org_unit_type=ou_type_uuid,
        org_unit_level=ou_level_uuid,
    )
    logger.debug("OU update payload", payload=payload.dict())
    if not dry_run:
        await gql_client.update_org_unit(payload)
    logger.debug("OU updated", uuid=str(org_unit))


async def terminate_ou(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info("(Re-)terminate OU", org_unit=str(org_unit))

    mo_validity = timeline_interval_to_mo_validity(start, end)

    # Temporary work-around: get addresses to terminate if any
    mo_unit = await gql_client.get_org_unit_timeline(
        unit_uuid=org_unit,
        from_date=mo_validity.from_,
        to_date=mo_validity.to,
    )

    if mo_validity.to is not None:
        addr_term_payloads = [
            AddressTerminateInput(
                uuid=address.uuid,
                from_=mo_validity.from_,
                to=mo_validity.to,
            )
            for validity in one(mo_unit.objects).validities
            for address in validity.addresses
        ]
        payload = OrganisationUnitTerminateInput(
            uuid=org_unit,
            from_=mo_validity.from_,
            to=mo_validity.to,
        )
    else:
        addr_term_payloads = [
            AddressTerminateInput(
                uuid=address.uuid,
                # Converting from "from" to "to" due to the wierd way terminations in MO
                # work
                to=mo_validity.from_ - timedelta(days=1),
            )
            for validity in one(mo_unit.objects).validities
            for address in validity.addresses
        ]
        payload = OrganisationUnitTerminateInput(
            uuid=org_unit,
            # Converting from "from" to "to" due to the wierd way terminations in MO
            # work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug(
        "OU address termination payloads",
        payloads=[payload.dict() for payload in addr_term_payloads],
    )
    logger.debug("OU terminate payload", payload=payload.dict())
    if not dry_run:
        for addr_term_payload in addr_term_payloads:
            await gql_client.terminate_address(addr_term_payload)
        await gql_client.terminate_org_unit(payload)
    logger.debug("OU terminated", org_unit=str(org_unit))


async def get_engagement_timeline(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
) -> EngagementTimeline:
    logger.info("Get MO engagement timeline", person=str(person), emp_id=user_key)

    gql_timeline = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=None, to_date=None
    )
    objects = gql_timeline.objects

    if not objects:
        return EngagementTimeline()

    object_ = one(objects)
    validities = object_.validities

    activity_intervals = tuple(
        Active(
            start=obj.validity.from_,
            # TODO (#61435): MOs GraphQL subtracts one day from the validity end dates
            # when reading, compared to what was written.
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    key_intervals = tuple(
        EngagementKey(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.job_function.user_key,
        )
        for obj in validities
    )

    name_intervals = tuple(
        EngagementName(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            # TODO: introduce name strategy here
            value=obj.extension_1,
        )
        for obj in validities
    )

    unit_intervals = tuple(
        EngagementUnit(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=one(set(ou.uuid for ou in obj.org_unit)),
        )
        for obj in validities
    )

    sd_unit_intervals = tuple(
        EngagementSDUnit(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.extension_3,
        )
        for obj in validities
    )

    unit_id_intervals = tuple(
        EngagementUnitId(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.extension_2,
        )
        for obj in validities
    )

    type_intervals = tuple(
        EngagementType(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=EngType(obj.engagement_type.name),
        )
        for obj in validities
    )

    timeline = EngagementTimeline(
        eng_active=Timeline[Active](intervals=combine_intervals(activity_intervals)),
        eng_key=Timeline[EngagementKey](intervals=combine_intervals(key_intervals)),
        eng_name=Timeline[EngagementName](intervals=combine_intervals(name_intervals)),
        eng_unit=Timeline[EngagementUnit](intervals=combine_intervals(unit_intervals)),
        eng_sd_unit=Timeline[EngagementSDUnit](
            intervals=combine_intervals(sd_unit_intervals)
        ),
        eng_unit_id=Timeline[EngagementUnitId](
            intervals=combine_intervals(unit_id_intervals)
        ),
        eng_type=Timeline[EngagementType](intervals=combine_intervals(type_intervals)),
    )
    logger.debug("MO engagement timeline", timeline=timeline.dict())

    return timeline


async def get_leave_timeline(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
) -> LeaveTimeline:
    gql_timeline = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=None,
            to_date=None,
        )
    )
    objects = gql_timeline.objects

    if not objects:
        return LeaveTimeline()

    validities = one(objects).validities

    active_intervals = tuple(
        Active(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    timeline = LeaveTimeline(
        leave_active=Timeline[Active](intervals=combine_intervals(active_intervals)),
    )
    logger.debug("MO leave timeline", timeline=timeline.dict())

    return timeline


async def create_engagement(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    desired_eng_timeline: EngagementTimeline,
    eng_types: dict[EngType, UUID],
    dry_run: bool = False,
) -> None:
    logger.info("Creating engagement", person=str(person), emp_id=user_key)
    logger.debug(
        "Creating engagement",
        start=start,
        end=end,
        desired_eng_timeline=desired_eng_timeline.dict(),
    )

    # Get the job_function
    r_job_function = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=["engagement_job_function"]),
            user_keys=[str(desired_eng_timeline.eng_key.entity_at(start).value)],
            # The scope is the JobPositionLevelCode, and employments in SD
            # always refer to JobPositions at level 0.
            scope=["0"],
        )
    )
    current_job_function = one(r_job_function.objects).current
    assert current_job_function is not None
    job_function_uuid = current_job_function.uuid

    payload = EngagementCreateInput(
        user_key=user_key,
        validity=timeline_interval_to_mo_validity(start, end),
        # TODO: introduce extension_1 strategy
        extension_1=desired_eng_timeline.eng_name.entity_at(start).value,
        extension_2=desired_eng_timeline.eng_unit_id.entity_at(start).value,
        # TODO: introduce extension_3 strategy
        extension_3=str(desired_eng_timeline.eng_sd_unit.entity_at(start).value),
        person=person,
        org_unit=desired_eng_timeline.eng_unit.entity_at(start).value,
        engagement_type=eng_types[
            desired_eng_timeline.eng_type.entity_at(start).value  # type: ignore
        ],
        # TODO: introduce job_function strategy
        job_function=job_function_uuid,
    )
    logger.debug("Create engagement payload", payload=payload.dict())
    if not dry_run:
        await gql_client.create_engagement(payload)
    logger.debug("Engagement created", person=str(person), emp_id=user_key)


async def create_person(
    gql_client: GraphQLClient,
    cpr: str,
    givenname: str,
    lastname: str,
    dry_run: bool = False,
) -> None:
    logger.info("Create new person", cpr=cpr, givenname=givenname, lastname=lastname)

    employee_input = EmployeeCreateInput(
        cpr_number=cpr,
        given_name=givenname,
        surname=lastname,
    )
    logger.debug("Create person payload", payload=employee_input.dict())
    if not dry_run:
        await gql_client.create_person(input=employee_input)
    logger.debug("Person created", cpr=cpr)


async def update_person(
    gql_client: GraphQLClient,
    uuid: UUID,
    start: datetime,
    person: Person,
    dry_run: bool = False,
) -> None:
    logger.info("Update person")

    payload = EmployeeUpdateInput(
        uuid=uuid,
        cpr_number=person.cpr,
        given_name=person.given_name,
        surname=person.surname,
        validity=RAValidityInput(from_=start, to=None),
    )
    logger.debug("Update person payload", payload=payload.dict())
    if not dry_run:
        await gql_client.update_person(payload)
    logger.debug("Person updated", cpr=person.cpr)


async def create_leave(
    gql_client: GraphQLClient,
    person: UUID,
    eng_uuid: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    sd_leave_timeline: LeaveTimeline,
    leave_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info("Create leave", person=str(person), user_key=user_key)
    logger.debug(
        "Create leave", start=start, end=end, sd_leave_timeline=sd_leave_timeline.dict()
    )

    payload = LeaveCreateInput(
        user_key=user_key,
        person=person,
        engagement=eng_uuid,
        leave_type=leave_type,
        validity=timeline_interval_to_mo_validity(start, end),
    )
    logger.debug("Create leave payload", payload=payload.dict())

    if not dry_run:
        await gql_client.create_leave(payload)
    logger.debug("Leave created", person=str(person), user_key=user_key)


async def update_engagement(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    desired_eng_timeline: EngagementTimeline,
    eng_types: dict[EngType, UUID],
    dry_run: bool = False,
) -> None:
    logger.info("Update engagement", person=str(person), emp_id=user_key)
    logger.debug(
        "Update engagement",
        start=start,
        end=end,
        desired_eng_timeline=desired_eng_timeline.dict(),
    )

    # Get the job_function
    r_job_function = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=["engagement_job_function"]),
            user_keys=[str(desired_eng_timeline.eng_key.entity_at(start).value)],
            # The scope is the JobPositionLevelCode, and employments in SD
            # always refer to JobPositions at level 0.
            scope=["0"],
        )
    )
    current_job_function = one(r_job_function.objects).current
    assert current_job_function is not None
    job_function_uuid = current_job_function.uuid

    mo_validity = timeline_interval_to_mo_validity(start, end)

    eng = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=start, to_date=end
    )
    obj = only(eng.objects)

    if obj:
        # The engagement already exists in this validity period
        for validity in one(eng.objects).validities:
            eng_name = desired_eng_timeline.eng_name.entity_at(start).value
            payload = EngagementUpdateInput(
                uuid=obj.uuid,
                user_key=user_key,
                primary=validity.primary.uuid if validity.primary is not None else None,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
                # TODO: introduce extention_1 strategy
                # The empty string will be converted to null in the LoRa DB. Update
                # logic when https://redmine.magenta.dk/issues/65028 has been fixed.
                extension_1=eng_name if eng_name is not None else "",
                extension_2=desired_eng_timeline.eng_unit_id.entity_at(start).value,
                # TODO: introduce extension_3 strategy
                extension_3=str(
                    desired_eng_timeline.eng_sd_unit.entity_at(start).value
                ),
                extension_4=validity.extension_4,
                extension_5=validity.extension_5,
                extension_6=validity.extension_6,
                extension_7=validity.extension_7,
                extension_8=validity.extension_8,
                extension_9=validity.extension_9,
                extension_10=validity.extension_10,
                person=person,
                org_unit=desired_eng_timeline.eng_unit.entity_at(start).value,
                engagement_type=eng_types[
                    desired_eng_timeline.eng_type.entity_at(start).value  # type: ignore
                ],
                job_function=job_function_uuid,
            )
            logger.debug(
                "Update engagement in validity interval",
                payload=payload.dict(),
                validity=validity,
            )
            if not dry_run:
                await gql_client.update_engagement(payload)
            logger.debug("Engagement updated", person=str(person), emp_id=user_key)
        return

    # The engagement does not already exist in this validity period
    eng = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=None, to_date=None
    )
    payload = EngagementUpdateInput(
        uuid=one(eng.objects).uuid,
        user_key=user_key,
        validity=mo_validity,
        # TODO: introduce extention_1 strategy
        extension_1=desired_eng_timeline.eng_name.entity_at(start).value,
        extension_2=desired_eng_timeline.eng_unit_id.entity_at(start).value,
        # TODO: introduce extension_3 strategy
        extension_3=str(desired_eng_timeline.eng_sd_unit.entity_at(start).value),
        person=person,
        org_unit=desired_eng_timeline.eng_unit.entity_at(start).value,
        engagement_type=eng_types[desired_eng_timeline.eng_type.entity_at(start).value],  # type: ignore
        job_function=job_function_uuid,
    )
    logger.debug(
        "Update engagement in interval", payload=payload.dict(), mo_validity=mo_validity
    )
    if not dry_run:
        await gql_client.update_engagement(payload)
    logger.debug("Engagement updated", person=str(person), emp_id=user_key)


async def update_leave(
    gql_client: GraphQLClient,
    person: UUID,
    eng_uuid: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    sd_leave_timeline: LeaveTimeline,
    leave_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info("Update leave", person=str(person), user_key=user_key)
    logger.debug(
        "Update leave", start=start, end=end, sd_leave_timeline=sd_leave_timeline.dict()
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    leave = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=start,
            to_date=end,
        )
    )
    objects = leave.objects
    obj = only(objects)

    if obj:
        # The leave already exists in this validity period
        for validity in one(objects).validities:
            payload = LeaveUpdateInput(
                uuid=obj.uuid,
                user_key=user_key,
                person=person,
                engagement=eng_uuid,
                leave_type=leave_type,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
            )
            logger.debug("Update leave", payload=payload.dict())
            if not dry_run:
                await gql_client.update_leave(payload)
            logger.debug("Leave updated", person=str(person), user_key=user_key)
        return

    # The leave does not already exist in this validity period
    leave = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=None,
            to_date=None,
        )
    )
    payload = LeaveUpdateInput(
        uuid=one(leave.objects).uuid,
        user_key=user_key,
        person=person,
        engagement=eng_uuid,
        leave_type=leave_type,
        validity=mo_validity,
    )
    logger.debug("Update leave payload", payload=payload.dict())

    if not dry_run:
        await gql_client.update_leave(payload)
    logger.debug("Leave updated", person=str(person), user_key=user_key)


async def terminate_engagement(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Terminate engagement",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    eng = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=None, to_date=None
    )
    eng_uuid = one(eng.objects).uuid

    if mo_validity.to is not None:
        payload = EngagementTerminateInput(
            uuid=eng_uuid, from_=mo_validity.from_, to=mo_validity.to
        )
    else:
        payload = EngagementTerminateInput(
            uuid=eng_uuid,
            # Converting from "from" to "to" due to the wierd way terminations in MO work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug("Terminate engagement", payload=payload.dict())

    if not dry_run:
        await gql_client.terminate_engagement(payload)
    logger.debug("Engagement terminated", person=str(person), user_key=user_key)


async def terminate_leave(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Terminate leave",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    leave = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=None,
            to_date=None,
        )
    )
    leave_uuid = one(leave.objects).uuid

    if mo_validity.to is not None:
        payload = LeaveTerminateInput(
            uuid=leave_uuid, from_=mo_validity.from_, to=mo_validity.to
        )
    else:
        payload = LeaveTerminateInput(
            uuid=leave_uuid,
            # Converting from "from" to "to" due to the wierd way terminations in MO work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug("Terminate leave", payload=payload.dict())

    if not dry_run:
        await gql_client.terminate_leave(payload)
    logger.debug("Leave terminated", person=str(person), user_key=user_key)


def _get_related_units_endpoints(
    objects: list[GetRelatedUnitsRelatedUnitsObjects],
    start: datetime,
    end: datetime,
) -> list[datetime]:
    """
    Get the related unit endpoints timeline datetimes. E.g. in the case of dep3 having
    related units C, D and E as below, the function will return
    [t3, t4, t5, t6, t7, t8] (where t3 and t8 are the provided start and end argument,
    respectively).

    Time  --------t1--------t2----t3--t4--t5--t6--t7--t8-----t9--------------------->
    dep3          |-------------C---------|---E---|
                                      |---D---|
    """
    endpoints = set(
        collapse(
            (validity.validity.from_, _mo_end_to_timeline_end(validity.validity.to))
            for obj in objects
            for validity in obj.validities
        )
    )
    endpoints = endpoints.union({start, end})

    return sorted(endpoint for endpoint in endpoints if start <= endpoint <= end)


def _get_related_unit_at(
    objects: list[GetRelatedUnitsRelatedUnitsObjects],
    unit_uuid: OrgUnitUUID,
    at: datetime,
) -> OrgUnitUUID | None:
    """
    Get a single related unit (or None if no such unit exists) at the given time. If
    there are more than one related unit, we select the first in a list of sorted org
    unit UUIDs
    """
    related_units = sorted(
        org_unit.uuid
        for obj in objects
        for validity in obj.validities
        for org_unit in validity.org_units
        if not org_unit.uuid == unit_uuid
        and validity.validity.from_
        <= at
        < _mo_end_to_timeline_end(validity.validity.to)
    )
    return first(related_units, default=None)


async def related_units(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
    unit_interval: EngagementUnit,
    unknown_unit_uuid: OrgUnitUUID,
) -> list[EngagementUnit]:
    """
    Returns the related units in the given interval (or the "Unknown" unit if no related
    unit can be found). Note that the input interval may be divided into smaller
    intervals.
    """
    mo_validity = timeline_interval_to_mo_validity(
        unit_interval.start, unit_interval.end
    )

    mo_rel_units = await gql_client.get_related_units(
        RelatedUnitFilter(
            from_date=mo_validity.from_,
            to_date=mo_validity.to,
            org_unit=OrganisationUnitFilter(uuids=[unit_uuid]),
        )
    )

    objects = mo_rel_units.objects

    # Get the related unit interval endpoints as timeline datetimes
    endpoints = _get_related_units_endpoints(
        objects=objects, start=unit_interval.start, end=unit_interval.end
    )
    timeline_related_units = []
    for start, end in pairwise(endpoints):
        timeline_related_unit = _get_related_unit_at(
            objects=objects, unit_uuid=unit_uuid, at=start
        )
        if timeline_related_unit is None:
            timeline_related_unit = unknown_unit_uuid
        assert timeline_related_unit is not None
        timeline_related_units.append(
            EngagementUnit(
                start=start,
                end=end,
                value=timeline_related_unit,
            )
        )

    return timeline_related_units


async def delete_address(
    gql_client: GraphQLClient, address_uuid: UUID, dry_run: bool
) -> None:
    logger.debug("Delete address in MO", addr_uuid=str(address_uuid))
    if not dry_run:
        await gql_client.delete_address(address_uuid)


async def create_pnumber_address(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    address_uuid: UUID | None,
    sd_pnumber_timeline: Timeline[UnitPNumber],
    dry_run: bool,
) -> None:
    logger.debug("Create P-number in MO", pnumber_timeline=sd_pnumber_timeline.dict())

    # TODO: move these class calls to application start up for better performance

    # Get the address visibility UUID
    visibility_class_uuid = await _get_class(
        gql_client=gql_client,
        facet_user_key="visibility",
        # TODO: handle required variability in municipality mode
        class_user_key="Public",
    )

    # Get the P-number address type
    p_number_address_type_uuid = await _get_class(
        gql_client=gql_client,
        facet_user_key="org_unit_address_type",
        # TODO: use correct class user_key in municipality mode
        class_user_key="P-nummer",
    )

    first_sd_pnumber = first(sd_pnumber_timeline.intervals)
    create_address_payload = AddressCreateInput(
        uuid=address_uuid,
        org_unit=org_unit,
        visibility=visibility_class_uuid,
        validity=timeline_interval_to_mo_validity(
            first_sd_pnumber.start, first_sd_pnumber.end
        ),
        user_key=first_sd_pnumber.value,
        value=first_sd_pnumber.value,
        address_type=p_number_address_type_uuid,
    )
    logger.debug("Create address", payload=create_address_payload.dict())
    if not dry_run:
        created_address_uuid = (
            await gql_client.create_address(create_address_payload)
        ).uuid
    else:
        created_address_uuid = uuid4()

    for sd_pnumber in sd_pnumber_timeline.intervals[1:]:
        update_address_payload = AddressUpdateInput(
            uuid=created_address_uuid,
            org_unit=org_unit,
            visibility=visibility_class_uuid,
            validity=timeline_interval_to_mo_validity(sd_pnumber.start, sd_pnumber.end),
            user_key=sd_pnumber.value,
            value=sd_pnumber.value,
            address_type=p_number_address_type_uuid,
        )
        logger.debug("Update address", payload=update_address_payload.dict())
        if not dry_run:
            await gql_client.update_address(update_address_payload)


async def create_postal_address(
    gql_client: GraphQLClient,
    org_unit: OrgUnitUUID,
    address_uuid: UUID | None,
    sd_postal_address_timeline: Timeline[UnitPostalAddress],
    dry_run: bool,
) -> None:
    logger.debug(
        "Create postal address in MO",
        pnumber_timeline=sd_postal_address_timeline.dict(),
    )

    # TODO: move these class calls to application start up for better performance

    # Get the address visibility UUID
    visibility_class_uuid = await _get_class(
        gql_client=gql_client,
        facet_user_key="visibility",
        # TODO: handle required variability in municipality mode
        class_user_key="Public",
    )

    # Get the postal address type

    # postal_address_type_uuid = await _get_class(
    #     gql_client=gql_client,
    #     facet_user_key="org_unit_address_type",
    #     # TODO: use correct class user_key in municipality mode
    #     class_user_key="AdresseSDOrgUnit",
    # )

    # TODO: replace this code block with the one just above when the postal address
    #       user_key has converged
    ou_type_classes = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=["org_unit_address_type"]),
            user_keys=["AdresseAPOSOrgUnit", "AdresseSDOrgUnit"],
        )
    )
    current = one(ou_type_classes.objects).current
    assert current is not None
    postal_address_type_uuid = current.uuid

    first_sd_postal_address = first(sd_postal_address_timeline.intervals)
    create_address_payload = AddressCreateInput(
        uuid=address_uuid,
        org_unit=org_unit,
        visibility=visibility_class_uuid,
        validity=timeline_interval_to_mo_validity(
            first_sd_postal_address.start, first_sd_postal_address.end
        ),
        user_key=first_sd_postal_address.value,
        value=first_sd_postal_address.value,
        address_type=postal_address_type_uuid,
    )
    logger.debug("Create address", payload=create_address_payload.dict())
    if not dry_run:
        created_address_uuid = (
            await gql_client.create_address(create_address_payload)
        ).uuid
    else:
        created_address_uuid = uuid4()

    for sd_postal_address in sd_postal_address_timeline.intervals[1:]:
        update_address_payload = AddressUpdateInput(
            uuid=created_address_uuid,
            org_unit=org_unit,
            visibility=visibility_class_uuid,
            validity=timeline_interval_to_mo_validity(
                sd_postal_address.start, sd_postal_address.end
            ),
            user_key=sd_postal_address.value,
            value=sd_postal_address.value,
            address_type=postal_address_type_uuid,
        )
        logger.debug("Update address", payload=update_address_payload.dict())
        if not dry_run:
            await gql_client.update_address(update_address_payload)
