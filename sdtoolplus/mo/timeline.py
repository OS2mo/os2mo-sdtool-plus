# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
from datetime import datetime
from datetime import timedelta
from itertools import pairwise
from uuid import UUID

import structlog
from more_itertools import one
from more_itertools import only
from more_itertools.more import collapse
from more_itertools.more import first

from sdtoolplus.autogenerated_graphql_client import ClassFilter
from sdtoolplus.autogenerated_graphql_client import EmployeeFilter
from sdtoolplus.autogenerated_graphql_client import EngagementCreateInput
from sdtoolplus.autogenerated_graphql_client import EngagementTerminateInput
from sdtoolplus.autogenerated_graphql_client import EngagementUpdateInput
from sdtoolplus.autogenerated_graphql_client import FacetFilter
from sdtoolplus.autogenerated_graphql_client import GetRelatedUnitsRelatedUnitsObjects
from sdtoolplus.autogenerated_graphql_client import GraphQLClientGraphQLMultiError
from sdtoolplus.autogenerated_graphql_client import LeaveCreateInput
from sdtoolplus.autogenerated_graphql_client import LeaveFilter
from sdtoolplus.autogenerated_graphql_client import LeaveTerminateInput
from sdtoolplus.autogenerated_graphql_client import LeaveUpdateInput
from sdtoolplus.autogenerated_graphql_client import RAValidityInput
from sdtoolplus.autogenerated_graphql_client.input_types import AssociationCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import AssociationFilter
from sdtoolplus.autogenerated_graphql_client.input_types import (
    AssociationTerminateInput,
)
from sdtoolplus.autogenerated_graphql_client.input_types import AssociationUpdateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EmployeeCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EmployeeUpdateInput
from sdtoolplus.autogenerated_graphql_client.input_types import EngagementFilter
from sdtoolplus.autogenerated_graphql_client.input_types import OrganisationUnitFilter
from sdtoolplus.autogenerated_graphql_client.input_types import RelatedUnitFilter
from sdtoolplus.config import TIMEZONE
from sdtoolplus.depends import GraphQLClient
from sdtoolplus.exceptions import MoreThanOneAssociationError
from sdtoolplus.exceptions import MoreThanOneEngagementError
from sdtoolplus.exceptions import MoreThanOneLeaveError
from sdtoolplus.exceptions import NoValueError
from sdtoolplus.mo_org_unit_importer import OrgUnitUUID
from sdtoolplus.models import POSITIVE_INFINITY
from sdtoolplus.models import Active
from sdtoolplus.models import AssociationTimeline
from sdtoolplus.models import EngagementKey
from sdtoolplus.models import EngagementName
from sdtoolplus.models import EngagementSDUnit
from sdtoolplus.models import EngagementTimeline
from sdtoolplus.models import EngagementType
from sdtoolplus.models import EngagementUnit
from sdtoolplus.models import EngagementUnitId
from sdtoolplus.models import EngType
from sdtoolplus.models import LeaveTimeline
from sdtoolplus.models import Person
from sdtoolplus.models import Timeline
from sdtoolplus.models import combine_intervals

logger = structlog.stdlib.get_logger()


def mo_end_to_datetime(mo_end: datetime | None) -> datetime:
    """
    Convert a MO end datetime or None to a datetime directly as it is in MO, i.e.
    no +/- timedelta adjustments are performed.
    """
    return mo_end if mo_end is not None else POSITIVE_INFINITY


def datetime_to_mo_end(end_datetime: datetime) -> datetime | None:
    """
    Convert a datetime to a MO end date or None directly as it is, i.e. no +/-
    timedelta adjustments are performed.
    """
    return None if end_datetime == POSITIVE_INFINITY else end_datetime


def _mo_end_to_timeline_end(mo_end: datetime | None) -> datetime:
    """
    Convert a MO end datetime to the end date required by our timeline objects.
    """
    mo_end = mo_end_to_datetime(mo_end)
    return (
        mo_end + timedelta(days=1)
        if not mo_end == POSITIVE_INFINITY
        else POSITIVE_INFINITY
    )


def timeline_interval_to_mo_validity(start: datetime, end: datetime) -> RAValidityInput:
    mo_end = datetime_to_mo_end(end)
    # Subtract one day due to MO
    mo_end = mo_end - timedelta(days=1) if mo_end is not None else None
    return RAValidityInput(from_=start, to=mo_end)


def get_patch_validity(
    codegen_validity_from: datetime,
    codegen_validity_to: datetime | None,
    mo_validity: RAValidityInput,
) -> RAValidityInput:
    """
    Get the validity for which the patch update should be performed. We need to truncate
    it with the timeline (start, end) endpoint update validities in order not to write
    beyond these in MO for the particular patch operation.
    """
    codegen_validity_to_datetime = mo_end_to_datetime(codegen_validity_to)
    mo_validity_to = mo_end_to_datetime(mo_validity.to)

    patch_validity_from = max(codegen_validity_from, mo_validity.from_)
    patch_validity_to = min(codegen_validity_to_datetime, mo_validity_to)

    return RAValidityInput(
        from_=patch_validity_from,
        to=None if patch_validity_to is POSITIVE_INFINITY else patch_validity_to,
    )


async def get_class(
    gql_client: GraphQLClient,
    facet_user_key: str,
    class_user_key: str,
) -> UUID:
    ou_type_classes = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=[facet_user_key]),
            user_keys=[class_user_key],
        )
    )

    try:
        current = one(ou_type_classes.objects).current
    except ValueError as error:
        logger.error(
            "Not exactly on class found in MO",
            facet_user_key=facet_user_key,
            class_user_key=class_user_key,
            error=error,
        )
        raise error
    assert current is not None
    return current.uuid


async def get_class_user_key(
    gql_client: GraphQLClient,
    class_uuid: UUID,
    at: datetime | None = None,
) -> str:
    classes = await gql_client.get_class(ClassFilter(uuids=[class_uuid]), at=at)

    try:
        current = one(classes.objects).current
    except ValueError as error:
        logger.error(
            "Class not found or more than one class found", class_uuid=class_uuid
        )
        raise error
    if current is None:
        return await get_class_user_key(
            gql_client=gql_client, class_uuid=class_uuid, at=datetime.now(tz=TIMEZONE)
        )

    return current.user_key


async def get_engagement_types(gql_client: GraphQLClient) -> dict[EngType, UUID]:
    """
    Get map from engagement type (Enum) to MO engagement type class UUID
    """
    r_eng_types = await gql_client.get_class(
        ClassFilter(facet=FacetFilter(user_keys=["engagement_type"]))
    )

    relevant_classes = (
        obj.current
        for obj in r_eng_types.objects
        if obj.current is not None
        and obj.current.user_key in (eng_type.value for eng_type in EngType)
    )

    return {EngType(clazz.user_key): clazz.uuid for clazz in relevant_classes}


async def get_job_function(
    gql_client: GraphQLClient, job_function_user_key: str
) -> UUID:
    """
    Get the job_function class UUID
    """
    r_job_function = await gql_client.get_class(
        ClassFilter(
            facet=FacetFilter(user_keys=["engagement_job_function"]),
            user_keys=[job_function_user_key],
            # The scope is the JobPositionLevelCode, and employments in SD
            # always refer to JobPositions at level 0.
            scope=["0"],
        )
    )
    try:
        current_job_function = one(r_job_function.objects).current
    except ValueError as error:
        logger.error(
            "Not exactly on class found in MO",
            facet_user_key="engagement_job_function",
            class_user_key=job_function_user_key,
            error=error,
        )
        raise error

    assert current_job_function is not None

    return current_job_function.uuid


def get_association_filter(
    person: UUID, user_key: str, from_date: datetime | None, to_date: datetime | None
) -> AssociationFilter:
    return AssociationFilter(
        # TODO: check if association_type_user_keys is municipality dependent
        association_type_user_keys=["SD-medarbejder"],
        employee=EmployeeFilter(uuids=[person]),
        # NOTE: users keys are assumed unique and static. If they change we will
        # risk creating duplicate associations. Ideally, we should attach the
        # association to the engagement UUID, but in order to be backwards
        # compatible with the old SD-integration, we will use the user_key.
        user_keys=[user_key],
        from_date=from_date,
        to_date=to_date,
    )


def get_engagement_filter(
    person: UUID, user_key: str, from_date: datetime | None, to_date: datetime | None
) -> EngagementFilter:
    return EngagementFilter(
        employee=EmployeeFilter(uuids=[person]),
        user_keys=[user_key],
        from_date=from_date,
        to_date=to_date,
    )


async def get_engagement_timeline(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
) -> EngagementTimeline:
    logger.info("Get MO engagement timeline", person=str(person), emp_id=user_key)

    gql_timeline = await gql_client.get_engagement_timeline(
        get_engagement_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )
    objects = gql_timeline.objects

    if not objects:
        return EngagementTimeline()

    object_ = one(objects, too_long=MoreThanOneEngagementError)
    validities = object_.validities

    # Make sure we only look up each class once in MO for this time calculation
    class_uuid_to_user_key: dict[UUID, str] = dict()

    activity_intervals = tuple(
        Active(
            start=obj.validity.from_,
            # TODO (#61435): MOs GraphQL subtracts one day from the validity end dates
            # when reading, compared to what was written.
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    key_intervals = []
    for obj in validities:
        job_function_user_key = await get_class_user_key(
            gql_client=gql_client,
            class_uuid=obj.job_function_uuid,
            at=obj.validity.from_,
        )
        key_intervals.append(
            EngagementKey(
                start=obj.validity.from_,
                end=_mo_end_to_timeline_end(obj.validity.to),
                value=job_function_user_key,
            )
        )

    name_intervals = tuple(
        EngagementName(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            # TODO: introduce name strategy here
            value=obj.extension_1,
        )
        for obj in validities
    )

    unit_intervals = tuple(
        EngagementUnit(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.org_unit_uuid,
        )
        for obj in validities
    )

    sd_unit_intervals = tuple(
        EngagementSDUnit(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.extension_5,
        )
        for obj in validities
    )

    unit_id_intervals = tuple(
        EngagementUnitId(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.extension_4,
        )
        for obj in validities
    )

    type_intervals = []
    for obj in validities:
        type_user_key = class_uuid_to_user_key.get(obj.engagement_type_uuid)
        if type_user_key is None:
            type_user_key = await get_class_user_key(
                gql_client=gql_client, class_uuid=obj.engagement_type_uuid
            )
        type_intervals.append(
            EngagementType(
                start=obj.validity.from_,
                end=_mo_end_to_timeline_end(obj.validity.to),
                value=EngType(type_user_key),
            )
        )

    timeline = EngagementTimeline(
        eng_active=Timeline[Active](intervals=combine_intervals(activity_intervals)),
        eng_key=Timeline[EngagementKey](
            intervals=combine_intervals(tuple(key_intervals))
        ),
        eng_name=Timeline[EngagementName](intervals=combine_intervals(name_intervals)),
        eng_unit=Timeline[EngagementUnit](intervals=combine_intervals(unit_intervals)),
        eng_sd_unit=Timeline[EngagementSDUnit](
            intervals=combine_intervals(sd_unit_intervals)
        ),
        eng_unit_id=Timeline[EngagementUnitId](
            intervals=combine_intervals(unit_id_intervals)
        ),
        eng_type=Timeline[EngagementType](
            intervals=combine_intervals(tuple(type_intervals))
        ),
    )
    logger.debug("MO engagement timeline", timeline=timeline.dict())

    return timeline


async def get_leave_timeline(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
) -> LeaveTimeline:
    gql_timeline = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=None,
            to_date=None,
        )
    )
    objects = gql_timeline.objects

    if not objects:
        return LeaveTimeline()

    validities = one(objects, too_long=MoreThanOneLeaveError).validities

    active_intervals = tuple(
        Active(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    timeline = LeaveTimeline(
        leave_active=Timeline[Active](intervals=combine_intervals(active_intervals)),
    )
    logger.debug("MO leave timeline", timeline=timeline.dict())

    return timeline


async def get_association_timeline(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
) -> AssociationTimeline:
    gql_timeline = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )

    objects = gql_timeline.objects

    if not objects:
        return AssociationTimeline()

    logger.debug("ass", objects=objects)
    validities = one(objects, too_long=MoreThanOneAssociationError).validities

    active_intervals = tuple(
        Active(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=True,
        )
        for obj in validities
    )

    unit_intervals = tuple(
        EngagementSDUnit(
            start=obj.validity.from_,
            end=_mo_end_to_timeline_end(obj.validity.to),
            value=obj.org_unit_uuid,
        )
        for obj in validities
    )

    timeline = AssociationTimeline(
        association_active=Timeline[Active](
            intervals=combine_intervals(active_intervals)
        ),
        association_unit=Timeline[EngagementSDUnit](
            intervals=combine_intervals(unit_intervals)
        ),
    )
    logger.debug("MO association timeline", timeline=timeline.dict())

    return timeline


async def create_engagement(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    desired_eng_timeline: EngagementTimeline,
    eng_types: dict[EngType, UUID],
    dry_run: bool = False,
) -> None:
    logger.info("Creating engagement", person=str(person), emp_id=user_key)
    logger.debug(
        "Creating engagement",
        start=start,
        end=end,
        desired_eng_timeline=desired_eng_timeline.dict(),
    )

    # Get the job_function
    job_function_uuid = await get_job_function(
        gql_client=gql_client,
        job_function_user_key=str(desired_eng_timeline.eng_key.entity_at(start).value),
    )

    payload = EngagementCreateInput(
        user_key=user_key,
        validity=timeline_interval_to_mo_validity(start, end),
        extension_1=desired_eng_timeline.eng_name.entity_at(start).value,
        extension_4=desired_eng_timeline.eng_unit_id.entity_at(start).value,
        extension_5=str(desired_eng_timeline.eng_sd_unit.entity_at(start).value),
        person=person,
        org_unit=desired_eng_timeline.eng_unit.entity_at(start).value,
        engagement_type=eng_types[
            desired_eng_timeline.eng_type.entity_at(start).value  # type: ignore
        ],
        # TODO: introduce job_function strategy
        job_function=job_function_uuid,
    )
    logger.debug("Create engagement payload", payload=payload.dict())
    if not dry_run:
        await gql_client.create_engagement(payload)
    logger.debug("Engagement created", person=str(person), emp_id=user_key)


async def create_person(
    gql_client: GraphQLClient,
    cpr: str,
    givenname: str,
    lastname: str,
    dry_run: bool = False,
) -> None:
    logger.info("Create new person", cpr=cpr, givenname=givenname, lastname=lastname)

    employee_input = EmployeeCreateInput(
        cpr_number=cpr,
        given_name=givenname,
        surname=lastname,
    )
    logger.debug("Create person payload", payload=employee_input.dict())
    if not dry_run:
        await gql_client.create_person(input=employee_input)
    logger.debug("Person created", cpr=cpr)


async def update_person(
    gql_client: GraphQLClient,
    uuid: UUID,
    start: datetime,
    person: Person,
    dry_run: bool = False,
) -> None:
    logger.info("Update person")

    payload = EmployeeUpdateInput(
        uuid=uuid,
        cpr_number=person.cpr,
        given_name=person.given_name,
        surname=person.surname,
        validity=RAValidityInput(from_=start, to=None),
    )
    logger.debug("Update person payload", payload=payload.dict())
    if not dry_run:
        await gql_client.update_person(payload)
    logger.debug("Person updated", cpr=person.cpr)


async def create_leave(
    gql_client: GraphQLClient,
    person: UUID,
    eng_uuid: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    sd_leave_timeline: LeaveTimeline,
    leave_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info("Create leave", person=str(person), user_key=user_key)
    logger.debug(
        "Create leave", start=start, end=end, sd_leave_timeline=sd_leave_timeline.dict()
    )

    payload = LeaveCreateInput(
        user_key=user_key,
        person=person,
        engagement=eng_uuid,
        leave_type=leave_type,
        validity=timeline_interval_to_mo_validity(start, end),
    )
    logger.debug("Create leave payload", payload=payload.dict())

    if not dry_run:
        try:
            await gql_client.create_leave(payload)
        except GraphQLClientGraphQLMultiError as error:
            if not str(one(error.errors)) == "ErrorCodes.V_NO_ACTIVE_ENGAGEMENT":
                raise error
            logger.error(
                "Could not create leave in interval due to a missing engagement",
                person=str(person),
                user_key=user_key,
                eng_uuid=str(eng_uuid),
            )
            return

    logger.debug("Leave created", person=str(person), user_key=user_key)


async def update_engagement(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    desired_eng_timeline: EngagementTimeline,
    eng_types: dict[EngType, UUID],
    dry_run: bool = False,
) -> None:
    logger.info("Update engagement", person=str(person), emp_id=user_key)
    logger.debug(
        "Update engagement",
        start=start,
        end=end,
        desired_eng_timeline=desired_eng_timeline.dict(),
    )

    # Get the job_function
    job_function_uuid = await get_job_function(
        gql_client=gql_client,
        job_function_user_key=str(desired_eng_timeline.eng_key.entity_at(start).value),
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    eng = await gql_client.get_engagement_timeline(
        get_engagement_filter(
            person=person, user_key=user_key, from_date=start, to_date=end
        )
    )
    obj = only(eng.objects)

    if obj:
        # The engagement already exists in this validity period
        for validity in one(eng.objects).validities:
            eng_name = desired_eng_timeline.eng_name.entity_at(start).value
            payload = EngagementUpdateInput(
                uuid=obj.uuid,
                user_key=user_key,
                primary=validity.primary_uuid,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
                # The empty string will be converted to null in the LoRa DB. Update
                # logic when https://redmine.magenta.dk/issues/65028 has been fixed.
                extension_1=eng_name if eng_name is not None else "",
                extension_2=validity.extension_2,
                extension_3=validity.extension_3,
                extension_4=desired_eng_timeline.eng_unit_id.entity_at(start).value,
                extension_5=str(
                    desired_eng_timeline.eng_sd_unit.entity_at(start).value
                ),
                extension_6=validity.extension_6,
                extension_7=validity.extension_7,
                extension_8=validity.extension_8,
                extension_9=validity.extension_9,
                extension_10=validity.extension_10,
                person=person,
                org_unit=desired_eng_timeline.eng_unit.entity_at(start).value,
                engagement_type=eng_types[
                    desired_eng_timeline.eng_type.entity_at(start).value  # type: ignore
                ],
                job_function=job_function_uuid,
            )
            logger.debug(
                "Update engagement in validity interval",
                payload=payload.dict(),
                validity=validity,
            )
            if not dry_run:
                await gql_client.update_engagement(payload)
            logger.debug("Engagement updated", person=str(person), emp_id=user_key)
        return

    # The engagement does not already exist in this validity period
    eng = await gql_client.get_engagement_timeline(
        get_engagement_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )
    payload = EngagementUpdateInput(
        uuid=one(eng.objects).uuid,
        user_key=user_key,
        validity=mo_validity,
        # TODO: introduce extention_1 strategy
        extension_1=desired_eng_timeline.eng_name.entity_at(start).value,
        extension_4=desired_eng_timeline.eng_unit_id.entity_at(start).value,
        extension_5=str(desired_eng_timeline.eng_sd_unit.entity_at(start).value),
        person=person,
        org_unit=desired_eng_timeline.eng_unit.entity_at(start).value,
        engagement_type=eng_types[desired_eng_timeline.eng_type.entity_at(start).value],  # type: ignore
        job_function=job_function_uuid,
    )
    logger.debug(
        "Update engagement in interval", payload=payload.dict(), mo_validity=mo_validity
    )
    if not dry_run:
        await gql_client.update_engagement(payload)
    logger.debug("Engagement updated", person=str(person), emp_id=user_key)


async def update_leave(
    gql_client: GraphQLClient,
    person: UUID,
    eng_uuid: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    sd_leave_timeline: LeaveTimeline,
    leave_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info("Update leave", person=str(person), user_key=user_key)
    logger.debug(
        "Update leave", start=start, end=end, sd_leave_timeline=sd_leave_timeline.dict()
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    leave = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=start,
            to_date=end,
        )
    )
    objects = leave.objects
    obj = only(objects)

    if obj:
        # The leave already exists in this validity period
        for validity in one(objects).validities:
            payload = LeaveUpdateInput(
                uuid=obj.uuid,
                user_key=user_key,
                person=person,
                engagement=eng_uuid,
                leave_type=leave_type,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
            )
            logger.debug("Update leave", payload=payload.dict())
            if not dry_run:
                try:
                    await gql_client.update_leave(payload)
                except GraphQLClientGraphQLMultiError as error:
                    if (
                        not str(one(error.errors))
                        == "ErrorCodes.V_NO_ACTIVE_ENGAGEMENT"
                    ):
                        raise error
                    logger.error(
                        "Could not update leave in interval due to a missing engagement",
                        person=str(person),
                        user_key=user_key,
                        eng_uuid=str(eng_uuid),
                    )
                    return

            logger.debug("Leave updated", person=str(person), user_key=user_key)
        return

    # The leave does not already exist in this validity period
    leave = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=None,
            to_date=None,
        )
    )
    payload = LeaveUpdateInput(
        uuid=one(leave.objects).uuid,
        user_key=user_key,
        person=person,
        engagement=eng_uuid,
        leave_type=leave_type,
        validity=mo_validity,
    )
    logger.debug("Update leave payload", payload=payload.dict())

    if not dry_run:
        try:
            await gql_client.update_leave(payload)
        except GraphQLClientGraphQLMultiError as error:
            if not str(one(error.errors)) == "ErrorCodes.V_NO_ACTIVE_ENGAGEMENT":
                raise error
            logger.error(
                "Could not update leave in interval due to a missing engagement",
                person=str(person),
                user_key=user_key,
                eng_uuid=str(eng_uuid),
            )
            return

    logger.debug("Leave updated", person=str(person), user_key=user_key)


async def terminate_engagement(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Terminate engagement",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    eng = await gql_client.get_engagement_timeline(
        get_engagement_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )
    try:
        eng_uuid = one(eng.objects).uuid
    except ValueError:
        # This can happen if the SD engagement active timeline only contains
        # status 8 intervals
        logger.warning(
            "Cannot terminate engagement since it is not found in MO",
            person=str(person),
            user_key=user_key,
        )
        return

    if mo_validity.to is not None:
        payload = EngagementTerminateInput(
            uuid=eng_uuid, from_=mo_validity.from_, to=mo_validity.to
        )
    else:
        payload = EngagementTerminateInput(
            uuid=eng_uuid,
            # Converting from "from" to "to" due to the wierd way terminations in MO work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug("Terminate engagement", payload=payload.dict())

    if not dry_run:
        await gql_client.terminate_engagement(payload)
    logger.debug("Engagement terminated", person=str(person), user_key=user_key)


async def terminate_leave(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Terminate leave",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    leave = await gql_client.get_leave(
        LeaveFilter(
            employee=EmployeeFilter(uuids=[person]),
            user_keys=[user_key],
            from_date=None,
            to_date=None,
        )
    )
    leave_uuid = one(leave.objects).uuid

    if mo_validity.to is not None:
        payload = LeaveTerminateInput(
            uuid=leave_uuid, from_=mo_validity.from_, to=mo_validity.to
        )
    else:
        payload = LeaveTerminateInput(
            uuid=leave_uuid,
            # Converting from "from" to "to" due to the wierd way terminations in MO work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug("Terminate leave", payload=payload.dict())

    if not dry_run:
        await gql_client.terminate_leave(payload)
    logger.debug("Leave terminated", person=str(person), user_key=user_key)


async def terminate_leave_before_engagement_termination(
    gql_client: GraphQLClient,
    eng_term_start: datetime,
    eng_term_end: datetime,
    mo_leave_timeline: LeaveTimeline,
    person: UUID,
    user_key: str,
) -> None:
    logger.debug(
        "Terminate leave prior to engagement termination",
        person=str(person),
        user_key=user_key,
        eng_term_start=eng_term_start,
        eng_term_end=eng_term_end,
    )

    endpoints = sorted(
        mo_leave_timeline.get_interval_endpoints().union({eng_term_start, eng_term_end})
    )
    endpoints = [
        endpoint for endpoint in endpoints if eng_term_start <= endpoint <= eng_term_end
    ]

    for start, end in pairwise(endpoints):
        try:
            mo_leave_timeline.leave_active.entity_at(start)
        except NoValueError:
            logger.debug(
                "No leave to terminate in this interval",
                person=str(person),
                user_key=user_key,
                start=start,
                end=end,
            )
            continue
        await terminate_leave(
            gql_client=gql_client,
            person=person,
            user_key=user_key,
            start=start,
            end=end,
        )
        logger.debug(
            "Terminated leave prior to engagement termination",
            person=str(person),
            user_key=user_key,
            start=start,
            end=end,
        )


def _get_related_units_endpoints(
    objects: list[GetRelatedUnitsRelatedUnitsObjects],
    start: datetime,
    end: datetime,
) -> list[datetime]:
    """
    Get the related unit endpoints timeline datetimes. E.g. in the case of dep3 having
    related units C, D and E as below, the function will return
    [t3, t4, t5, t6, t7, t8] (where t3 and t8 are the provided start and end argument,
    respectively).

    Time  --------t1--------t2----t3--t4--t5--t6--t7--t8-----t9--------------------->
    dep3          |-------------C---------|---E---|
                                      |---D---|
    """
    endpoints = set(
        collapse(
            (validity.validity.from_, _mo_end_to_timeline_end(validity.validity.to))
            for obj in objects
            for validity in obj.validities
        )
    )
    endpoints = endpoints.union({start, end})

    return sorted(endpoint for endpoint in endpoints if start <= endpoint <= end)


def _get_related_unit_at(
    objects: list[GetRelatedUnitsRelatedUnitsObjects],
    unit_uuid: OrgUnitUUID,
    at: datetime,
) -> OrgUnitUUID | None:
    """
    Get a single related unit (or None if no such unit exists) at the given time. If
    there are more than one related unit, we select the first in a list of sorted org
    unit UUIDs
    """
    related_units = sorted(
        org_unit_uuid
        for obj in objects
        for validity in obj.validities
        for org_unit_uuid in validity.org_unit_uuids
        if not org_unit_uuid == unit_uuid
        and validity.validity.from_
        <= at
        < _mo_end_to_timeline_end(validity.validity.to)
    )
    return first(related_units, default=None)


async def related_units(
    gql_client: GraphQLClient,
    unit_uuid: OrgUnitUUID,
    unit_interval: EngagementUnit,
    unknown_unit_uuid: OrgUnitUUID,
) -> list[EngagementUnit]:
    """
    Returns the related units in the given interval (or the "Unknown" unit if no related
    unit can be found). Note that the input interval may be divided into smaller
    intervals.
    """
    mo_rel_units = await gql_client.get_related_units(
        RelatedUnitFilter(
            from_date=unit_interval.start,
            # This to_date is counterintuitive for this OU relation look up,
            # since the to_date is the day *after* the relation potentially
            # ends, but MO requires these dates. Especially since we are not
            # allowed to ask for an OU relation where from_date=to_date, which
            # is the case for a unit_interval lasting only for a single day.
            to_date=datetime_to_mo_end(unit_interval.end),
            org_unit=OrganisationUnitFilter(uuids=[unit_uuid]),
        )
    )

    objects = mo_rel_units.objects

    # Get the related unit interval endpoints as timeline datetimes
    endpoints = _get_related_units_endpoints(
        objects=objects, start=unit_interval.start, end=unit_interval.end
    )
    timeline_related_units = []
    for start, end in pairwise(endpoints):
        timeline_related_unit = _get_related_unit_at(
            objects=objects, unit_uuid=unit_uuid, at=start
        )
        if timeline_related_unit is None:
            timeline_related_unit = unknown_unit_uuid
        assert timeline_related_unit is not None
        timeline_related_units.append(
            EngagementUnit(
                start=start,
                end=end,
                value=timeline_related_unit,
            )
        )

    return timeline_related_units


async def create_association(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    sd_association_timeline: AssociationTimeline,
    start: datetime,
    end: datetime,
    association_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Create association",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    payload = AssociationCreateInput(
        user_key=user_key,
        person=person,
        org_unit=sd_association_timeline.association_unit.entity_at(start).value,
        association_type=association_type,
        validity=timeline_interval_to_mo_validity(start, end),
    )
    logger.debug("Create association payload", payload=payload.dict())

    if not dry_run:
        await gql_client.create_association(payload)
    logger.debug("Association created", person=str(person), user_key=user_key)


async def update_association(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    sd_association_timeline: AssociationTimeline,
    start: datetime,
    end: datetime,
    association_type: UUID,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Update association",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)
    logger.debug("mo_validity", mo_validity=mo_validity)

    association = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=start, to_date=end
        )
    )
    objects = association.objects
    obj = only(objects)

    if obj:
        # The association already exists in this validity period
        for validity in one(objects).validities:
            logger.debug("validity", validity=validity)
            payload = AssociationUpdateInput(
                uuid=obj.uuid,
                user_key=user_key,
                person=person,
                org_unit=sd_association_timeline.association_unit.entity_at(
                    start
                ).value,
                association_type=association_type,
                validity=get_patch_validity(
                    validity.validity.from_, validity.validity.to, mo_validity
                ),
            )
            logger.debug("Update association", payload=payload.dict())
            if not dry_run:
                await gql_client.update_association(payload)
            logger.debug("Association updated", person=str(person), user_key=user_key)
        return

    # The association does not already exist in this validity period
    association = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )
    payload = AssociationUpdateInput(
        uuid=one(association.objects).uuid,
        user_key=user_key,
        person=person,
        org_unit=sd_association_timeline.association_unit.entity_at(start).value,
        association_type=association_type,
        validity=mo_validity,
    )
    logger.debug("Update association payload", payload=payload.dict())

    if not dry_run:
        await gql_client.update_association(payload)
    logger.debug("Association updated", person=str(person), user_key=user_key)


async def terminate_association(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    start: datetime,
    end: datetime,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Terminate association",
        person=str(person),
        user_key=user_key,
        start=start,
        end=end,
    )

    mo_validity = timeline_interval_to_mo_validity(start, end)

    association = await gql_client.get_association_timeline(
        get_association_filter(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
    )
    association_uuid = one(association.objects).uuid

    if mo_validity.to is not None:
        payload = AssociationTerminateInput(
            uuid=association_uuid, from_=mo_validity.from_, to=mo_validity.to
        )
    else:
        payload = AssociationTerminateInput(
            uuid=association_uuid,
            # Converting from "from" to "to" due to the wierd way terminations in MO work
            to=mo_validity.from_ - timedelta(days=1),
        )
    logger.debug("Terminate association", payload=payload.dict())

    if not dry_run:
        await gql_client.terminate_association(payload)
    logger.debug("Association terminated", person=str(person), user_key=user_key)
