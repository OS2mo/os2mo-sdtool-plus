# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
import asyncio
from datetime import date
from itertools import pairwise
from typing import cast
from uuid import UUID

from fastramqpi.ramqp.depends import handle_exclusively_decorator
from more_itertools import first
from more_itertools import one
from sdclient.client import SDClient
from sdclient.exceptions import SDParentNotFound
from sdclient.exceptions import SDRootElementNotFound
from sdclient.requests import GetEmploymentChangedRequest

from sdtoolplus.autogenerated_graphql_client import EmployeeFilter
from sdtoolplus.autogenerated_graphql_client import EngagementFilter
from sdtoolplus.autogenerated_graphql_client import EventSendInput
from sdtoolplus.config import Mode
from sdtoolplus.config import SDToolPlusSettings
from sdtoolplus.depends import GraphQLClient
from sdtoolplus.exceptions import DepartmentParentsNotFoundError
from sdtoolplus.exceptions import DepartmentValidityExceedsParentsValiditiesError
from sdtoolplus.exceptions import HolesInDepartmentParentsTimelineError
from sdtoolplus.exceptions import NoValueError
from sdtoolplus.mo.timelines.engagement import create_engagement
from sdtoolplus.mo.timelines.engagement import get_engagement_filter
from sdtoolplus.mo.timelines.engagement import get_engagement_timeline
from sdtoolplus.mo.timelines.engagement import get_engagement_types
from sdtoolplus.mo.timelines.engagement import get_job_function
from sdtoolplus.mo.timelines.engagement import terminate_engagement
from sdtoolplus.mo.timelines.engagement import update_engagement
from sdtoolplus.mo.timelines.leave import get_leave_timeline as get_mo_leave_timeline
from sdtoolplus.mo.timelines.leave import terminate_leave_before_engagement_termination
from sdtoolplus.mo.timelines.related_unit import related_units
from sdtoolplus.mo_org_unit_importer import OrgUnitUUID
from sdtoolplus.models import EmploymentGraphQLEvent
from sdtoolplus.models import Engagement
from sdtoolplus.models import EngagementKey
from sdtoolplus.models import EngagementTimeline
from sdtoolplus.models import EngagementUnit
from sdtoolplus.models import LeaveTimeline
from sdtoolplus.models import Timeline
from sdtoolplus.models import UnitParent
from sdtoolplus.models import combine_intervals
from sdtoolplus.sd.timelines.common import sd_end_to_timeline_end
from sdtoolplus.sd.timelines.common import sd_start_to_timeline_start
from sdtoolplus.sd.timelines.employment import get_employment_timeline
from sdtoolplus.sd.timelines.employment import (
    get_leave_timeline as get_sd_leave_timeline,
)
from sdtoolplus.sync.association import sync_associations
from sdtoolplus.sync.leave import _sync_leave_intervals
from sdtoolplus.timeline import logger
from sdtoolplus.timeline import prefix_eng_user_key
from sdtoolplus.timeline import split_engagement_user_key
from sdtoolplus.types import CPRNumber


async def _sync_eng_intervals(
    gql_client: GraphQLClient,
    person: UUID,
    institution_identifier: str,
    employment_identifier: str,
    desired_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
    mo_leave_timeline: LeaveTimeline,
    settings: SDToolPlusSettings,
    dry_run: bool,
) -> None:
    user_key = prefix_eng_user_key(
        settings, employment_identifier, institution_identifier
    )

    logger.info(
        "Create, update or terminate engagement in MO",
        person=str(person),
        user_key=user_key,
    )

    # Get the engagement types
    eng_types = await get_engagement_types(gql_client)

    desired_interval_endpoints = desired_eng_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_eng_timeline.get_interval_endpoints()

    # There are occasionally bad data in the past resulting errors, which in turn
    # leads to missing a processing of current and future data (where the latter
    # are typically more important). We therefore process the timeline in reverse to
    # increase the probability of processing the most important data first.
    endpoints = sorted(
        desired_interval_endpoints.union(mo_interval_endpoints), reverse=True
    )
    logger.debug("List of endpoints", endpoints=endpoints)

    for end, start in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if desired_eng_timeline.equal_at(start, mo_eng_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = desired_eng_timeline.eng_active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_leave_before_engagement_termination(
                gql_client=gql_client,
                eng_term_start=start,
                eng_term_end=end,
                mo_leave_timeline=mo_leave_timeline,
                person=person,
                user_key=user_key,
            )
            await terminate_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not desired_eng_timeline.has_required_mo_values(start):
            logger.error("Cannot create/update engagement due to missing timeline data")
            continue

        mo_eng = await gql_client.get_engagement_timeline(
            get_engagement_filter(
                person=person, user_key=user_key, from_date=None, to_date=None
            )
        )
        if mo_eng.objects:
            await update_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                desired_eng_timeline=desired_eng_timeline,
                eng_types=eng_types,
                dry_run=dry_run,
            )
        else:
            await create_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                desired_eng_timeline=desired_eng_timeline,
                eng_types=eng_types,
                dry_run=dry_run,
            )

    logger.info(
        "Finished syncing engagement in MO",
        person=str(person),
        user_key=user_key,
    )


async def engagement_ou_strategy_elevate_to_ny_level(
    sd_client: SDClient,
    sd_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    Engagement OU strategy that elevates the engagement from the
    "Afdelings-niveau" to the parent "NY-niveau" as follows (the N-units represents
    NY-level units):

    SD emp unit:         |---------afd1----------|-----------afd2--------------|

    Parent (afd1):   |------N1-----|---N2---|------N3-----------------------------------
    Parent (afd2):           |-------N4-------|----N5----|----------N6-------------|-N7-

    Desired eng unit:    |----N1---|---N2---|-N3-|---N5--|----------N6---------|
    """
    logger.info("Applying OU elevate-to-NY-level strategy")

    # Find the OU parent timelines for each SD employment department (using sync HTTP
    # calls to spare the SD API)
    eng_unit_uuids: set[OrgUnitUUID] = set(
        eng_unit.value  # type: ignore
        for eng_unit in sd_eng_timeline.eng_unit.intervals
    )
    ou_parent_timelines: dict[OrgUnitUUID, Timeline[UnitParent]] = dict()
    for eng_unit_uuid in eng_unit_uuids:
        try:
            parents = await asyncio.to_thread(
                sd_client.get_department_parent_history,
                eng_unit_uuid,
            )
        except SDParentNotFound as error:
            logger.error(
                "Error getting department parent(s) from SD. "
                "Cannot elevate engagement to the above NY-level(s)",
                error=error,
                eng_unit_uuid=str(eng_unit_uuid),
            )
            raise DepartmentParentsNotFoundError(eng_unit_uuid)

        parent_intervals = tuple(
            UnitParent(
                start=sd_start_to_timeline_start(parent.startDate),
                end=sd_end_to_timeline_end(parent.endDate),
                value=parent.parentUuid,
            )
            for parent in parents
        )
        parent_timeline = Timeline[UnitParent](
            intervals=combine_intervals(parent_intervals)
        )

        if parent_timeline.has_holes():
            logger.error(
                "There are holes in the employment department parent timeline. "
                "Cannot elevate engagement to the above NY-level(s)",
                eng_unit_uuid=str(eng_unit_uuid),
            )
            raise HolesInDepartmentParentsTimelineError(eng_unit_uuid)

        ou_parent_timelines[eng_unit_uuid] = parent_timeline

    # Elevate the engagement to the parent unit, i.e. the NY-level just above the
    # current "Afdelings-niveau"
    desired_parent_intervals = []
    for eng_unit in sd_eng_timeline.eng_unit.intervals:
        # In this loop, we need to construct this desired engagement unit timeline
        # for each SD employment department (using afd1 as an example):
        # SD emp dep:          |---------afd1----------|
        # Parent (afd1):   |------N1-----|---N2---|------N3-----------------------
        # Desired eng unit:    |----N1---|---N2---|-N3-|

        parent_timeline = ou_parent_timelines[eng_unit.value]  # type: ignore
        parent_timeline_endpoints = parent_timeline.get_interval_endpoints()
        try:
            assert min(parent_timeline_endpoints) <= eng_unit.start
            assert max(parent_timeline_endpoints) >= eng_unit.end
        except AssertionError:
            logger.error("SD department validity exceeds parents validities")
            raise DepartmentValidityExceedsParentsValiditiesError()

        all_endpoints = sorted(
            parent_timeline_endpoints.union({eng_unit.start, eng_unit.end})
        )
        relevant_endpoints = [
            endpoint
            for endpoint in all_endpoints
            if eng_unit.start <= endpoint <= eng_unit.end
        ]

        for start, end in pairwise(relevant_endpoints):
            desired_parent_intervals.append(
                EngagementUnit(
                    start=start, end=end, value=parent_timeline.entity_at(start).value
                )
            )

    desired_eng_timeline = EngagementTimeline(
        eng_active=sd_eng_timeline.eng_active,
        eng_key=sd_eng_timeline.eng_key,
        eng_name=sd_eng_timeline.eng_name,
        eng_unit=Timeline[EngagementUnit](
            intervals=combine_intervals(tuple(desired_parent_intervals))
        ),
        eng_sd_unit=sd_eng_timeline.eng_sd_unit,
        eng_unit_id=sd_eng_timeline.eng_unit_id,
        eng_type=sd_eng_timeline.eng_type,
    )

    logger.debug(
        "Desired engagement timeline", desired_eng_timeline=desired_eng_timeline.dict()
    )

    logger.info("Done applying OU elevate-to-NY-level strategy")

    return desired_eng_timeline


async def engagement_ou_strategy_region(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    The engagement OU strategy for the regions works as follows:

    1) If the engagement already exists in MO, and if the unit is not "Unknown", the
       engagement will stay in the MO unit for the given interval.
    2) If the engagement is placed in "Unknown" in MO, we will attempt to place the
       engagement in a (random) related unit in the given interval.

    These two rules apply apart from the following exception. If the engagement SD unit
    UUID value changes (stored in MOs engagement attribute "extension_5"), we will
    re-calculate the engagement placement according to 2) above. As a consequence, *any*
    manual engagement changes in MO are overwritten in the given interval! This happens
    when the engagement is placed in a new department in SD. The following ASCII
    illustrates this latter scenario (the unit strings in the drawing actually
    represents unit UUIDs, but are written as strings in the drawing for better
    readability):

    MO (unit)     |------adm1-------|--------adm2---------|-------------adm3----------|
    MO (SD unit)  |------sd1--------|--------sd2----------|-------------sd3-----------|

    SD (unit)     |------sd1--------|------sd2----|------------sd4-----------|---sd3--|

    Re-calc       |------ok---------|------ok-----|--fix--|--------fix-------|---ok---|
    intervals
    """
    logger.info("Applying OU region strategy")
    assert settings.unknown_unit is not None

    sd_ou_only_timeline = EngagementTimeline(eng_unit=sd_eng_timeline.eng_unit)
    mo_ou_only_timeline = EngagementTimeline(eng_unit=mo_eng_timeline.eng_unit)

    sd_interval_endpoints = sd_ou_only_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_ou_only_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of engagement unit endpoints", endpoints=endpoints)

    # Get the MO unit for each endpoint interval or set to "Unknown", if no value is
    # found in MO in the interval
    unit_intervals = []
    for start, end in pairwise(endpoints):
        logger.debug(
            "Processing OU region strategy endpoint pair", start=start, end=end
        )
        try:
            entity = mo_eng_timeline.eng_unit.entity_at(start)
            unit = entity.value
            if settings.recalc_mo_unit_when_sd_employment_moved:
                # Overwrite (i.e. set to the unknown unit and hence recalculate below)
                # if the MO SD unit (extension_5) and the SD unit UUID are different
                # (see docstring ASCII)
                mo_sd_unit = mo_eng_timeline.eng_sd_unit.entity_at(start).value
                sd_unit = sd_eng_timeline.eng_unit.entity_at(start).value
                if not mo_sd_unit == sd_unit:
                    unit = settings.unknown_unit  # type: ignore
        except NoValueError:
            unit = settings.unknown_unit  # type: ignore
        unit_intervals.append(EngagementUnit(start=start, end=end, value=unit))

    logger.debug("Unit intervals", unit_intervals=unit_intervals)

    # Find the engagement unit(s) in all intervals
    related_unit_intervals = []
    for unit_interval in unit_intervals:
        if not unit_interval.value == settings.unknown_unit:
            related_unit_intervals.append(unit_interval)
        else:
            try:
                sd_unit = sd_eng_timeline.eng_unit.entity_at(unit_interval.start).value
            except NoValueError:
                related_unit_intervals.append(unit_interval)
                continue
            related_unit_intervals.extend(
                await related_units(
                    gql_client=gql_client,
                    unit_uuid=cast(OrgUnitUUID, sd_unit),
                    unit_interval=unit_interval,
                    unknown_unit_uuid=settings.unknown_unit,
                )
            )
    logger.debug(
        "Updated engagement units", related_unit_intervals=related_unit_intervals
    )

    desired_timeline = EngagementTimeline(
        eng_active=sd_eng_timeline.eng_active,
        eng_key=sd_eng_timeline.eng_key,
        eng_name=sd_eng_timeline.eng_name,
        eng_unit=Timeline[EngagementUnit](
            intervals=combine_intervals(tuple(related_unit_intervals))
        ),
        eng_sd_unit=sd_eng_timeline.eng_sd_unit,
        eng_unit_id=sd_eng_timeline.eng_unit_id,
        eng_type=sd_eng_timeline.eng_type,
    )
    logger.debug(
        "Desired engagement timeline", desired_timeline=desired_timeline.dict()
    )

    logger.info("Done applying OU region strategy")

    return desired_timeline


async def engagement_ou_strategy(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    Combined state/strategy pattern choosing an OU timeline strategy based on
    the state specified in the application settings.
    """
    if settings.mode == Mode.MUNICIPALITY:
        if settings.apply_ny_logic:
            return await engagement_ou_strategy_elevate_to_ny_level(
                sd_client, sd_eng_timeline
            )
        return sd_eng_timeline
    return await engagement_ou_strategy_region(
        gql_client=gql_client,
        settings=settings,
        sd_eng_timeline=sd_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
    )


async def fix_missing_job_functions(
    gql_client: GraphQLClient,
    sd_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    eng_key_intervals: list[EngagementKey] = []
    for interval in sd_eng_timeline.eng_key.intervals:
        job_function_user_key = cast(str, interval.value)
        try:
            await get_job_function(
                gql_client=gql_client,
                job_function_user_key=job_function_user_key,
            )
        except ValueError as error:
            if not str(error).startswith("too few items in iterable"):
                raise error

            logger.debug(
                "Job function not found. Defaulting to unknown",
                job_function_user_key=job_function_user_key,
            )

            eng_key_intervals.append(
                EngagementKey(
                    start=interval.start,
                    end=interval.end,
                    value="unknown",
                )
            )
            continue

        eng_key_intervals.append(interval)

    eng_key_timeline = Timeline[EngagementKey](
        intervals=combine_intervals(tuple(eng_key_intervals))
    )
    logger.debug("Engagement key timeline", eng_key_timeline=eng_key_timeline)

    desired_eng_timeline = EngagementTimeline(
        eng_active=sd_eng_timeline.eng_active,
        eng_key=eng_key_timeline,
        eng_name=sd_eng_timeline.eng_name,
        eng_unit=sd_eng_timeline.eng_unit,
        eng_sd_unit=sd_eng_timeline.eng_sd_unit,
        eng_unit_id=sd_eng_timeline.eng_unit_id,
        eng_type=sd_eng_timeline.eng_type,
    )

    return desired_eng_timeline


@handle_exclusively_decorator(
    key=lambda sd_client,
    gql_client,
    institution_identifier,
    cpr,
    employment_identifier,
    settings,
    dry_run=False: (institution_identifier, cpr, employment_identifier)
)
async def sync_engagement(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    cpr: str,
    employment_identifier: str,
    settings: SDToolPlusSettings,
    dry_run: bool = False,
) -> None:
    """
    Sync the entire engagement and leave timelines for the given CPR and
    SD EmploymentIdentifier (corresponding to the MO engagement user_key).

    Args:
        sd_client: The SD client
        gql_client: The GraphQL client
        institution_identifier: The SD institution identifier
        cpr: The person CPR number
        employment_identifier: The SD EmploymentIdentifier
        settings: The application settings
        dry_run: If true, nothing will be written to MO.
    """

    logger.info(
        "Sync engagement timeline",
        inst_id=institution_identifier,
        cpr=cpr,
        emp_id=employment_identifier,
        dry_run=dry_run,
    )

    if cpr.endswith("0000"):
        logger.warning(
            "Skipping engagement since CPR ends with 0000",
            institution_identifier=institution_identifier,
            cpr=cpr,
        )
        return

    try:
        r_employment = await asyncio.to_thread(
            sd_client.get_employment_changed,
            GetEmploymentChangedRequest(
                InstitutionIdentifier=institution_identifier,
                PersonCivilRegistrationIdentifier=cpr,
                EmploymentIdentifier=employment_identifier,
                ActivationDate=date.min,
                DeactivationDate=date.max,
                DepartmentIndicator=True,
                EmploymentStatusIndicator=True,
                ProfessionIndicator=True,
                WorkingTimeIndicator=True,
                UUIDIndicator=True,
            ),
        )
        sd_eng_timeline = get_employment_timeline(r_employment)
        sd_leave_timeline = get_sd_leave_timeline(r_employment)

        # Work-around for bug in SDs API (see https://redmine.magenta.dk/issues/64950)
        if sd_eng_timeline == EngagementTimeline():
            logger.warning(
                "Empty SD employment timeline. Skipping event",
                institution_identifier=institution_identifier,
                cpr=cpr,
                emp_id=employment_identifier,
            )
            return
    except SDRootElementNotFound as sd_error:
        logger.warning(
            "Could not read employment from SD",
            institution_identifier=institution_identifier,
            cpr=cpr,
            emp_id=employment_identifier,
            error=sd_error.error,
        )
        raise sd_error

    # Get the person
    r_person = await gql_client.get_person(CPRNumber(cpr))
    try:
        person = one(r_person.objects)
    except ValueError as error:
        logger.error(
            "Not exactly one person found",
            institution_identifier=institution_identifier,
            cpr=cpr,
            error=error,
        )
        raise error

    mo_eng_timeline = await get_engagement_timeline(
        gql_client=gql_client,
        person=person.uuid,
        user_key=prefix_eng_user_key(
            settings, employment_identifier, institution_identifier
        ),
    )

    desired_eng_timeline = await engagement_ou_strategy(
        sd_client=sd_client,
        gql_client=gql_client,
        settings=settings,
        sd_eng_timeline=sd_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
    )

    desired_eng_timeline = await fix_missing_job_functions(
        gql_client=gql_client,
        sd_eng_timeline=desired_eng_timeline,
    )

    mo_leave_timeline = await get_mo_leave_timeline(
        gql_client=gql_client,
        person=person.uuid,
        user_key=prefix_eng_user_key(
            settings, employment_identifier, institution_identifier
        ),
    )

    await _sync_eng_intervals(
        gql_client=gql_client,
        person=person.uuid,
        institution_identifier=institution_identifier,
        employment_identifier=employment_identifier,
        desired_eng_timeline=desired_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
        mo_leave_timeline=mo_leave_timeline,
        settings=settings,
        dry_run=dry_run,
    )

    # Sync leaves
    await _sync_leave_intervals(
        gql_client=gql_client,
        person=person.uuid,
        institution_identifier=institution_identifier,
        employment_identifier=employment_identifier,
        sd_leave_timeline=sd_leave_timeline,
        mo_leave_timeline=mo_leave_timeline,
        settings=settings,
        dry_run=dry_run,
    )

    await sync_associations(
        gql_client=gql_client,
        settings=settings,
        person=person.uuid,
        user_key=employment_identifier,
        desired_eng_timeline=desired_eng_timeline,
        dry_run=dry_run,
    )


async def queue_mo_engagements_for_sd_unit_sync(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    cpr: str | None,
    dry_run: bool,
) -> None:
    """
    Sync the SD unit to the MO engagement extension_5 attribute. All other engagement
    fields are also synchronized except for the engagement unit which is left unchanged.

    Args:
        gql_client: The GraphQL client
        settings: The application settings
        cpr: The person CPR number
        dry_run: If true, nothing will be written to MO.
    """
    logger.info(
        "Sync SD unit to MO engagement extension_5 attributes",
        cpr=cpr,
        dry_run=dry_run,
    )

    # Get all MO engagements
    eng_filter = EngagementFilter(from_date=None, to_date=None)
    if cpr is not None:
        eng_filter = EngagementFilter(
            employee=EmployeeFilter(cpr_numbers=[cpr]), from_date=None, to_date=None
        )

    engagements = []

    # Make a sequence of paginated GraphQL requests to get all MO engagement
    next_cursor = None
    while True:
        mo_engagement_batch = await gql_client.get_engagements(
            input=eng_filter,
            cursor=next_cursor,
            limit=300,
        )
        next_cursor = mo_engagement_batch.page_info.next_cursor

        for obj in mo_engagement_batch.objects:
            inst_id, emp_id = split_engagement_user_key(
                settings=settings,
                user_key=first(obj.validities).user_key,
            )
            try:
                eng = Engagement(
                    institution_identifier=inst_id,
                    cpr=one(first(obj.validities).person).cpr_number,
                    employment_identifier=emp_id,
                )
            except ValueError:
                logger.warn(
                    "Could not create object for queueing engagement for SD unit (extention_3) sync",
                    eng_obj=obj.dict(),
                )
                continue
            engagements.append(eng)

        logger.info("Number of engagements processed", n=len(engagements))

        if next_cursor is None:
            break

    for eng in engagements:
        logger.debug(
            "Queuing engagement for SD unit (extension_5) sync", engagement=eng.dict()
        )
        event = EventSendInput(
            namespace="sd",
            routing_key="employment",
            subject=EmploymentGraphQLEvent(
                institution_identifier=eng.institution_identifier,
                cpr=eng.cpr,
                employment_identifier=eng.employment_identifier,
            ).json(),
        )
        await gql_client.send_event(input=event)

    logger.info(
        f"Done queueing {len(engagements)} engagements for SD unit (extension_5) sync)"
    )
