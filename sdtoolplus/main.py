# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
import asyncio
import datetime
import re
from uuid import UUID

import structlog
from fastapi import APIRouter
from fastapi import BackgroundTasks
from fastapi import Depends
from fastapi import FastAPI
from fastapi import HTTPException
from fastapi import Response
from fastramqpi.events import GraphQLEvents
from fastramqpi.events import Listener
from fastramqpi.events import Namespace
from fastramqpi.main import FastRAMQPI
from fastramqpi.metrics import dipex_last_success_timestamp  # a Prometheus `Gauge`
from fastramqpi.os2mo_dar_client import AsyncDARClient
from more_itertools import first
from more_itertools import one
from sdclient.client import SDClient
from sdclient.requests import GetDepartmentRequest
from sdclient.responses import Department
from sqlalchemy import Engine
from starlette.status import HTTP_200_OK
from starlette.status import HTTP_422_UNPROCESSABLE_ENTITY
from starlette.status import HTTP_500_INTERNAL_SERVER_ERROR

from sdtoolplus.job_positions import sync_professions

from . import depends
from .addresses import AddressFixer
from .app import App
from .autogenerated_graphql_client import EventSendInput
from .autogenerated_graphql_client import GraphQLClient
from .config import SDToolPlusSettings
from .db.engine import get_engine
from .db.rundb import Status
from .db.rundb import delete_last_run
from .db.rundb import get_status
from .db.rundb import persist_status
from .depends import request_id
from .events import OrgGraphQLEvent
from .events import PersonGraphQLEvent
from .events import router as events_router
from .events import sd_amqp_lifespan
from .exceptions import EngagementSyncTemporarilyDisabled
from .minisync.api import minisync_router
from .mo_class import MOOrgUnitLevelMap
from .models import EngagementSyncPayload
from .models import OrgUnitSyncPayload
from .models import PersonSyncPayload
from .sd.person import get_all_sd_persons
from .timeline import sync_engagement
from .timeline import sync_mo_engagement_sd_units
from .timeline import sync_ou
from .timeline import sync_person
from .tree_tools import tree_as_string

logger = structlog.stdlib.get_logger()


async def run_db_start_operations(
    engine: Engine, dry_run: bool, response: Response
) -> dict | None:
    if dry_run:
        return None

    logger.info("Checking RunDB status...")
    status_last_run = await get_status(engine)
    if not status_last_run == Status.COMPLETED:
        logger.warn("Previous run did not complete successfully!")
        response.status_code = HTTP_500_INTERNAL_SERVER_ERROR
        return {"msg": "Previous run did not complete successfully!"}
    logger.info("Previous run completed successfully")

    await persist_status(engine, Status.RUNNING)

    return None


async def run_db_end_operations(engine: Engine, dry_run: bool) -> None:
    if not dry_run:
        await persist_status(engine, Status.COMPLETED)
    dipex_last_success_timestamp.set_to_current_time()


async def background_run(
    settings: SDToolPlusSettings,
    engine: Engine,
    inst_ids: list[str],
    org_unit: UUID | None = None,
    dry_run: bool = False,
) -> None:
    """
    Run org tree sync in background for all institutions.

    Args:
        settings: the SDToolPlusSettings
        engine: the SQLAlchemy DB engine
        inst_ids: list of the SD InstitutionIdentifiers
        org_unit: if not None, only run for this unit
        dry_run: if True, no changes will be written in MO
    """
    sdtoolplus: App = App(settings, first(inst_ids))

    for ii in inst_ids:
        logger.info("Starting background run", inst_id=ii)
        sdtoolplus.set_inst_id(ii)
        async for org_unit_node, mutation, result in sdtoolplus.execute(
            org_unit=org_unit, dry_run=dry_run
        ):
            logger.info(
                "Processed unit",
                org_unit_name=org_unit_node.name,
                org_unit_uuid=str(org_unit_node.uuid),
            )

        logger.info("Finished background run", inst_id=ii)

        # Send email notifications for illegal moves
        if settings.email_notifications_enabled and not dry_run:
            sdtoolplus.send_email_notification()

    await run_db_end_operations(engine, dry_run)
    logger.info("Run completed!")


def create_fastramqpi() -> FastRAMQPI:
    settings = SDToolPlusSettings()

    fastramqpi = FastRAMQPI(
        application_name="os2mo-sdtool-plus",
        settings=settings.fastramqpi,
        graphql_client_cls=GraphQLClient,
        graphql_version=25,
        graphql_events=GraphQLEvents(
            declare_namespaces=[
                Namespace(name="sd"),
            ],
            declare_listeners=[
                Listener(
                    namespace="sd",
                    user_key="employment",
                    routing_key="employment",
                    path="/events/sd/employment",
                ),
                Listener(
                    namespace="sd",
                    user_key="org",
                    routing_key="org",
                    path="/events/sd/org",
                ),
                Listener(
                    namespace="sd",
                    user_key="person",
                    routing_key="person",
                    path="/events/sd/person",
                ),
            ],
        ),
    )
    fastramqpi.add_context(settings=settings)

    engine = get_engine(settings)
    fastramqpi.add_context(engine=engine)

    sd_client = SDClient(
        sd_username=settings.sd_username,
        sd_password=settings.sd_password.get_secret_value(),
        use_test_env=settings.sd_use_test_env,
    )
    fastramqpi.add_context(sd_client=sd_client)

    if settings.sd_amqp is not None:
        fastramqpi.add_lifespan_manager(
            sd_amqp_lifespan(
                settings=settings.sd_amqp, context=fastramqpi.get_context()
            ),
            priority=1200,
        )

    fastapi_router = APIRouter(dependencies=[Depends(request_id)])

    @fastapi_router.get("/tree/mo")
    async def print_mo_tree(settings: depends.Settings) -> str:
        """
        For debugging problems. Prints the part of the MO tree that
        should be compared to the SD tree.
        """
        sdtoolplus: App = App(settings)
        mo_tree = sdtoolplus.get_mo_tree()
        return tree_as_string(mo_tree)

    @fastapi_router.get("/tree/sd")
    async def print_sd_tree(settings: depends.Settings) -> str:
        """
        For debugging problems. Prints the SD tree.
        """
        sdtoolplus: App = App(settings)
        mo_org_unit_level_map = MOOrgUnitLevelMap(sdtoolplus.session)
        sd_tree = await sdtoolplus.get_sd_tree(mo_org_unit_level_map)
        return tree_as_string(sd_tree)

    @fastapi_router.get("/rundb/status")
    async def rundb_get_status(engine: depends.Engine) -> int:
        """
        Get the RunDB status and return a job-runner.sh (curl) friendly integer
        status.

        Returns:
            0 if status is "completed", 1 if status is "running" and 3 in case of
            an error.
        """
        try:
            status = await get_status(engine)
            return 0 if status == Status.COMPLETED else 1
        except Exception:
            return 3

    @fastapi_router.post("/rundb/delete-last-run")
    async def rundb_delete_last_run(engine: depends.Engine):
        await delete_last_run(engine)
        return {"msg": "Last run deleted"}

    @fastapi_router.post("/persons/sync")
    async def sync_all_persons(
        sd_client: depends.SDClient,
        graphql_client: depends.GraphQLClient,
        institution_identifier: str,
    ) -> None:
        """
        Sync all persons in SD
        """
        logger.info("Syncing all SD persons")

        sd_persons = await get_all_sd_persons(
            sd_client=sd_client,
            institution_identifier=institution_identifier,
            effective_date=datetime.date.today(),
        )

        for person in sd_persons:
            logger.debug(
                "Syncing person",
                cpr=person.cpr,
                name=f"{person.given_name} {person.surname}",
            )
            await graphql_client.send_event(
                input=EventSendInput(
                    namespace="sd",
                    routing_key="person",
                    subject=PersonGraphQLEvent(
                        institution_identifier=institution_identifier,
                        cpr=person.cpr,
                    ).json(),
                )
            )

        logger.info("Done syncing all SD persons")

    @fastapi_router.post("/job-functions/sync")
    async def sync_job_functions(
        sd_client: depends.SDClient,
        graphql_client: depends.GraphQLClient,
        institution_identifier: str,
    ) -> None:
        await sync_professions(sd_client, graphql_client, institution_identifier)

    @fastapi_router.post("/trigger", status_code=HTTP_200_OK)
    async def trigger(
        settings: depends.Settings,
        engine: depends.Engine,
        response: Response,
        org_unit: UUID | None = None,
        inst_id: str | None = None,
        dry_run: bool = False,
    ) -> list[dict] | dict:
        logger.info("Starting run", org_unit=str(org_unit), dry_run=dry_run)

        run_db_start_operations_resp = await run_db_start_operations(
            engine, dry_run, response
        )
        if run_db_start_operations_resp is not None:
            return run_db_start_operations_resp

        sdtoolplus: App = App(settings, inst_id)

        results: list[dict] = [
            {
                "type": mutation.__class__.__name__,
                "unit": repr(org_unit_node),
                "mutation_result": str(result),
            }
            async for org_unit_node, mutation, result in sdtoolplus.execute(
                org_unit=org_unit, dry_run=dry_run
            )
        ]
        logger.info("Finished adding or updating org unit objects")

        # Send email notifications for illegal moves
        if settings.email_notifications_enabled and not dry_run:
            sdtoolplus.send_email_notification()

        await run_db_end_operations(engine, dry_run)
        logger.info("Run completed!")

        return results

    @fastapi_router.post("/trigger-all-inst-ids", status_code=HTTP_200_OK)
    async def trigger_all_inst_ids(
        settings: depends.Settings,
        engine: depends.Engine,
        response: Response,
        background_tasks: BackgroundTasks,
        org_unit: UUID | None = None,
        inst_id: str | None = None,
        dry_run: bool = False,
    ) -> dict[str, str]:
        logger.info("Starting run", org_unit=str(org_unit), dry_run=dry_run)

        run_db_start_operations_resp = await run_db_start_operations(
            engine, dry_run, response
        )
        if run_db_start_operations_resp is not None:
            return run_db_start_operations_resp

        if inst_id is not None:
            inst_ids = [inst_id]
        else:
            assert settings.mo_subtree_paths_for_root is not None
            inst_ids = list(settings.mo_subtree_paths_for_root.keys())

        background_tasks.add_task(
            background_run, settings, engine, inst_ids, org_unit, dry_run
        )

        return {"msg": "Org tree sync started in background"}

    @fastapi_router.post("/trigger/addresses", status_code=HTTP_200_OK)
    async def trigger_addresses(
        settings: depends.Settings,
        engine: depends.Engine,
        response: Response,
        gql_client: depends.GraphQLClient,
        org_unit: UUID | None = None,
        inst_id: str | None = None,
        dry_run: bool = False,
    ) -> list[dict] | dict:
        logger.info("Starting address run", org_unit=str(org_unit), dry_run=dry_run)

        run_db_start_operations_resp = await run_db_start_operations(
            engine, dry_run, response
        )
        if run_db_start_operations_resp is not None:
            return run_db_start_operations_resp

        addr_fixer = AddressFixer(
            gql_client,
            SDClient(
                settings.sd_username,
                settings.sd_password.get_secret_value(),
            ),
            AsyncDARClient(),
            settings,
            inst_id if inst_id is not None else settings.sd_institution_identifier,
        )

        results: list[dict] = [
            {
                "address_operation": operation.value,
                "address_type": addr.address_type.user_key,
                "unit": repr(org_unit_node),
                "address": addr.value,
            }
            async for operation, org_unit_node, addr in addr_fixer.fix_addresses(
                org_unit, dry_run
            )
        ]
        logger.info("Finished adding or updating org unit objects")

        await run_db_end_operations(engine, dry_run)
        logger.info("Run completed!")

        return results

    @fastapi_router.post("/timeline/sync/person", status_code=HTTP_200_OK)
    async def timeline_sync_person(
        sd_client: depends.SDClient,
        gql_client: depends.GraphQLClient,
        payload: PersonSyncPayload,
        dry_run: bool = False,
    ) -> dict:
        """Sync the person with the given CPR from the given institution identifier."""
        await sync_person(
            sd_client=sd_client,
            gql_client=gql_client,
            institution_identifier=payload.institution_identifier,
            cpr=payload.cpr,
            dry_run=dry_run,
        )

        return {"msg": "success"}

    @fastapi_router.post("/timeline/sync/engagement", status_code=HTTP_200_OK)
    async def timeline_sync_engagement(
        settings: depends.Settings,
        sd_client: depends.SDClient,
        gql_client: depends.GraphQLClient,
        payload: EngagementSyncPayload,
        dry_run: bool = False,
    ) -> dict:
        if not settings.recalc_mo_unit_when_sd_employment_moved:
            raise EngagementSyncTemporarilyDisabled()

        await sync_engagement(
            sd_client=sd_client,
            gql_client=gql_client,
            institution_identifier=payload.institution_identifier,
            cpr=payload.cpr,
            employment_identifier=payload.employment_identifier,
            settings=settings,
            dry_run=dry_run,
        )
        return {"msg": "success"}

    @fastapi_router.post("/timeline/sync/ou", status_code=HTTP_200_OK)
    async def timeline_sync_ou(
        settings: depends.Settings,
        sd_client: depends.SDClient,
        gql_client: depends.GraphQLClient,
        payload: OrgUnitSyncPayload,
        dry_run: bool = False,
    ) -> dict:
        await sync_ou(
            sd_client=sd_client,
            gql_client=gql_client,
            institution_identifier=payload.institution_identifier,
            org_unit=payload.org_unit,
            settings=settings,
            dry_run=dry_run,
        )
        return {"msg": "success"}

    @fastapi_router.post(
        "/timeline/sync/engagement/mo-sd-units", status_code=HTTP_200_OK
    )
    async def timeline_sync_engagement_mo_sd_unit(
        settings: depends.Settings,
        sd_client: depends.SDClient,
        gql_client: depends.GraphQLClient,
        background_tasks: BackgroundTasks,
        cpr: str | None = None,
        dry_run: bool = False,
    ) -> dict:
        if settings.recalc_mo_unit_when_sd_employment_moved:
            raise HTTPException(
                status_code=HTTP_422_UNPROCESSABLE_ENTITY,
                detail="MO SD unit sync not allowed when RECALC_MO_UNIT_WHEN_SD_EMPLOYMENT_MOVED is true",
            )

        background_tasks.add_task(
            sync_mo_engagement_sd_units,
            sd_client=sd_client,
            gql_client=gql_client,
            settings=settings,
            cpr=cpr,
            dry_run=dry_run,
        )

        return {"msg": "Sync started in background"}
    @fastapi_router.post("/timeline/sync/ou/all", status_code=HTTP_200_OK)
    async def full_timeline_sync_ous(
        settings: depends.Settings,
        sd_client: depends.SDClient,
        gql_client: depends.GraphQLClient,
        institution_identifier: str,
        dry_run: bool = False,
    ) -> dict:
        # TODO: This only works when all unit_levels are integers
        ny_regex = re.compile(r"NY(\d)-niveau")
        # Set priority on org_unit events such that top-level units are imported first.
        default_priority = 10_000

        def priority_from_level(department: Department) -> int:
            if department.DepartmentLevelIdentifier == "Afdelings-niveau":
                return default_priority
            match = ny_regex.match(department.DepartmentLevelIdentifier)
            assert match
            priority = default_priority - int(one(match.groups()))
            return priority

        departments = await asyncio.to_thread(
            sd_client.get_department,
            GetDepartmentRequest(
                InstitutionIdentifier=institution_identifier,
                ActivationDate=datetime.datetime.min,
                DeactivationDate=datetime.datetime.max,
                DepartmentNameIndicator=False,
                UUIDIndicator=True,
                PostalAddressIndicator=False,
            ),
        )
        if dry_run:
            logger.info(
                f"Dry-run. Would create {len(departments.Department)} org_unit events"
            )
            return {"msg": "success"}

        events = [
            EventSendInput(
                namespace="sd",
                routing_key="org_unit",
                subject=OrgGraphQLEvent(
                    institution_identifier=institution_identifier,
                    org_unit=d.DepartmentUUIDIdentifier,
                ).json(),
                priority=priority_from_level(d),
            )
            for d in departments.Department
        ]

        await asyncio.gather(*[gql_client.send_event(input=e) for e in events])

        return {"msg": "success"}

    app = fastramqpi.get_app()
    app.include_router(fastapi_router)
    app.include_router(minisync_router)
    app.include_router(events_router)

    return fastramqpi


def create_app() -> FastAPI:
    fastramqpi = create_fastramqpi()
    return fastramqpi.get_app()
