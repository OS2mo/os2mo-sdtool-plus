# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
import asyncio
from datetime import date
from datetime import datetime
from itertools import pairwise
from uuid import UUID

import structlog
from fastramqpi.ramqp.depends import handle_exclusively_decorator
from more_itertools import first
from more_itertools import one
from more_itertools import only
from pydantic import BaseModel
from sdclient.client import SDClient
from sdclient.exceptions import SDParentNotFound
from sdclient.exceptions import SDRootElementNotFound
from sdclient.requests import GetEmploymentChangedRequest
from sdclient.responses import GetDepartmentResponse

from sdtoolplus.autogenerated_graphql_client import ClassFilter
from sdtoolplus.autogenerated_graphql_client import EmployeeFilter
from sdtoolplus.autogenerated_graphql_client import EngagementFilter
from sdtoolplus.autogenerated_graphql_client import EventSendInput
from sdtoolplus.autogenerated_graphql_client import LeaveFilter
from sdtoolplus.autogenerated_graphql_client.get_person_timeline import (
    GetPersonTimelineEmployees,
)
from sdtoolplus.depends import GraphQLClient
from sdtoolplus.exceptions import ClassNotFoundError
from sdtoolplus.exceptions import DepartmentParentsNotFoundError
from sdtoolplus.exceptions import DepartmentTimelineNotFoundError
from sdtoolplus.exceptions import DepartmentValidityExceedsParentsValiditiesError
from sdtoolplus.exceptions import HolesInDepartmentParentsTimelineError
from sdtoolplus.exceptions import MoreThanOneClassError
from sdtoolplus.exceptions import MoreThanOneEngagementError
from sdtoolplus.exceptions import MoreThanOnePersonError
from sdtoolplus.exceptions import NoValueError
from sdtoolplus.exceptions import PersonNotFoundError
from sdtoolplus.mo.timeline import create_association
from sdtoolplus.mo.timeline import create_engagement
from sdtoolplus.mo.timeline import create_leave
from sdtoolplus.mo.timeline import create_ou
from sdtoolplus.mo.timeline import create_person
from sdtoolplus.mo.timeline import create_phone_number
from sdtoolplus.mo.timeline import create_pnumber_address
from sdtoolplus.mo.timeline import create_postal_address
from sdtoolplus.mo.timeline import delete_address
from sdtoolplus.mo.timeline import get_association_filter
from sdtoolplus.mo.timeline import (
    get_association_timeline as get_mo_association_timeline,
)
from sdtoolplus.mo.timeline import get_class
from sdtoolplus.mo.timeline import get_engagement_timeline
from sdtoolplus.mo.timeline import get_engagement_types
from sdtoolplus.mo.timeline import get_ou_timeline
from sdtoolplus.mo.timeline import (
    get_phone_number_timeline as get_mo_phone_number_timeline,
)
from sdtoolplus.mo.timeline import get_pnumber_timeline as get_mo_pnumber_timeline
from sdtoolplus.mo.timeline import (
    get_postal_address_timeline as get_mo_postal_address_timeline,
)
from sdtoolplus.mo.timeline import related_units
from sdtoolplus.mo.timeline import terminate_association
from sdtoolplus.mo.timeline import terminate_engagement
from sdtoolplus.mo.timeline import terminate_leave
from sdtoolplus.mo.timeline import terminate_ou
from sdtoolplus.mo.timeline import update_association
from sdtoolplus.mo.timeline import update_engagement
from sdtoolplus.mo.timeline import update_leave
from sdtoolplus.mo.timeline import update_ou
from sdtoolplus.mo.timeline import update_person
from sdtoolplus.mo_org_unit_importer import OrgUnitUUID
from sdtoolplus.models import EmploymentGraphQLEvent
from sdtoolplus.models import EngagementTimeline
from sdtoolplus.models import EngagementUnit
from sdtoolplus.models import LeaveTimeline
from sdtoolplus.models import Person
from sdtoolplus.models import Timeline
from sdtoolplus.models import UnitId
from sdtoolplus.models import UnitParent
from sdtoolplus.models import UnitPhoneNumber
from sdtoolplus.models import UnitPNumber
from sdtoolplus.models import UnitPostalAddress
from sdtoolplus.models import UnitTimeline
from sdtoolplus.models import combine_intervals
from sdtoolplus.sd.person import get_sd_person
from sdtoolplus.sd.timeline import (
    get_association_timeline as get_sd_association_timeline,
)
from sdtoolplus.sd.timeline import get_department
from sdtoolplus.sd.timeline import get_department_timeline
from sdtoolplus.sd.timeline import get_employment_timeline
from sdtoolplus.sd.timeline import (
    get_phone_number_timeline as get_sd_phone_number_timeline,
)
from sdtoolplus.sd.timeline import get_pnumber_timeline as get_sd_pnumber_timeline
from sdtoolplus.sd.timeline import (
    get_postal_address_timeline as get_sd_postal_address_timeline,
)
from sdtoolplus.sd.timeline import sd_end_to_timeline_end
from sdtoolplus.sd.timeline import sd_start_to_timeline_start
from sdtoolplus.types import CPRNumber

from .config import Mode
from .config import SDToolPlusSettings
from .mo.timeline import get_leave_timeline as get_mo_leave_timeline
from .sd.timeline import get_leave_timeline as get_sd_leave_timeline

logger = structlog.stdlib.get_logger()


def _sd_inst_id_prefix(key: str, inst_id: str) -> str:
    return f"{inst_id}-{key}"


def _prefix_eng_user_key(
    settings: SDToolPlusSettings, user_key: str, inst_id: str
) -> str:
    if settings.mode == Mode.MUNICIPALITY:
        return user_key
    return _sd_inst_id_prefix(user_key, inst_id)


def _split_engagement_user_key(
    settings: SDToolPlusSettings, user_key: str
) -> tuple[str, str]:
    if settings.mode == Mode.MUNICIPALITY:
        return settings.sd_institution_identifier, user_key
    institution_identifier, employment_id = user_key.split("-")
    return institution_identifier, employment_id


def prefix_unit_id_with_inst_id(
    settings: SDToolPlusSettings, unit_timeline: UnitTimeline, inst_id: str
) -> UnitTimeline:
    if settings.mode == Mode.MUNICIPALITY:
        return unit_timeline

    unit_id_intervals = tuple(
        UnitId(
            start=interval.start,
            end=interval.end,
            value=_sd_inst_id_prefix(interval.value, inst_id),  # type: ignore
        )
        for interval in unit_timeline.unit_id.intervals
    )

    prefixed_unit_timeline = UnitTimeline(
        active=unit_timeline.active,
        name=unit_timeline.name,
        unit_id=Timeline[UnitId](intervals=unit_id_intervals),
        unit_level=unit_timeline.unit_level,
        parent=unit_timeline.parent,
    )
    logger.debug(
        "SD timeline with prefixed unit_id", timeline=prefixed_unit_timeline.dict()
    )

    return prefixed_unit_timeline


async def _sync_person(
    gql_client: GraphQLClient,
    sd_person: Person,
    mo_person: GetPersonTimelineEmployees,
    dry_run: bool,
) -> None:
    mo_objects = only(mo_person.objects, too_long=MoreThanOnePersonError)
    if mo_objects is None:
        await create_person(
            gql_client=gql_client,
            cpr=sd_person.cpr,
            givenname=sd_person.given_name,
            lastname=sd_person.surname,
            dry_run=dry_run,
        )
        return
    mo_validities = mo_objects.validities

    if (
        len(mo_validities) > 1
        or one(mo_validities).given_name != sd_person.given_name
        or one(mo_validities).surname != sd_person.surname
    ):
        await update_person(
            gql_client=gql_client,
            uuid=one(mo_person.objects).uuid,
            start=datetime.today(),
            person=sd_person,
            dry_run=dry_run,
        )


@handle_exclusively_decorator(
    key=lambda sd_client, gql_client, institution_identifier, cpr, dry_run=False: cpr
)
async def sync_person(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    cpr: str,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Sync person",
        inst_id=institution_identifier,
        cpr=cpr,
        dry_run=dry_run,
    )
    try:
        sd_person = await get_sd_person(
            sd_client=sd_client,
            institution_identifier=institution_identifier,
            cpr=cpr,
            effective_date=datetime.today(),
        )
    except SDRootElementNotFound:
        raise PersonNotFoundError()

    mo_person = await gql_client.get_person_timeline(
        filter=EmployeeFilter(
            cpr_numbers=[cpr], from_date=datetime.today(), to_date=None
        )
    )
    logger.debug("MO person", mo_person=mo_person.dict())

    await _sync_person(
        gql_client=gql_client,
        mo_person=mo_person,
        sd_person=sd_person,
        dry_run=dry_run,
    )

    logger.info("Done syncing person!")


async def _sync_eng_intervals(
    gql_client: GraphQLClient,
    person: UUID,
    institution_identifier: str,
    employment_identifier: str,
    desired_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
    settings: SDToolPlusSettings,
    dry_run: bool,
) -> None:
    user_key = _prefix_eng_user_key(
        settings, employment_identifier, institution_identifier
    )

    logger.info(
        "Create, update or terminate engagement in MO",
        person=str(person),
        user_key=user_key,
    )

    # Get the engagement types
    eng_types = await get_engagement_types(gql_client)

    desired_interval_endpoints = desired_eng_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_eng_timeline.get_interval_endpoints()

    endpoints = sorted(desired_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if desired_eng_timeline.equal_at(start, mo_eng_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = desired_eng_timeline.eng_active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not desired_eng_timeline.has_required_mo_values(start):
            logger.error("Cannot create/update engagement due to missing timeline data")
            continue

        mo_eng = await gql_client.get_engagement_timeline(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
        if mo_eng.objects:
            await update_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                desired_eng_timeline=desired_eng_timeline,
                eng_types=eng_types,
                dry_run=dry_run,
            )
        else:
            await create_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                desired_eng_timeline=desired_eng_timeline,
                eng_types=eng_types,
                dry_run=dry_run,
            )

    logger.info(
        "Finished syncing engagement in MO",
        person=str(person),
        user_key=user_key,
    )


async def _sync_leave_intervals(
    gql_client: GraphQLClient,
    person: UUID,
    institution_identifier: str,
    employment_identifier: str,
    sd_leave_timeline: LeaveTimeline,
    mo_leave_timeline: LeaveTimeline,
    settings: SDToolPlusSettings,
    dry_run: bool,
) -> None:
    user_key = _prefix_eng_user_key(
        settings, employment_identifier, institution_identifier
    )

    logger.info(
        "Create, update or terminate leave in MO",
        person=str(person),
        user_key=user_key,
    )

    # Get the leave type (assuming for now that there is only one)
    r_leave_type = await gql_client.get_class(ClassFilter(user_keys=["Orlov"]))
    leave_type = one(
        r_leave_type.objects,
        too_short=ClassNotFoundError,
        too_long=MoreThanOneClassError,
    ).uuid

    # Get the corresponding engagement
    mo_eng = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=None, to_date=None
    )
    eng_obj = only(mo_eng.objects, too_long=MoreThanOneEngagementError)
    if eng_obj is None:
        logger.warning("Not syncing leaves - no corresponding engagement found")
        return
    eng_uuid = eng_obj.uuid

    sd_interval_endpoints = sd_leave_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_leave_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if sd_leave_timeline.equal_at(start, mo_leave_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = sd_leave_timeline.leave_active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_leave(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not sd_leave_timeline.has_required_mo_values(start):
            logger.error("Cannot create/update leave due to missing timeline data")
            continue

        mo_leave = await gql_client.get_leave(
            LeaveFilter(
                employee=EmployeeFilter(uuids=[person]),
                user_keys=[user_key],
                from_date=None,
                to_date=None,
            )
        )
        if mo_leave.objects:
            await update_leave(
                gql_client=gql_client,
                person=person,
                eng_uuid=eng_uuid,
                user_key=user_key,
                start=start,
                end=end,
                sd_leave_timeline=sd_leave_timeline,
                leave_type=leave_type,
                dry_run=dry_run,
            )
        else:
            await create_leave(
                gql_client=gql_client,
                person=person,
                eng_uuid=eng_uuid,
                user_key=user_key,
                start=start,
                end=end,
                sd_leave_timeline=sd_leave_timeline,
                leave_type=leave_type,
                dry_run=dry_run,
            )

    logger.info(
        "Finished syncing leave in MO",
        person=str(person),
        user_key=user_key,
    )


def patch_missing_parents(
    settings: SDToolPlusSettings,
    desired_unit_timeline: UnitTimeline,
) -> UnitTimeline:
    """
    In some cases, an SD unit does not have a parent in its entire validity
    interval. This function patches the unit timeline with the parent "Unknown"
    in the intervals, where the SD unit does not have a parent.
    """
    # TODO: handle this for the municipality case
    assert settings.mode == Mode.REGION

    endpoints = sorted(desired_unit_timeline.get_interval_endpoints())
    parent_intervals = []
    for start, end in pairwise(endpoints):
        try:
            desired_unit_timeline.active.entity_at(start)
        except NoValueError:
            continue
        try:
            parent_uuid = desired_unit_timeline.parent.entity_at(start).value
        except NoValueError:
            parent_uuid = settings.unknown_unit  # type: ignore
        parent_intervals.append(
            UnitParent(
                start=start,
                end=end,
                value=parent_uuid,
            )
        )

    return UnitTimeline(
        active=desired_unit_timeline.active,
        name=desired_unit_timeline.name,
        unit_id=desired_unit_timeline.unit_id,
        unit_level=desired_unit_timeline.unit_level,
        parent=Timeline[UnitParent](
            intervals=combine_intervals(tuple(parent_intervals))
        ),
    )


async def _sync_ou_intervals(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    org_unit: OrgUnitUUID,
    desired_unit_timeline: UnitTimeline,
    mo_unit_timeline: UnitTimeline,
    institution_identifier: str,
    priority: int,
    dry_run: bool,
) -> bool:
    logger.info(
        "Create, update or terminate OU in MO",
        org_unit=str(org_unit),
        priority=priority,
    )

    # Skip synchronisation if OU was never in SD. This ensures we don't delete
    # org-units unrelated to SD in MO. Note that is *is* technically possible
    # to delete OUs in SD, but in that case we don't receive an AMQP event
    # anyway due to limitations in SD.
    if desired_unit_timeline == UnitTimeline():
        logger.debug("Skipping sync of OU")
        return False

    sd_interval_endpoints = desired_unit_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_unit_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if desired_unit_timeline.equal_at(start, mo_unit_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = desired_unit_timeline.active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_ou(
                gql_client=gql_client,
                org_unit=org_unit,
                start=start,
                end=end,
                institution_identifier=institution_identifier,
                priority=priority,
                dry_run=dry_run,
            )
            continue

        if not desired_unit_timeline.has_required_mo_values(start):
            logger.error("Cannot update OU due to missing timeline data")
            return False

        ou = await gql_client.get_org_unit_timeline(
            unit_uuid=org_unit, from_date=None, to_date=None
        )
        if ou.objects:
            await update_ou(
                gql_client=gql_client,
                org_unit=org_unit,
                start=start,
                end=end,
                desired_unit_timeline=desired_unit_timeline,
                org_unit_type_user_key=settings.org_unit_type,
                institution_identifier=institution_identifier,
                priority=priority,
                dry_run=dry_run,
            )
        else:
            await create_ou(
                gql_client=gql_client,
                org_unit=org_unit,
                start=start,
                end=end,
                desired_unit_timeline=desired_unit_timeline,
                org_unit_type_user_key=settings.org_unit_type,
                institution_identifier=institution_identifier,
                priority=priority,
                dry_run=dry_run,
            )

        logger.info("Finished updating unit in interval", org_unit=str(org_unit))

    logger.info("Finished syncing unit", org_unit=str(org_unit))
    return True


async def _sync_association_intervals(
    gql_client: GraphQLClient,
    person: UUID,
    user_key: str,
    desired_eng_timeline: EngagementTimeline,
    dry_run: bool,
) -> None:
    """
    Make an association to the unit where the person is employed in SD.
    """
    logger.info(
        "Create, update or terminate association in MO",
        person=str(person),
        user_key=user_key,
    )

    # Get the association type (assuming for now that there is only one)
    association_type_uuid = await get_class(
        gql_client=gql_client,
        facet_user_key="association_type",
        # TODO: check if class_user_keys is municipality dependent
        class_user_key="SD-medarbejder",
    )

    sd_association_timeline = get_sd_association_timeline(desired_eng_timeline)
    mo_association_timeline = await get_mo_association_timeline(
        gql_client=gql_client,
        person=person,
        user_key=user_key,
    )

    sd_interval_endpoints = sd_association_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_association_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if sd_association_timeline.equal_at(start, mo_association_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = sd_association_timeline.association_active.entity_at(
                start
            ).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_association(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not sd_association_timeline.has_required_mo_values(start):
            logger.error(
                "Cannot create/update association due to missing timeline data"
            )
            continue

        mo_association = await gql_client.get_association_timeline(
            get_association_filter(
                person=person, user_key=user_key, from_date=None, to_date=None
            )
        )

        if mo_association.objects:
            await update_association(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                sd_association_timeline=sd_association_timeline,
                start=start,
                end=end,
                association_type=association_type_uuid,
                dry_run=dry_run,
            )
        else:
            await create_association(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                sd_association_timeline=sd_association_timeline,
                start=start,
                end=end,
                association_type=association_type_uuid,
                dry_run=dry_run,
            )

    logger.info(
        "Finished syncing association in MO",
        person=str(person),
        user_key=user_key,
    )


async def sync_associations(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    person: UUID,
    user_key: str,
    desired_eng_timeline: EngagementTimeline,
    dry_run: bool,
) -> None:
    """
    Sync associations (state pattern choosing a strategy based on the application
    settings).
    """
    if settings.apply_ny_logic:
        await _sync_association_intervals(
            gql_client=gql_client,
            person=person,
            user_key=user_key,
            desired_eng_timeline=desired_eng_timeline,
            dry_run=dry_run,
        )


async def _sync_ou_pnumber(
    gql_client: GraphQLClient,
    department: GetDepartmentResponse,
    org_unit: OrgUnitUUID,
    dry_run: bool,
) -> None:
    logger.info("Sync P-number timeline", org_unit=str(org_unit))

    sd_pnumber_timeline = get_sd_pnumber_timeline(department)
    mo_pnumber_timeline_obj = await get_mo_pnumber_timeline(
        gql_client=gql_client,
        unit_uuid=org_unit,
    )

    if sd_pnumber_timeline == mo_pnumber_timeline_obj.pnumber:
        logger.debug("P-number timelines identical")
        return

    if mo_pnumber_timeline_obj.uuid is not None:
        await delete_address(
            gql_client=gql_client,
            address_uuid=mo_pnumber_timeline_obj.uuid,
            dry_run=dry_run,
        )

    if sd_pnumber_timeline == Timeline[UnitPNumber]():
        return

    await create_pnumber_address(
        gql_client=gql_client,
        org_unit=org_unit,
        address_uuid=mo_pnumber_timeline_obj.uuid,
        sd_pnumber_timeline=sd_pnumber_timeline,
        dry_run=dry_run,
    )


async def _sync_ou_postal_address(
    gql_client: GraphQLClient,
    department: GetDepartmentResponse,
    org_unit: OrgUnitUUID,
    dry_run: bool,
) -> None:
    logger.info("Sync postal address timeline", org_unit=str(org_unit))

    sd_postal_address_timeline = get_sd_postal_address_timeline(department)
    mo_postal_address_timeline_obj = await get_mo_postal_address_timeline(
        gql_client=gql_client,
        unit_uuid=org_unit,
    )

    if sd_postal_address_timeline == mo_postal_address_timeline_obj.postal_address:
        logger.debug("Postal address timelines identical")
        return

    if mo_postal_address_timeline_obj.uuid is not None:
        await delete_address(
            gql_client=gql_client,
            address_uuid=mo_postal_address_timeline_obj.uuid,
            dry_run=dry_run,
        )

    if sd_postal_address_timeline == Timeline[UnitPostalAddress]():
        return

    await create_postal_address(
        gql_client=gql_client,
        org_unit=org_unit,
        address_uuid=mo_postal_address_timeline_obj.uuid,
        sd_postal_address_timeline=sd_postal_address_timeline,
        dry_run=dry_run,
    )


async def _sync_ou_phone_number(
    gql_client: GraphQLClient,
    department: GetDepartmentResponse,
    org_unit: OrgUnitUUID,
    dry_run: bool,
) -> None:
    logger.info("Sync phone number timeline", org_unit=str(org_unit))

    sd_phone_number_timeline = get_sd_phone_number_timeline(department)
    mo_phone_number_timeline_obj = await get_mo_phone_number_timeline(
        gql_client=gql_client,
        unit_uuid=org_unit,
    )

    if sd_phone_number_timeline == mo_phone_number_timeline_obj.phone_number:
        logger.debug("Phone number timelines identical")
        return

    if mo_phone_number_timeline_obj.uuid is not None:
        await delete_address(
            gql_client=gql_client,
            address_uuid=mo_phone_number_timeline_obj.uuid,
            dry_run=dry_run,
        )

    if sd_phone_number_timeline == Timeline[UnitPhoneNumber]():
        return

    await create_phone_number(
        gql_client=gql_client,
        org_unit=org_unit,
        address_uuid=mo_phone_number_timeline_obj.uuid,
        sd_phone_number_timeline=sd_phone_number_timeline,
        dry_run=dry_run,
    )


@handle_exclusively_decorator(
    key=lambda sd_client,
    gql_client,
    institution_identifier,
    org_unit,
    settings,
    priority,
    dry_run=False: org_unit
)
async def sync_ou(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    org_unit: OrgUnitUUID,
    settings: SDToolPlusSettings,
    priority: int,
    dry_run: bool = False,
) -> None:
    """Sync the entire org unit timeline for the given unit."""
    logger.info(
        "Sync OU timeline",
        institution_identifier=institution_identifier,
        org_uuid=str(org_unit),
        dry_run=dry_run,
    )

    department = await get_department(
        sd_client=sd_client,
        institution_identifier=institution_identifier,
        unit_uuid=org_unit,
    )

    sd_unit_timeline = await get_department_timeline(
        department=department,
        sd_client=sd_client,
        inst_id=institution_identifier,
        unit_uuid=org_unit,
    )
    desired_unit_timeline = prefix_unit_id_with_inst_id(
        settings, sd_unit_timeline, institution_identifier
    )
    desired_unit_timeline = patch_missing_parents(settings, desired_unit_timeline)

    mo_unit_timeline = await get_ou_timeline(gql_client, org_unit)

    ou_sync_successful = await _sync_ou_intervals(
        gql_client=gql_client,
        settings=settings,
        org_unit=org_unit,
        desired_unit_timeline=desired_unit_timeline,
        mo_unit_timeline=mo_unit_timeline,
        institution_identifier=institution_identifier,
        priority=priority,
        dry_run=dry_run,
    )

    if department is not None and ou_sync_successful:
        logger.info("Syncing OU addresses", org_unit=str(org_unit))

        await _sync_ou_pnumber(
            gql_client=gql_client,
            department=department,
            org_unit=org_unit,
            dry_run=dry_run,
        )

        await _sync_ou_postal_address(
            gql_client=gql_client,
            department=department,
            org_unit=org_unit,
            dry_run=dry_run,
        )

        await _sync_ou_phone_number(
            gql_client=gql_client,
            department=department,
            org_unit=org_unit,
            dry_run=dry_run,
        )

        logger.info("Finished syncing OU addresses", org_unit=str(org_unit))


async def engagement_ou_strategy_elevate_to_ny_level(
    sd_client: SDClient,
    sd_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    Engagement OU strategy that elevates the engagement from the
    "Afdelings-niveau" to the parent "NY-niveau" as follows (the N-units represents
    NY-level units):

    SD emp unit:         |---------afd1----------|-----------afd2--------------|

    Parent (afd1):   |------N1-----|---N2---|------N3-----------------------------------
    Parent (afd2):           |-------N4-------|----N5----|----------N6-------------|-N7-

    Desired eng unit:    |----N1---|---N2---|-N3-|---N5--|----------N6---------|
    """
    logger.info("Applying OU elevate-to-NY-level strategy")

    # Find the OU parent timelines for each SD employment department (using sync HTTP
    # calls to spare the SD API)
    eng_unit_uuids: set[OrgUnitUUID] = set(
        eng_unit.value  # type: ignore
        for eng_unit in sd_eng_timeline.eng_unit.intervals
    )
    ou_parent_timelines: dict[OrgUnitUUID, Timeline[UnitParent]] = dict()
    for eng_unit_uuid in eng_unit_uuids:
        try:
            parents = await asyncio.to_thread(
                sd_client.get_department_parent_history,
                eng_unit_uuid,
            )
        except SDParentNotFound as error:
            logger.error(
                "Error getting department parent(s) from SD. "
                "Cannot elevate engagement to the above NY-level(s)",
                error=error,
                eng_unit_uuid=str(eng_unit_uuid),
            )
            raise DepartmentParentsNotFoundError(eng_unit_uuid)

        parent_intervals = tuple(
            UnitParent(
                start=sd_start_to_timeline_start(parent.startDate),
                end=sd_end_to_timeline_end(parent.endDate),
                value=parent.parentUuid,
            )
            for parent in parents
        )
        parent_timeline = Timeline[UnitParent](
            intervals=combine_intervals(parent_intervals)
        )

        if parent_timeline.has_holes():
            logger.error(
                "There are holes in the employment department parent timeline. "
                "Cannot elevate engagement to the above NY-level(s)",
                eng_unit_uuid=str(eng_unit_uuid),
            )
            raise HolesInDepartmentParentsTimelineError(eng_unit_uuid)

        ou_parent_timelines[eng_unit_uuid] = parent_timeline

    # Elevate the engagement to the parent unit, i.e. the NY-level just above the
    # current "Afdelings-niveau"
    desired_parent_intervals = []
    for eng_unit in sd_eng_timeline.eng_unit.intervals:
        # In this loop, we need to construct this desired engagement unit timeline
        # for each SD employment department (using afd1 as an example):
        # SD emp dep:          |---------afd1----------|
        # Parent (afd1):   |------N1-----|---N2---|------N3-----------------------
        # Desired eng unit:    |----N1---|---N2---|-N3-|

        parent_timeline = ou_parent_timelines[eng_unit.value]  # type: ignore
        parent_timeline_endpoints = parent_timeline.get_interval_endpoints()
        try:
            assert min(parent_timeline_endpoints) <= eng_unit.start
            assert max(parent_timeline_endpoints) >= eng_unit.end
        except AssertionError:
            logger.error("SD department validity exceeds parents validities")
            raise DepartmentValidityExceedsParentsValiditiesError()

        all_endpoints = sorted(
            parent_timeline_endpoints.union({eng_unit.start, eng_unit.end})
        )
        relevant_endpoints = [
            endpoint
            for endpoint in all_endpoints
            if eng_unit.start <= endpoint <= eng_unit.end
        ]

        for start, end in pairwise(relevant_endpoints):
            desired_parent_intervals.append(
                EngagementUnit(
                    start=start, end=end, value=parent_timeline.entity_at(start).value
                )
            )

    desired_eng_timeline = EngagementTimeline(
        eng_active=sd_eng_timeline.eng_active,
        eng_key=sd_eng_timeline.eng_key,
        eng_name=sd_eng_timeline.eng_name,
        eng_unit=Timeline[EngagementUnit](
            intervals=combine_intervals(tuple(desired_parent_intervals))
        ),
        eng_sd_unit=sd_eng_timeline.eng_sd_unit,
        eng_unit_id=sd_eng_timeline.eng_unit_id,
        eng_type=sd_eng_timeline.eng_type,
    )

    logger.debug(
        "Desired engagement timeline", desired_eng_timeline=desired_eng_timeline.dict()
    )

    logger.info("Done applying OU elevate-to-NY-level strategy")

    return desired_eng_timeline


async def engagement_ou_strategy_region(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    The engagement OU strategy for the regions works as follows:

    1) If the engagement already exists in MO, and if the unit is not "Unknown", the
       engagement will stay in the MO unit for the given interval.
    2) If the engagement is placed in "Unknown" in MO, we will attempt to place the
       engagement in a (random) related unit in the given interval.

    These two rules apply apart from the following exception. If the engagement SD unit
    UUID value changes (stored in MOs engagement attribute "extension_3"), we will
    re-calculate the engagement placement according to 2) above. As a consequence, *any*
    manual engagement changes in MO are overwritten in the given interval! This happens
    when the engagement is placed in a new department in SD. The following ASCII
    illustrates this latter scenario (the unit strings in the drawing actually
    represents unit UUIDs, but are written as strings in the drawing for better
    readability):

    MO (unit)     |------adm1-------|--------adm2---------|-------------adm3----------|
    MO (SD unit)  |------sd1--------|--------sd2----------|-------------sd3-----------|

    SD (unit)     |------sd1--------|------sd2----|------------sd4-----------|---sd3--|

    Re-calc       |------ok---------|------ok-----|--fix--|--------fix-------|---ok---|
    intervals
    """
    logger.info("Applying OU region strategy")
    assert settings.unknown_unit is not None

    sd_ou_only_timeline = EngagementTimeline(eng_unit=sd_eng_timeline.eng_unit)
    mo_ou_only_timeline = EngagementTimeline(eng_unit=mo_eng_timeline.eng_unit)

    sd_interval_endpoints = sd_ou_only_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_ou_only_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of engagement unit endpoints", endpoints=endpoints)

    # Get the MO unit for each endpoint interval or set to "Unknown", if no value is
    # found in MO in the interval
    unit_intervals = []
    for start, end in pairwise(endpoints):
        logger.debug(
            "Processing OU region strategy endpoint pair", start=start, end=end
        )
        try:
            entity = mo_eng_timeline.eng_unit.entity_at(start)
            unit = entity.value
            if settings.recalc_mo_unit_when_sd_employment_moved:
                # Overwrite (i.e. set to the unknown unit and hence recalculate below)
                # if the MO SD unit (extension_3) and the SD unit UUID are different
                # (see docstring ASCII)
                mo_sd_unit = mo_eng_timeline.eng_sd_unit.entity_at(start).value
                sd_unit = sd_eng_timeline.eng_unit.entity_at(start).value
                if not mo_sd_unit == sd_unit:
                    unit = settings.unknown_unit  # type: ignore
        except NoValueError:
            unit = settings.unknown_unit  # type: ignore
        unit_intervals.append(EngagementUnit(start=start, end=end, value=unit))

    # Find the engagement unit(s) in all intervals
    related_unit_intervals = []
    for unit_interval in unit_intervals:
        if not unit_interval.value == settings.unknown_unit:
            related_unit_intervals.append(unit_interval)
        else:
            related_unit_intervals.extend(
                await related_units(
                    gql_client=gql_client,
                    unit_uuid=sd_eng_timeline.eng_unit.entity_at(
                        unit_interval.start
                    ).value,  # type: ignore
                    unit_interval=unit_interval,
                    unknown_unit_uuid=settings.unknown_unit,
                )
            )
    logger.debug(
        "Updated engagement units", related_unit_intervals=related_unit_intervals
    )

    desired_timeline = EngagementTimeline(
        eng_active=sd_eng_timeline.eng_active,
        eng_key=sd_eng_timeline.eng_key,
        eng_name=sd_eng_timeline.eng_name,
        eng_unit=Timeline[EngagementUnit](
            intervals=combine_intervals(tuple(related_unit_intervals))
        ),
        eng_sd_unit=sd_eng_timeline.eng_sd_unit,
        eng_unit_id=sd_eng_timeline.eng_unit_id,
        eng_type=sd_eng_timeline.eng_type,
    )
    logger.debug(
        "Desired engagement timeline", desired_timeline=desired_timeline.dict()
    )

    logger.info("Done applying OU region strategy")

    return desired_timeline


async def engagement_ou_strategy(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    Combined state/strategy pattern choosing an OU timeline strategy based on
    the state specified in the application settings.
    """
    if settings.mode == Mode.MUNICIPALITY:
        if settings.apply_ny_logic:
            return await engagement_ou_strategy_elevate_to_ny_level(
                sd_client, sd_eng_timeline
            )
        return sd_eng_timeline
    return await engagement_ou_strategy_region(
        gql_client=gql_client,
        settings=settings,
        sd_eng_timeline=sd_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
    )


@handle_exclusively_decorator(
    key=lambda sd_client,
    gql_client,
    institution_identifier,
    cpr,
    employment_identifier,
    settings,
    dry_run=False: (institution_identifier, cpr, employment_identifier)
)
async def sync_engagement(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    cpr: str,
    employment_identifier: str,
    settings: SDToolPlusSettings,
    dry_run: bool = False,
) -> None:
    """
    Sync the entire engagement and leave timelines for the given CPR and
    SD EmploymentIdentifier (corresponding to the MO engagement user_key).

    Args:
        sd_client: The SD client
        gql_client: The GraphQL client
        institution_identifier: The SD institution identifier
        cpr: The person CPR number
        employment_identifier: The SD EmploymentIdentifier
        settings: The application settings
        dry_run: If true, nothing will be written to MO.
    """

    logger.info(
        "Sync engagement timeline",
        inst_id=institution_identifier,
        cpr=cpr,
        emp_id=employment_identifier,
        dry_run=dry_run,
    )

    r_employment = await asyncio.to_thread(
        sd_client.get_employment_changed,
        GetEmploymentChangedRequest(
            InstitutionIdentifier=institution_identifier,
            PersonCivilRegistrationIdentifier=cpr,
            EmploymentIdentifier=employment_identifier,
            ActivationDate=date.min,
            DeactivationDate=date.max,
            DepartmentIndicator=True,
            EmploymentStatusIndicator=True,
            ProfessionIndicator=True,
            WorkingTimeIndicator=True,
            UUIDIndicator=True,
        ),
    )

    sd_eng_timeline = await get_employment_timeline(r_employment)

    # Work-around for bug in SDs API (see https://redmine.magenta.dk/issues/64950)
    if len(sd_eng_timeline.eng_unit.intervals) == 0:
        raise DepartmentTimelineNotFoundError()

    # Get the person
    r_person = await gql_client.get_person(CPRNumber(cpr))
    person = one(
        r_person.objects,
        too_short=PersonNotFoundError,
        too_long=MoreThanOnePersonError,
    )

    mo_eng_timeline = await get_engagement_timeline(
        gql_client=gql_client,
        person=person.uuid,
        user_key=_prefix_eng_user_key(
            settings, employment_identifier, institution_identifier
        ),
    )

    desired_eng_timeline = await engagement_ou_strategy(
        sd_client=sd_client,
        gql_client=gql_client,
        settings=settings,
        sd_eng_timeline=sd_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
    )

    await _sync_eng_intervals(
        gql_client=gql_client,
        person=person.uuid,
        institution_identifier=institution_identifier,
        employment_identifier=employment_identifier,
        desired_eng_timeline=desired_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
        settings=settings,
        dry_run=dry_run,
    )

    sd_leave_timeline = await get_sd_leave_timeline(r_employment)
    mo_leave_timeline = await get_mo_leave_timeline(
        gql_client=gql_client,
        person=person.uuid,
        user_key=_prefix_eng_user_key(
            settings, employment_identifier, institution_identifier
        ),
    )

    await _sync_leave_intervals(
        gql_client=gql_client,
        person=person.uuid,
        institution_identifier=institution_identifier,
        employment_identifier=employment_identifier,
        sd_leave_timeline=sd_leave_timeline,
        mo_leave_timeline=mo_leave_timeline,
        settings=settings,
        dry_run=dry_run,
    )

    await sync_associations(
        gql_client=gql_client,
        settings=settings,
        person=person.uuid,
        user_key=employment_identifier,
        desired_eng_timeline=desired_eng_timeline,
        dry_run=dry_run,
    )


async def queue_mo_engagements_for_sd_unit_sync(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    cpr: str | None,
    dry_run: bool,
) -> None:
    """
    Sync the SD unit to the MO engagement extension_3 attribute. All other engagement
    fields are also synchronized except for the engagement unit which is left unchanged.

    Args:
        sd_client: The SD client
        gql_client: The GraphQL client
        settings: The application settings
        cpr: The person CPR number
        dry_run: If true, nothing will be written to MO.
    """
    logger.info(
        "Sync SD unit to MO engagement extension_3 attributes",
        cpr=cpr,
        dry_run=dry_run,
    )

    class Engagement(BaseModel):
        institution_identifier: str
        cpr: str
        employment_identifier: str

    # Get all MO engagements
    eng_filter = EngagementFilter(from_date=None, to_date=None)
    if cpr is not None:
        eng_filter = EngagementFilter(
            employee=EmployeeFilter(cpr_numbers=[cpr]), from_date=None, to_date=None
        )

    engagements = []

    # Make a sequence of paginated GraphQL requests to get all MO engagement
    next_cursor = None
    while True:
        mo_engagement_batch = await gql_client.get_engagements(
            input=eng_filter,
            cursor=next_cursor,
            limit=300,
        )
        next_cursor = mo_engagement_batch.page_info.next_cursor

        for obj in mo_engagement_batch.objects:
            inst_id, emp_id = _split_engagement_user_key(
                settings=settings,
                user_key=first(obj.validities).user_key,
            )
            try:
                eng = Engagement(
                    institution_identifier=inst_id,
                    cpr=one(first(obj.validities).person).cpr_number,
                    employment_identifier=emp_id,
                )
            except ValueError:
                logger.warn(
                    "Could not create object for queueing engagement for SD unit (extention_3) sync",
                    eng_obj=obj.dict(),
                )
                continue
            engagements.append(eng)

        logger.info("Number of engagements processed", n=len(engagements))

        if next_cursor is None:
            break

    for eng in engagements:
        logger.debug(
            "Queuing engagement for SD unit (extension_3) sync", engagement=eng.dict()
        )
        event = EventSendInput(
            namespace="sd",
            routing_key="employment",
            subject=EmploymentGraphQLEvent(
                institution_identifier=eng.institution_identifier,
                cpr=eng.cpr,
                employment_identifier=eng.employment_identifier,
            ).json(),
        )
        await gql_client.send_event(input=event)

    logger.info(
        f"Done queueing {len(engagements)} engagements for SD unit (extension_3) sync)"
    )
