# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
import asyncio
from datetime import date
from datetime import datetime
from datetime import timedelta
from itertools import pairwise
from uuid import UUID

import structlog
from fastapi import HTTPException
from fastramqpi.ramqp.depends import handle_exclusively_decorator
from more_itertools import bucket
from more_itertools import first
from more_itertools import one
from more_itertools import only
from pydantic import BaseModel
from sdclient.client import SDClient
from sdclient.exceptions import SDRootElementNotFound
from sdclient.requests import GetEmploymentChangedRequest
from sdclient.responses import GetDepartmentResponse
from starlette.status import HTTP_404_NOT_FOUND

from sdtoolplus.autogenerated_graphql_client import ClassFilter
from sdtoolplus.autogenerated_graphql_client import EmployeeFilter
from sdtoolplus.autogenerated_graphql_client import EngagementFilter
from sdtoolplus.autogenerated_graphql_client import LeaveFilter
from sdtoolplus.autogenerated_graphql_client.get_address_timeline import (
    GetAddressTimelineAddresses,
)
from sdtoolplus.autogenerated_graphql_client.get_person_timeline import (
    GetPersonTimelineEmployees,
)
from sdtoolplus.autogenerated_graphql_client.input_types import AddressCreateInput
from sdtoolplus.autogenerated_graphql_client.input_types import AddressFilter
from sdtoolplus.autogenerated_graphql_client.input_types import AddressTerminateInput
from sdtoolplus.autogenerated_graphql_client.input_types import FacetFilter
from sdtoolplus.depends import GraphQLClient
from sdtoolplus.exceptions import DepartmentTimelineNotFound
from sdtoolplus.exceptions import NoValueError
from sdtoolplus.exceptions import PersonNotFoundError
from sdtoolplus.mo.timeline import create_engagement
from sdtoolplus.mo.timeline import create_leave
from sdtoolplus.mo.timeline import create_ou
from sdtoolplus.mo.timeline import create_person
from sdtoolplus.mo.timeline import create_pnumber_address
from sdtoolplus.mo.timeline import create_postal_address
from sdtoolplus.mo.timeline import delete_address
from sdtoolplus.mo.timeline import get_engagement_timeline
from sdtoolplus.mo.timeline import get_engagement_types
from sdtoolplus.mo.timeline import get_ou_timeline
from sdtoolplus.mo.timeline import get_pnumber_timeline as get_mo_pnumber_timeline
from sdtoolplus.mo.timeline import (
    get_postal_address_timeline as get_mo_postal_address_timeline,
)
from sdtoolplus.mo.timeline import related_units
from sdtoolplus.mo.timeline import terminate_engagement
from sdtoolplus.mo.timeline import terminate_leave
from sdtoolplus.mo.timeline import terminate_ou
from sdtoolplus.mo.timeline import update_engagement
from sdtoolplus.mo.timeline import update_leave
from sdtoolplus.mo.timeline import update_ou
from sdtoolplus.mo.timeline import update_person
from sdtoolplus.mo_org_unit_importer import OrgUnitUUID
from sdtoolplus.models import EngagementTimeline
from sdtoolplus.models import EngagementUnit
from sdtoolplus.models import LeaveTimeline
from sdtoolplus.models import Person
from sdtoolplus.models import Timeline
from sdtoolplus.models import UnitId
from sdtoolplus.models import UnitPNumber
from sdtoolplus.models import UnitPostalAddress
from sdtoolplus.models import UnitTimeline
from sdtoolplus.models import combine_intervals
from sdtoolplus.sd.person import get_sd_person
from sdtoolplus.sd.timeline import get_department
from sdtoolplus.sd.timeline import get_department_timeline
from sdtoolplus.sd.timeline import get_employment_timeline
from sdtoolplus.sd.timeline import get_pnumber_timeline as get_sd_pnumber_timeline
from sdtoolplus.sd.timeline import (
    get_postal_address_timeline as get_sd_postal_address_timeline,
)

from .config import TIMEZONE
from .config import Mode
from .config import SDToolPlusSettings
from .mo.timeline import get_leave_timeline as get_mo_leave_timeline
from .sd.timeline import get_leave_timeline as get_sd_leave_timeline

logger = structlog.stdlib.get_logger()


def _sd_inst_id_prefix(key: str, inst_id: str) -> str:
    return f"{inst_id}-{key}"


def _prefix_eng_user_key(
    settings: SDToolPlusSettings, user_key: str, inst_id: str
) -> str:
    if settings.mode == Mode.MUNICIPALITY:
        return user_key
    return _sd_inst_id_prefix(user_key, inst_id)


def prefix_unit_id_with_inst_id(
    settings: SDToolPlusSettings, unit_timeline: UnitTimeline, inst_id: str
) -> UnitTimeline:
    if settings.mode == Mode.MUNICIPALITY:
        return unit_timeline

    unit_id_intervals = tuple(
        UnitId(
            start=interval.start,
            end=interval.end,
            value=_sd_inst_id_prefix(interval.value, inst_id),  # type: ignore
        )
        for interval in unit_timeline.unit_id.intervals
    )

    prefixed_unit_timeline = UnitTimeline(
        active=unit_timeline.active,
        name=unit_timeline.name,
        unit_id=Timeline[UnitId](intervals=unit_id_intervals),
        unit_level=unit_timeline.unit_level,
        parent=unit_timeline.parent,
    )
    logger.debug(
        "SD timeline with prefixed unit_id", timeline=prefixed_unit_timeline.dict()
    )

    return prefixed_unit_timeline


async def _sync_person(
    gql_client: GraphQLClient,
    sd_person: Person,
    mo_person: GetPersonTimelineEmployees,
    dry_run: bool,
) -> None:
    mo_objects = only(mo_person.objects)
    if mo_objects is None:
        person_uuid = await create_person(
            gql_client=gql_client,
            cpr=sd_person.cpr,
            givenname=sd_person.given_name,
            lastname=sd_person.surname,
            dry_run=dry_run,
        )

    elif (
        len(mo_objects.validities) > 1
        or one(mo_objects.validities).given_name != sd_person.given_name
        or one(mo_objects.validities).surname != sd_person.surname
    ):
        person_uuid = one(mo_person.objects).uuid
        await update_person(
            gql_client=gql_client,
            uuid=person_uuid,
            start=datetime.today(),
            person=sd_person,
            dry_run=dry_run,
        )
    else:
        # No changes to person, now check addresses
        person_uuid = one(mo_person.objects).uuid
    await sync_person_addresses(
        gql_client=gql_client,
        person_uuid=person_uuid,
        sd_person=sd_person,
        dry_run=dry_run,
    )


async def sync_person_addresses(
    gql_client: GraphQLClient,
    person_uuid: UUID,
    sd_person: Person,
    dry_run: bool,
) -> None:
    """Persons are not temporal objects in SD and are handled differently than orgunits and engagements.
    In stead of the full timeline checks we only check the data from `now` to infinity.
    """
    # TODO: Cache this result as it rarely changes
    address_types_res = await gql_client.get_class(
        class_filter=ClassFilter(facet_user_keys=["employee_address_type"])
    )
    address_types = bucket(
        address_types_res.objects,
        key=lambda x: x.current.user_key if x.current else None,
    )

    desired_emails = sd_person.emails if sd_person.emails else []
    await handle_address(
        gql_client,
        desired_emails,
        person_uuid,
        one(address_types["engagement_email"]).uuid,
        dry_run,
    )
    desired_phone_numbers = (
        [phone_number for phone_number in sd_person.phone_numbers]
        if sd_person.phone_numbers
        else []
    )
    await handle_address(
        gql_client,
        desired_phone_numbers,
        person_uuid,
        one(address_types["engagement_telefon"]).uuid,
        dry_run,
    )
    desired_post_adresses = [sd_person.address] if sd_person.address else []
    # TODO: Addresses should have the scope DAR, but this is not the case everywhere right now.
    await handle_address(
        gql_client,
        desired_post_adresses,
        person_uuid,
        one(address_types["AdresseAPOSOrgUnit"]).uuid,
        dry_run,
    )


def find_address_actions(
    mo_values: GetAddressTimelineAddresses, desired_addresses: list[str]
) -> tuple[set[str], set[UUID]]:
    terminate: set[UUID] = set()
    create: set[str] = set()
    existing: set[str] = set()
    if not mo_values.objects:
        return set(desired_addresses), terminate
    for address in mo_values.objects:
        uuid = address.uuid
        # For each address check that there are only one validity,
        # that the wanted value exists in MO and in the correct timeframe
        if (
            len(address.validities) > 1
            or one(address.validities).value not in desired_addresses
            or one(address.validities).validity.from_ > datetime.now(tz=TIMEZONE)
            or one(address.validities).validity.to is not None
        ):
            # If any of the above reasons are met we terminate the address
            terminate.add(uuid)
        else:
            # If not it is because it exists in MO
            # Check for duplicates:
            if one(address.validities).value in existing:
                terminate.add(uuid)
            existing.add(one(address.validities).value)

    # Create any address from desired_addresses not in MO yet.
    create = {c for c in desired_addresses if c not in existing}
    return create, terminate


async def handle_address(
    gql_client: GraphQLClient,
    desired_addresses: list[str],
    person_uuid: UUID,
    address_type_uuid: UUID,
    dry_run: bool,
):
    mo_person_addresses = await gql_client.get_address_timeline(
        input=AddressFilter(
            employee=EmployeeFilter(uuids=[person_uuid]),
            address_type=ClassFilter(uuids=[address_type_uuid]),
            from_date=datetime.now(),
            to_date=None,
        )
    )
    create, terminate = find_address_actions(mo_person_addresses, desired_addresses)
    # TODO: cache this as it _never_ changes.
    visibility_internal = await gql_client.get_class(
        class_filter=ClassFilter(
            facet=FacetFilter(user_keys=["visibility"]), scope=["INTERNAL"]
        )
    )
    visibility_uuid = one(visibility_internal.objects).uuid

    # Check for new emails:
    for value in create:
        logger.info(
            "Create new address",
            value=value,
            person=person_uuid,
            address_type_uuid=address_type_uuid,
            dry_run=dry_run,
        )
        if not dry_run:
            await gql_client.create_address(
                input=AddressCreateInput(
                    person=person_uuid,
                    validity={"from": datetime.today(), "to": None},
                    value=value,
                    address_type=address_type_uuid,
                    visibility=visibility_uuid,
                )
            )
    # Check for removed emails
    for address_uuid in terminate:
        logger.info("terminate address", person=person_uuid, dry_run=dry_run)
        if not dry_run:
            await gql_client.terminate_address(
                AddressTerminateInput(
                    uuid=address_uuid,
                    to=datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
                    - timedelta(days=1),
                )
            )


@handle_exclusively_decorator(
    key=lambda sd_client, gql_client, institution_identifier, cpr, dry_run=False: cpr
)
async def sync_person(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    cpr: str,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Sync person",
        inst_id=institution_identifier,
        cpr=cpr,
        dry_run=dry_run,
    )
    try:
        sd_person = await get_sd_person(
            sd_client=sd_client,
            institution_identifier=institution_identifier,
            cpr=cpr,
            effective_date=datetime.today(),
        )
    except SDRootElementNotFound:
        raise HTTPException(
            status_code=HTTP_404_NOT_FOUND,
            detail="Person not found in SD",
        )

    mo_person = await gql_client.get_person_timeline(
        filter=EmployeeFilter(
            cpr_numbers=[cpr], from_date=datetime.today(), to_date=None
        )
    )
    logger.debug("MO person", mo_person=mo_person.dict())

    await _sync_person(
        gql_client=gql_client,
        mo_person=mo_person,
        sd_person=sd_person,
        dry_run=dry_run,
    )

    logger.info("Done syncing person!")


async def _sync_eng_intervals(
    gql_client: GraphQLClient,
    person: UUID,
    institution_identifier: str,
    employment_identifier: str,
    desired_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
    settings: SDToolPlusSettings,
    dry_run: bool,
) -> None:
    user_key = _prefix_eng_user_key(
        settings, employment_identifier, institution_identifier
    )

    logger.info(
        "Create, update or terminate engagement in MO",
        person=str(person),
        user_key=user_key,
    )

    # Get the engagement types
    eng_types = await get_engagement_types(gql_client)

    desired_interval_endpoints = desired_eng_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_eng_timeline.get_interval_endpoints()

    endpoints = sorted(desired_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if desired_eng_timeline.equal_at(start, mo_eng_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = desired_eng_timeline.eng_active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not desired_eng_timeline.has_required_mo_values(start):
            logger.error("Cannot create/update engagement due to missing timeline data")
            continue

        mo_eng = await gql_client.get_engagement_timeline(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
        if mo_eng.objects:
            await update_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                desired_eng_timeline=desired_eng_timeline,
                eng_types=eng_types,
                dry_run=dry_run,
            )
        else:
            await create_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                desired_eng_timeline=desired_eng_timeline,
                eng_types=eng_types,
                dry_run=dry_run,
            )

    logger.info(
        "Finished syncing engagement in MO",
        person=str(person),
        user_key=user_key,
    )


async def _sync_leave_intervals(
    gql_client: GraphQLClient,
    person: UUID,
    institution_identifier: str,
    employment_identifier: str,
    sd_leave_timeline: LeaveTimeline,
    mo_leave_timeline: LeaveTimeline,
    settings: SDToolPlusSettings,
    dry_run: bool,
) -> None:
    user_key = _prefix_eng_user_key(
        settings, employment_identifier, institution_identifier
    )

    logger.info(
        "Create, update or terminate leave in MO",
        person=str(person),
        user_key=user_key,
    )

    # Get the leave type (assuming for now that there is only one)
    r_leave_type = await gql_client.get_class(ClassFilter(user_keys=["Orlov"]))
    leave_type = one(r_leave_type.objects).uuid

    # Get the corresponding engagement
    mo_eng = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=None, to_date=None
    )
    eng_obj = only(mo_eng.objects)
    if eng_obj is None:
        logger.warning("Not syncing leaves - no corresponding engagement found")
        return
    eng_uuid = eng_obj.uuid

    sd_interval_endpoints = sd_leave_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_leave_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if sd_leave_timeline.equal_at(start, mo_leave_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = sd_leave_timeline.leave_active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_leave(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not sd_leave_timeline.has_required_mo_values(start):
            logger.error("Cannot create/update leave due to missing timeline data")
            continue

        mo_leave = await gql_client.get_leave(
            LeaveFilter(
                employee=EmployeeFilter(uuids=[person]),
                user_keys=[user_key],
                from_date=None,
                to_date=None,
            )
        )
        if mo_leave.objects:
            await update_leave(
                gql_client=gql_client,
                person=person,
                eng_uuid=eng_uuid,
                user_key=user_key,
                start=start,
                end=end,
                sd_leave_timeline=sd_leave_timeline,
                leave_type=leave_type,
                dry_run=dry_run,
            )
        else:
            await create_leave(
                gql_client=gql_client,
                person=person,
                eng_uuid=eng_uuid,
                user_key=user_key,
                start=start,
                end=end,
                sd_leave_timeline=sd_leave_timeline,
                leave_type=leave_type,
                dry_run=dry_run,
            )

    logger.info(
        "Finished syncing leave in MO",
        person=str(person),
        user_key=user_key,
    )


async def _sync_ou_intervals(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    org_unit: OrgUnitUUID,
    desired_unit_timeline: UnitTimeline,
    mo_unit_timeline: UnitTimeline,
    dry_run: bool,
) -> None:
    logger.info("Create, update or terminate OU in MO", org_unit=str(org_unit))

    # Skip synchronisation if OU was never in SD. This ensures we don't delete
    # org-units unrelated to SD in MO. Note that is *is* technically possible
    # to delete OUs in SD, but in that case we don't receive an AMQP event
    # anyway due to limitations in SD.
    if desired_unit_timeline == UnitTimeline():
        logger.debug("Skipping sync of OU")
        return

    sd_interval_endpoints = desired_unit_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_unit_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if desired_unit_timeline.equal_at(start, mo_unit_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = desired_unit_timeline.active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_ou(
                gql_client=gql_client,
                org_unit=org_unit,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not desired_unit_timeline.has_required_mo_values(start):
            logger.error("Cannot update OU due to missing timeline data")
            continue

        ou = await gql_client.get_org_unit_timeline(
            unit_uuid=org_unit, from_date=None, to_date=None
        )
        if ou.objects:
            await update_ou(
                gql_client=gql_client,
                org_unit=org_unit,
                start=start,
                end=end,
                desired_unit_timeline=desired_unit_timeline,
                org_unit_type_user_key=settings.org_unit_type,
                dry_run=dry_run,
            )
        else:
            await create_ou(
                gql_client=gql_client,
                org_unit=org_unit,
                start=start,
                end=end,
                desired_unit_timeline=desired_unit_timeline,
                org_unit_type_user_key=settings.org_unit_type,
                dry_run=dry_run,
            )

        logger.info("Finished updating unit", org_unit=str(org_unit))


async def _sync_ou_pnumber(
    gql_client: GraphQLClient,
    department: GetDepartmentResponse,
    org_unit: OrgUnitUUID,
    dry_run: bool,
) -> None:
    logger.info("Sync P-number timeline", org_unit=str(org_unit))

    sd_pnumber_timeline = get_sd_pnumber_timeline(department)
    mo_pnumber_timeline_obj = await get_mo_pnumber_timeline(
        gql_client=gql_client,
        unit_uuid=org_unit,
    )

    if sd_pnumber_timeline == mo_pnumber_timeline_obj.pnumber:
        logger.debug("P-number timelines identical")
        return

    if mo_pnumber_timeline_obj.uuid is not None:
        await delete_address(
            gql_client=gql_client,
            address_uuid=mo_pnumber_timeline_obj.uuid,
            dry_run=dry_run,
        )

    if sd_pnumber_timeline == Timeline[UnitPNumber]():
        return

    await create_pnumber_address(
        gql_client=gql_client,
        org_unit=org_unit,
        address_uuid=mo_pnumber_timeline_obj.uuid,
        sd_pnumber_timeline=sd_pnumber_timeline,
        dry_run=dry_run,
    )


async def _sync_ou_postal_address(
    gql_client: GraphQLClient,
    department: GetDepartmentResponse,
    org_unit: OrgUnitUUID,
    dry_run: bool,
) -> None:
    logger.info("Sync postal address timeline", org_unit=str(org_unit))

    sd_postal_address_timeline = get_sd_postal_address_timeline(department)
    mo_postal_address_timeline_obj = await get_mo_postal_address_timeline(
        gql_client=gql_client,
        unit_uuid=org_unit,
    )

    if sd_postal_address_timeline == mo_postal_address_timeline_obj.postal_address:
        logger.debug("Postal address timelines identical")
        return

    if mo_postal_address_timeline_obj.uuid is not None:
        await delete_address(
            gql_client=gql_client,
            address_uuid=mo_postal_address_timeline_obj.uuid,
            dry_run=dry_run,
        )

    if sd_postal_address_timeline == Timeline[UnitPostalAddress]():
        return

    await create_postal_address(
        gql_client=gql_client,
        org_unit=org_unit,
        address_uuid=mo_postal_address_timeline_obj.uuid,
        sd_postal_address_timeline=sd_postal_address_timeline,
        dry_run=dry_run,
    )


@handle_exclusively_decorator(
    key=lambda sd_client,
    gql_client,
    institution_identifier,
    org_unit,
    settings,
    dry_run=False: org_unit
)
async def sync_ou(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    org_unit: OrgUnitUUID,
    settings: SDToolPlusSettings,
    dry_run: bool = False,
) -> None:
    """Sync the entire org unit timeline for the given unit."""
    logger.info(
        "Sync OU timeline",
        institution_identifier=institution_identifier,
        org_uuid=str(org_unit),
        dry_run=dry_run,
    )

    department = await get_department(
        sd_client=sd_client,
        institution_identifier=institution_identifier,
        unit_uuid=org_unit,
    )

    sd_unit_timeline = await get_department_timeline(
        department=department,
        sd_client=sd_client,
        inst_id=institution_identifier,
        unit_uuid=org_unit,
    )
    desired_unit_timeline = prefix_unit_id_with_inst_id(
        settings, sd_unit_timeline, institution_identifier
    )

    mo_unit_timeline = await get_ou_timeline(gql_client, org_unit)

    await _sync_ou_intervals(
        gql_client=gql_client,
        settings=settings,
        org_unit=org_unit,
        desired_unit_timeline=desired_unit_timeline,
        mo_unit_timeline=mo_unit_timeline,
        dry_run=dry_run,
    )

    if department is not None:
        await _sync_ou_pnumber(
            gql_client=gql_client,
            department=department,
            org_unit=org_unit,
            dry_run=dry_run,
        )

        await _sync_ou_postal_address(
            gql_client=gql_client,
            department=department,
            org_unit=org_unit,
            dry_run=dry_run,
        )


async def engagement_ou_strategy_ny_logic(
    sd_client: SDClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    Engagement OU strategy that elevates the engagement from the
    "Afdelings-niveau" to the parent "NY-niveau".
    """
    # TODO: implement NY-logic case!
    return sd_eng_timeline


async def engagement_ou_strategy_region(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    The engagement OU strategy for the regions works as follows:

    1) If the engagement already exists in MO, and if the unit is not "Unknown", the
       engagement will stay in the MO unit for the given interval.
    2) If the engagement is placed in "Unknown" in MO, we will attempt to place the
       engagement in a (random) related unit in the given interval.

    These two rules apply apart from the following exception. If the engagement SD unit
    UUID value changes (stored in MOs engagement attribute "extension_3"), we will
    re-calculate the engagement placement according to 2) above. As a consequence, *any*
    manual engagement changes in MO are overwritten in the given interval! This happens
    when the engagement is placed in a new department in SD. The following ASCII
    illustrates this latter scenario (the unit strings in the drawing actually
    represents unit UUIDs, but are written as strings in the drawing for better
    readability):

    MO (unit)     |------adm1-------|--------adm2---------|-------------adm3----------|
    MO (SD unit)  |------sd1--------|--------sd2----------|-------------sd3-----------|

    SD (unit)     |------sd1--------|------sd2----|------------sd4-----------|---sd3--|

    Re-calc       |------ok---------|------ok-----|--fix--|--------fix-------|---ok---|
    intervals
    """
    logger.info("Applying OU region strategy")
    assert settings.unknown_unit is not None

    sd_ou_only_timeline = EngagementTimeline(eng_unit=sd_eng_timeline.eng_unit)
    mo_ou_only_timeline = EngagementTimeline(eng_unit=mo_eng_timeline.eng_unit)

    sd_interval_endpoints = sd_ou_only_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_ou_only_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of engagement unit endpoints", endpoints=endpoints)

    # Get the MO unit for each endpoint interval or set to "Unknown", if no value is
    # found in MO in the interval
    unit_intervals = []
    for start, end in pairwise(endpoints):
        try:
            entity = mo_eng_timeline.eng_unit.entity_at(start)
            unit = entity.value
            if settings.recalc_mo_unit_when_sd_employment_moved:
                # Overwrite (i.e. set to the unknown unit and hence recalculate below)
                # if the MO SD unit (extension_3) and the SD unit UUID are different
                # (see docstring ASCII)
                mo_sd_unit = mo_eng_timeline.eng_sd_unit.entity_at(start).value
                sd_unit = sd_eng_timeline.eng_unit.entity_at(start).value
                if not mo_sd_unit == sd_unit:
                    unit = settings.unknown_unit  # type: ignore
        except NoValueError:
            unit = settings.unknown_unit  # type: ignore
        unit_intervals.append(EngagementUnit(start=start, end=end, value=unit))

    # Find the engagement unit(s) in all intervals
    related_unit_intervals = []
    for unit_interval in unit_intervals:
        if not unit_interval.value == settings.unknown_unit:
            related_unit_intervals.append(unit_interval)
        else:
            related_unit_intervals.extend(
                await related_units(
                    gql_client=gql_client,
                    unit_uuid=sd_eng_timeline.eng_unit.entity_at(
                        unit_interval.start
                    ).value,  # type: ignore
                    unit_interval=unit_interval,
                    unknown_unit_uuid=settings.unknown_unit,
                )
            )
    logger.debug(
        "Updated engagement units", related_unit_intervals=related_unit_intervals
    )

    updated_timeline = EngagementTimeline(
        eng_active=sd_eng_timeline.eng_active,
        eng_key=sd_eng_timeline.eng_key,
        eng_name=sd_eng_timeline.eng_name,
        eng_unit=Timeline[EngagementUnit](
            intervals=combine_intervals(tuple(related_unit_intervals))
        ),
        eng_sd_unit=sd_eng_timeline.eng_sd_unit,
        eng_unit_id=sd_eng_timeline.eng_unit_id,
        eng_type=sd_eng_timeline.eng_type,
    )
    logger.debug(
        "Desired engagement timeline", desired_timeline=updated_timeline.dict()
    )

    logger.info("Done applying OU region strategy")

    return updated_timeline


async def engagement_ou_strategy(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    Combined state/strategy pattern choosing an OU timeline strategy based on
    the state specified in the application settings.
    """
    if settings.mode == Mode.MUNICIPALITY:
        if settings.apply_ny_logic:
            return await engagement_ou_strategy_ny_logic(
                sd_client, settings, sd_eng_timeline
            )
        return sd_eng_timeline
    return await engagement_ou_strategy_region(
        gql_client=gql_client,
        settings=settings,
        sd_eng_timeline=sd_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
    )


@handle_exclusively_decorator(
    key=lambda sd_client,
    gql_client,
    institution_identifier,
    cpr,
    employment_identifier,
    settings,
    dry_run=False: (institution_identifier, cpr, employment_identifier)
)
async def sync_engagement(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    cpr: str,
    employment_identifier: str,
    settings: SDToolPlusSettings,
    dry_run: bool = False,
) -> None:
    """
    Sync the entire engagement and leave timelines for the given CPR and
    SD EmploymentIdentifier (corresponding to the MO engagement user_key).

    Args:
        sd_client: The SD client
        gql_client: The GraphQL client
        institution_identifier: The SD institution identifier
        cpr: The person CPR number
        employment_identifier: The SD EmploymentIdentifier
        settings: The application settings
        dry_run: If true, nothing will be written to MO.
    """

    logger.info(
        "Sync engagement timeline",
        inst_id=institution_identifier,
        cpr=cpr,
        emp_id=employment_identifier,
        dry_run=dry_run,
    )

    r_employment = await asyncio.to_thread(
        sd_client.get_employment_changed,
        GetEmploymentChangedRequest(
            InstitutionIdentifier=institution_identifier,
            PersonCivilRegistrationIdentifier=cpr,
            EmploymentIdentifier=employment_identifier,
            ActivationDate=date.min,
            DeactivationDate=date.max,
            DepartmentIndicator=True,
            EmploymentStatusIndicator=True,
            ProfessionIndicator=True,
            WorkingTimeIndicator=True,
            UUIDIndicator=True,
        ),
    )

    sd_eng_timeline = await get_employment_timeline(r_employment)

    # Work-around for bug in SDs API (see https://redmine.magenta.dk/issues/64950)
    if len(sd_eng_timeline.eng_unit.intervals) == 0:
        raise DepartmentTimelineNotFound()

    # Get the person
    r_person = await gql_client.get_person(cpr)
    person = only(r_person.objects)
    if person is None:
        # TODO: Return proper HTTP 5xx error message if this happens
        raise PersonNotFoundError("Could not find person in MO")

    mo_eng_timeline = await get_engagement_timeline(
        gql_client=gql_client,
        person=person.uuid,
        user_key=_prefix_eng_user_key(
            settings, employment_identifier, institution_identifier
        ),
    )

    desired_eng_timeline = await engagement_ou_strategy(
        sd_client=sd_client,
        gql_client=gql_client,
        settings=settings,
        sd_eng_timeline=sd_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
    )

    await _sync_eng_intervals(
        gql_client=gql_client,
        person=person.uuid,
        institution_identifier=institution_identifier,
        employment_identifier=employment_identifier,
        desired_eng_timeline=desired_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
        settings=settings,
        dry_run=dry_run,
    )

    sd_leave_timeline = await get_sd_leave_timeline(r_employment)
    mo_leave_timeline = await get_mo_leave_timeline(
        gql_client=gql_client,
        person=person.uuid,
        user_key=_prefix_eng_user_key(
            settings, employment_identifier, institution_identifier
        ),
    )

    await _sync_leave_intervals(
        gql_client=gql_client,
        person=person.uuid,
        institution_identifier=institution_identifier,
        employment_identifier=employment_identifier,
        sd_leave_timeline=sd_leave_timeline,
        mo_leave_timeline=mo_leave_timeline,
        settings=settings,
        dry_run=dry_run,
    )


async def sync_mo_engagement_sd_units(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    cpr: str | None,
    dry_run: bool,
) -> None:
    """
    Sync the SD unit to the MO engagement extension_3 attribute. All other engagement
    fields are also synchronized except for the engagement unit which is left unchanged.

    Args:
        sd_client: The SD client
        gql_client: The GraphQL client
        settings: The application settings
        cpr: The person CPR number
        dry_run: If true, nothing will be written to MO.
    """
    logger.info(
        "Sync SD unit to MO engagement extension_3 attributes",
        cpr=cpr,
        dry_run=dry_run,
    )

    class Engagement(BaseModel):
        institution_identifier: str
        cpr: str
        employment_identifier: str

    # Get all MO engagements
    eng_filter = EngagementFilter(from_date=None, to_date=None)
    if cpr is not None:
        eng_filter = EngagementFilter(
            employee=EmployeeFilter(cpr_numbers=[cpr]), from_date=None, to_date=None
        )
    mo_engagements = await gql_client.get_engagements(eng_filter)
    engagements = []
    for obj in mo_engagements.objects:
        try:
            inst_id, emp_id = first(obj.validities).user_key.split("-")
            engagements.append(
                Engagement(
                    institution_identifier=inst_id,
                    cpr=one(first(obj.validities).person).cpr_number,
                    employment_identifier=emp_id,
                )
            )
        except ValueError:
            logger.warn("Could not sync SD unit for engagement", eng_obj=obj.dict())
            continue

    for eng in engagements:
        logger.debug("Syncing SD unit for engagement", engagement=eng.dict())
        await sync_engagement(
            sd_client=sd_client,
            gql_client=gql_client,
            institution_identifier=eng.institution_identifier,
            cpr=eng.cpr,
            employment_identifier=eng.employment_identifier,
            settings=settings,
            dry_run=dry_run,
        )

    logger.info("Done syncing SD unit to MO engagement extension_3 attributes")
