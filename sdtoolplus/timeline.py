# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
import asyncio
from datetime import date
from datetime import datetime
from itertools import pairwise
from uuid import UUID

import structlog
from fastapi import HTTPException
from more_itertools import first
from more_itertools import one
from more_itertools import only
from sdclient.client import SDClient
from sdclient.exceptions import SDRootElementNotFound
from sdclient.requests import GetEmploymentChangedRequest
from starlette.status import HTTP_404_NOT_FOUND

from sdtoolplus.autogenerated_graphql_client import ClassFilter
from sdtoolplus.autogenerated_graphql_client import EmployeeFilter
from sdtoolplus.autogenerated_graphql_client import LeaveFilter
from sdtoolplus.autogenerated_graphql_client import OrganisationUnitFilter
from sdtoolplus.autogenerated_graphql_client.get_person_timeline import (
    GetPersonTimelineEmployees,
)
from sdtoolplus.depends import GraphQLClient
from sdtoolplus.exceptions import DepartmentTimelineNotFound
from sdtoolplus.exceptions import NoValueError
from sdtoolplus.exceptions import PersonNotFoundError
from sdtoolplus.mo.timeline import create_engagement
from sdtoolplus.mo.timeline import create_leave
from sdtoolplus.mo.timeline import create_ou
from sdtoolplus.mo.timeline import create_person
from sdtoolplus.mo.timeline import get_engagement_timeline
from sdtoolplus.mo.timeline import get_engagement_types
from sdtoolplus.mo.timeline import get_ou_timeline
from sdtoolplus.mo.timeline import related_units
from sdtoolplus.mo.timeline import terminate_engagement
from sdtoolplus.mo.timeline import terminate_leave
from sdtoolplus.mo.timeline import terminate_ou
from sdtoolplus.mo.timeline import update_engagement
from sdtoolplus.mo.timeline import update_leave
from sdtoolplus.mo.timeline import update_ou
from sdtoolplus.mo.timeline import update_person
from sdtoolplus.mo_org_unit_importer import OrgUnitUUID
from sdtoolplus.models import EngagementTimeline
from sdtoolplus.models import EngagementUnit
from sdtoolplus.models import LeaveTimeline
from sdtoolplus.models import Person
from sdtoolplus.models import Timeline
from sdtoolplus.models import UnitId
from sdtoolplus.models import UnitTimeline
from sdtoolplus.models import combine_intervals
from sdtoolplus.sd.person import get_sd_persons
from sdtoolplus.sd.timeline import get_department_timeline
from sdtoolplus.sd.timeline import get_employment_timeline

from .config import Mode
from .config import SDToolPlusSettings
from .mo.timeline import get_leave_timeline as get_mo_leave_timeline
from .sd.timeline import get_leave_timeline as get_sd_leave_timeline

logger = structlog.stdlib.get_logger()


def _sd_inst_id_prefix(key: str, inst_id: str) -> str:
    return f"{inst_id}-{key}"


def _prefix_eng_user_key(
    settings: SDToolPlusSettings, user_key: str, inst_id: str
) -> str:
    if settings.mode == Mode.MUNICIPALITY:
        return user_key
    return _sd_inst_id_prefix(user_key, inst_id)


def prefix_unit_id_with_inst_id(
    settings: SDToolPlusSettings, unit_timeline: UnitTimeline, inst_id: str
) -> UnitTimeline:
    if settings.mode == Mode.MUNICIPALITY:
        return unit_timeline

    unit_id_intervals = tuple(
        UnitId(
            start=interval.start,
            end=interval.end,
            value=_sd_inst_id_prefix(interval.value, inst_id),  # type: ignore
        )
        for interval in unit_timeline.unit_id.intervals
    )

    prefixed_unit_timeline = UnitTimeline(
        active=unit_timeline.active,
        name=unit_timeline.name,
        unit_id=Timeline[UnitId](intervals=unit_id_intervals),
        unit_level=unit_timeline.unit_level,
        parent=unit_timeline.parent,
    )
    logger.debug(
        "SD timeline with prefixed unit_id", timeline=prefixed_unit_timeline.dict()
    )

    return prefixed_unit_timeline


async def _sync_person(
    gql_client: GraphQLClient,
    sd_person: Person,
    mo_person: GetPersonTimelineEmployees,
    dry_run: bool,
) -> None:
    mo_objects = only(mo_person.objects)
    if mo_objects is None:
        await create_person(
            gql_client=gql_client,
            cpr=sd_person.cpr,
            givenname=sd_person.given_name,
            lastname=sd_person.surname,
            dry_run=dry_run,
        )
        return
    mo_validities = mo_objects.validities

    if (
        len(mo_validities) > 1
        or one(mo_validities).given_name != sd_person.given_name
        or one(mo_validities).surname != sd_person.surname
    ):
        await update_person(
            gql_client=gql_client,
            uuid=one(mo_person.objects).uuid,
            start=datetime.today(),
            person=sd_person,
            dry_run=dry_run,
        )


async def sync_person(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    cpr: str,
    dry_run: bool = False,
) -> None:
    logger.info(
        "Sync person",
        inst_id=institution_identifier,
        cpr=cpr,
        dry_run=dry_run,
    )
    try:
        sd_person = await get_sd_persons(
            sd_client=sd_client,
            institution_identifier=institution_identifier,
            cpr=cpr,
            effective_date=datetime.today(),
        )
    except SDRootElementNotFound:
        raise HTTPException(
            status_code=HTTP_404_NOT_FOUND,
            detail="Person not found in SD",
        )

    mo_person = await gql_client.get_person_timeline(
        filter=EmployeeFilter(
            cpr_numbers=[cpr], from_date=datetime.today(), to_date=None
        )
    )
    logger.debug("MO person", mo_person=mo_person.dict())

    await _sync_person(
        gql_client=gql_client,
        mo_person=mo_person,
        sd_person=sd_person,
        dry_run=dry_run,
    )

    logger.info("Done syncing person!")


async def _sync_eng_intervals(
    gql_client: GraphQLClient,
    person: UUID,
    institution_identifier: str,
    employment_identifier: str,
    desired_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
    settings: SDToolPlusSettings,
    dry_run: bool,
) -> None:
    user_key = _prefix_eng_user_key(
        settings, employment_identifier, institution_identifier
    )

    logger.info(
        "Create, update or terminate engagement in MO",
        person=str(person),
        user_key=user_key,
    )

    # Get the engagement types
    eng_types = await get_engagement_types(gql_client)

    desired_interval_endpoints = desired_eng_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_eng_timeline.get_interval_endpoints()

    endpoints = sorted(desired_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if desired_eng_timeline.equal_at(start, mo_eng_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = desired_eng_timeline.eng_active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not desired_eng_timeline.has_required_mo_values(start):
            logger.error("Cannot create/update engagement due to missing timeline data")
            continue

        mo_eng = await gql_client.get_engagement_timeline(
            person=person, user_key=user_key, from_date=None, to_date=None
        )
        if mo_eng.objects:
            await update_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                desired_eng_timeline=desired_eng_timeline,
                eng_types=eng_types,
                dry_run=dry_run,
            )
        else:
            await create_engagement(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                desired_eng_timeline=desired_eng_timeline,
                eng_types=eng_types,
                dry_run=dry_run,
            )


async def _sync_leave_intervals(
    gql_client: GraphQLClient,
    person: UUID,
    institution_identifier: str,
    employment_identifier: str,
    sd_leave_timeline: LeaveTimeline,
    mo_leave_timeline: LeaveTimeline,
    settings: SDToolPlusSettings,
    dry_run: bool,
) -> None:
    user_key = _prefix_eng_user_key(
        settings, employment_identifier, institution_identifier
    )

    logger.info(
        "Create, update or terminate leave in MO",
        person=str(person),
        user_key=user_key,
    )

    # Get the leave type (assuming for now that there is only one)
    r_leave_type = await gql_client.get_class(ClassFilter(user_keys=["Orlov"]))
    leave_type = one(r_leave_type.objects).uuid

    # Get the corresponding engagement
    mo_eng = await gql_client.get_engagement_timeline(
        person=person, user_key=user_key, from_date=None, to_date=None
    )
    eng_obj = only(mo_eng.objects)
    if eng_obj is None:
        logger.warning("Not syncing leaves - no corresponding engagement found")
        return
    eng_uuid = eng_obj.uuid

    sd_interval_endpoints = sd_leave_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_leave_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if sd_leave_timeline.equal_at(start, mo_leave_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = sd_leave_timeline.leave_active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_leave(
                gql_client=gql_client,
                person=person,
                user_key=user_key,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not sd_leave_timeline.has_required_mo_values(start):
            logger.error("Cannot create/update leave due to missing timeline data")
            continue

        mo_leave = await gql_client.get_leave(
            LeaveFilter(
                employee=EmployeeFilter(uuids=[person]),
                user_keys=[user_key],
                from_date=None,
                to_date=None,
            )
        )
        if mo_leave.objects:
            await update_leave(
                gql_client=gql_client,
                person=person,
                eng_uuid=eng_uuid,
                user_key=user_key,
                start=start,
                end=end,
                sd_leave_timeline=sd_leave_timeline,
                leave_type=leave_type,
                dry_run=dry_run,
            )
        else:
            await create_leave(
                gql_client=gql_client,
                person=person,
                eng_uuid=eng_uuid,
                user_key=user_key,
                start=start,
                end=end,
                sd_leave_timeline=sd_leave_timeline,
                leave_type=leave_type,
                dry_run=dry_run,
            )


async def _skip_ou_sync(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    org_unit: OrgUnitUUID,
    desired_unit_timeline: UnitTimeline,
    mo_unit_timeline: UnitTimeline,
) -> bool:
    """
    Check if the org unit should be processed. Skip the unit if:
    1) The unit is the root unit of the payroll organization.
    2) The unit has the root payroll unit as its parent (at any time).
    3) The parents of the unit do *not* have root payroll unit as its GraphQL "root".
       We need to check the parents instead of the unit since the unit itself may not
       exist yet.
    """
    # TODO: Handle municipality mode

    assert settings.mo_subtree_paths_for_root is not None
    payroll_root = first(first(settings.mo_subtree_paths_for_root.values()))

    # Check 1)
    if org_unit == payroll_root:
        logger.debug("OU sync filter: unit is payroll root")
        return True

    # Check 2)
    # if not mo_unit_timeline == UnitTimeline() and any(
    if any(
        parent.value == payroll_root for parent in mo_unit_timeline.parent.intervals
    ):
        logger.debug("OU sync filter: unit is immediately below payroll root")
        return True

    # Check 3)
    parent_roots = await gql_client.get_parent_roots(
        OrganisationUnitFilter(
            parents=None,
            descendant=OrganisationUnitFilter(
                uuids=[
                    parent.value
                    for parent in desired_unit_timeline.parent.intervals
                    if parent.value is not None
                ],
                from_date=None,
                to_date=None,
            ),
            from_date=None,
            to_date=None,
        )
    )
    try:
        parent_root = one(parent_roots.objects).uuid
    except ValueError:
        logger.debug("OU sync filter: unit has been placed below multiple root units")
        return True
    if not parent_root == payroll_root:
        logger.debug("OU sync filter: unit root is not payroll root")
        return True

    return False


async def _sync_ou_intervals(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    org_unit: OrgUnitUUID,
    desired_unit_timeline: UnitTimeline,
    mo_unit_timeline: UnitTimeline,
    dry_run: bool,
) -> None:
    logger.info("Create, update or terminate OU in MO", org_unit=str(org_unit))

    skip_ou = await _skip_ou_sync(
        gql_client=gql_client,
        settings=settings,
        org_unit=org_unit,
        desired_unit_timeline=desired_unit_timeline,
        mo_unit_timeline=mo_unit_timeline,
    )
    if skip_ou:
        logger.debug("Skipping sync of OU")
        return

    sd_interval_endpoints = desired_unit_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_unit_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of endpoints", endpoints=endpoints)

    for start, end in pairwise(endpoints):
        logger.debug("Processing endpoint pair", start=start, end=end)

        if desired_unit_timeline.equal_at(start, mo_unit_timeline):
            logger.debug("SD and MO equal")
            continue

        try:
            is_active = desired_unit_timeline.active.entity_at(start).value
        except NoValueError:
            is_active = False  # type: ignore

        if not is_active:
            await terminate_ou(
                gql_client=gql_client,
                org_unit=org_unit,
                start=start,
                end=end,
                dry_run=dry_run,
            )
            continue

        if not desired_unit_timeline.has_required_mo_values(start):
            logger.error("Cannot update OU due to missing timeline data")
            continue

        ou = await gql_client.get_org_unit_timeline(
            unit_uuid=org_unit, from_date=None, to_date=None
        )
        if ou.objects:
            await update_ou(
                gql_client=gql_client,
                org_unit=org_unit,
                start=start,
                end=end,
                desired_unit_timeline=desired_unit_timeline,
                org_unit_type_user_key=settings.org_unit_type,
                dry_run=dry_run,
            )
        else:
            await create_ou(
                gql_client=gql_client,
                org_unit=org_unit,
                start=start,
                end=end,
                desired_unit_timeline=desired_unit_timeline,
                org_unit_type_user_key=settings.org_unit_type,
                dry_run=dry_run,
            )


async def sync_ou(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    org_unit: OrgUnitUUID,
    settings: SDToolPlusSettings,
    dry_run: bool = False,
) -> None:
    """Sync the entire org unit timeline for the given unit."""
    logger.info(
        "Sync OU timeline",
        institution_identifier=institution_identifier,
        org_uuid=str(org_unit),
        dry_run=dry_run,
    )

    sd_unit_timeline = await get_department_timeline(
        sd_client=sd_client,
        inst_id=institution_identifier,
        unit_uuid=org_unit,
    )
    desired_unit_timeline = prefix_unit_id_with_inst_id(
        settings, sd_unit_timeline, institution_identifier
    )

    mo_unit_timeline = await get_ou_timeline(gql_client, org_unit)

    await _sync_ou_intervals(
        gql_client=gql_client,
        settings=settings,
        org_unit=org_unit,
        desired_unit_timeline=desired_unit_timeline,
        mo_unit_timeline=mo_unit_timeline,
        dry_run=dry_run,
    )


async def engagement_ou_strategy_ny_logic(
    sd_client: SDClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    Engagement OU strategy that elevates the engagement from the
    "Afdelings-niveau" to the parent "NY-niveau".
    """
    # TODO: implement NY-logic case!
    return sd_eng_timeline


async def engagement_ou_strategy_region(
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    The engagement OU strategy for the regions works as follows:

    1) If the engagement already exists in MO, and if the unit is not "Unknown", the
       engagement will stay in the MO unit for the given interval.
    2) If the engagement is placed in "Unknown" in MO, we will attempt to place the
       engagement in a (random) related unit in the given interval.
    """
    logger.info("Applying OU region strategy")
    assert settings.unknown_unit is not None

    sd_ou_only_timeline = EngagementTimeline(eng_unit=sd_eng_timeline.eng_unit)
    mo_ou_only_timeline = EngagementTimeline(eng_unit=mo_eng_timeline.eng_unit)

    sd_interval_endpoints = sd_ou_only_timeline.get_interval_endpoints()
    mo_interval_endpoints = mo_ou_only_timeline.get_interval_endpoints()

    endpoints = sorted(sd_interval_endpoints.union(mo_interval_endpoints))
    logger.debug("List of engagement unit endpoints", endpoints=endpoints)

    # Get the MO unit for each endpoint interval or set to "Unknown", if no value is
    # found in MO in the interval
    unit_intervals = []
    for start, end in pairwise(endpoints):
        try:
            entity = mo_eng_timeline.eng_unit.entity_at(start)
            unit = entity.value
        except NoValueError:
            unit = settings.unknown_unit  # type: ignore
        unit_intervals.append(EngagementUnit(start=start, end=end, value=unit))

    # Find the engagement unit(s) in all intervals
    related_unit_intervals = []
    for unit_interval in unit_intervals:
        if not unit_interval.value == settings.unknown_unit:
            related_unit_intervals.append(unit_interval)
        else:
            related_unit_intervals.extend(
                await related_units(
                    gql_client=gql_client,
                    unit_uuid=sd_eng_timeline.eng_unit.entity_at(
                        unit_interval.start
                    ).value,  # type: ignore
                    unit_interval=unit_interval,
                    unknown_unit_uuid=settings.unknown_unit,
                )
            )
    logger.debug(
        "Updated engagement units", related_unit_intervals=related_unit_intervals
    )

    updated_timeline = EngagementTimeline(
        eng_active=sd_eng_timeline.eng_active,
        eng_key=sd_eng_timeline.eng_key,
        eng_name=sd_eng_timeline.eng_name,
        eng_unit=Timeline[EngagementUnit](
            intervals=combine_intervals(tuple(related_unit_intervals))
        ),
        eng_unit_id=sd_eng_timeline.eng_unit_id,
        eng_type=sd_eng_timeline.eng_type,
    )
    logger.debug(
        "Updated SD engagement timeline", updated_timeline=updated_timeline.dict()
    )

    logger.info("Done applying OU region strategy")

    return updated_timeline


async def engagement_ou_strategy(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    settings: SDToolPlusSettings,
    sd_eng_timeline: EngagementTimeline,
    mo_eng_timeline: EngagementTimeline,
) -> EngagementTimeline:
    """
    Combined state/strategy pattern choosing an OU timeline strategy based on
    the state specified in the application settings.
    """
    if settings.mode == Mode.MUNICIPALITY:
        if settings.apply_ny_logic:
            return await engagement_ou_strategy_ny_logic(
                sd_client, settings, sd_eng_timeline
            )
        return sd_eng_timeline
    return await engagement_ou_strategy_region(
        gql_client=gql_client,
        settings=settings,
        sd_eng_timeline=sd_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
    )


async def sync_engagement(
    sd_client: SDClient,
    gql_client: GraphQLClient,
    institution_identifier: str,
    cpr: str,
    employment_identifier: str,
    settings: SDToolPlusSettings,
    dry_run: bool = False,
) -> None:
    """
    Sync the entire engagement and leave timelines for the given CPR and
    SD EmploymentIdentifier (corresponding to the MO engagement user_key).

    Args:
        sd_client: The SD client
        gql_client: The GraphQL client
        institution_identifier: The SD institution identifier
        cpr: The person CPR number
        employment_identifier: The SD EmploymentIdentifier
        settings: The application settings
        dry_run: If true, nothing will be written to MO.
    """

    logger.info(
        "Sync engagement timeline",
        inst_id=institution_identifier,
        cpr=cpr,
        emp_id=employment_identifier,
        dry_run=dry_run,
    )

    r_employment = await asyncio.to_thread(
        sd_client.get_employment_changed,
        GetEmploymentChangedRequest(
            InstitutionIdentifier=institution_identifier,
            PersonCivilRegistrationIdentifier=cpr,
            EmploymentIdentifier=employment_identifier,
            ActivationDate=date.min,
            DeactivationDate=date.max,
            DepartmentIndicator=True,
            EmploymentStatusIndicator=True,
            ProfessionIndicator=True,
            WorkingTimeIndicator=True,
            UUIDIndicator=True,
        ),
    )

    sd_eng_timeline = await get_employment_timeline(r_employment)

    # Work-around for bug in SDs API (see https://redmine.magenta.dk/issues/64950)
    if len(sd_eng_timeline.eng_unit.intervals) == 0:
        raise DepartmentTimelineNotFound()

    # Get the person
    r_person = await gql_client.get_person(cpr)
    person = only(r_person.objects)
    if person is None:
        # TODO: Return proper HTTP 5xx error message if this happens
        raise PersonNotFoundError("Could not find person in MO")

    mo_eng_timeline = await get_engagement_timeline(
        gql_client=gql_client,
        person=person.uuid,
        user_key=_prefix_eng_user_key(
            settings, employment_identifier, institution_identifier
        ),
    )

    desired_eng_timeline = await engagement_ou_strategy(
        sd_client=sd_client,
        gql_client=gql_client,
        settings=settings,
        sd_eng_timeline=sd_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
    )

    await _sync_eng_intervals(
        gql_client=gql_client,
        person=person.uuid,
        institution_identifier=institution_identifier,
        employment_identifier=employment_identifier,
        desired_eng_timeline=desired_eng_timeline,
        mo_eng_timeline=mo_eng_timeline,
        settings=settings,
        dry_run=dry_run,
    )

    sd_leave_timeline = await get_sd_leave_timeline(r_employment)
    mo_leave_timeline = await get_mo_leave_timeline(
        gql_client=gql_client,
        person=person.uuid,
        user_key=_prefix_eng_user_key(
            settings, employment_identifier, institution_identifier
        ),
    )

    await _sync_leave_intervals(
        gql_client=gql_client,
        person=person.uuid,
        institution_identifier=institution_identifier,
        employment_identifier=employment_identifier,
        sd_leave_timeline=sd_leave_timeline,
        mo_leave_timeline=mo_leave_timeline,
        settings=settings,
        dry_run=dry_run,
    )
